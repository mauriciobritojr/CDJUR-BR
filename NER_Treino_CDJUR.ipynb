{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##BERT"
      ],
      "metadata": {
        "id": "2UvkY9Rtv6G7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Funções Gerais"
      ],
      "metadata": {
        "id": "37uXxZG1wJ-u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GidgnbIUefVW",
        "outputId": "24737d75-a88b-42ae-d979-cee8e551fd4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "L0UPt4Zvwcn9",
        "outputId": "d1ac4a06-6188-430c-ee86-9142d09cbbdd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSAu2iRfwcn9",
        "outputId": "494578c1-dd33-4403-8acd-acbedcb8484a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=fdda0fad1d78fe9c8da47899e6211a2acbfcdb3b1a1f59b2e97ba41f1f1743bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcNBLC7wwcn-",
        "outputId": "154a1194-0f6b-45ca-f2b3-5e20f4390362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-16 19:26:28.563845\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "inicio = datetime.now()\n",
        "print(inicio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzKI8_YLwcn-"
      },
      "outputs": [],
      "source": [
        "#CDJur - Grupos de entidades\n",
        "import tqdm\n",
        "import os\n",
        "\n",
        "def get_data(path_file):\n",
        "  sentence_id = 0\n",
        "  data = []\n",
        "  #for p, _, files in tqdm.tqdm(os.walk(os.path.abspath(path_dataset))):\n",
        "  #  for file_in in tqdm.tqdm(files):\n",
        "      #print(file_in)\n",
        "  #    if file_in == 'train.conll' or file_in == 'test.conll':\n",
        "  #      continue\n",
        "  with open(path_file, encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "      splits = line.split(' ')\n",
        "\n",
        "      if len(splits) == 2:\n",
        "        item = {}\n",
        "        item['sentence_idx'] = sentence_id\n",
        "        item['word'] = splits[0]\n",
        "        item['tag'] = splits[-1].replace('\\n', '').strip()\n",
        "        if (item['word'] == '' or item['tag'] == ''):\n",
        "          if (item['tag'].startswith('B')):\n",
        "            print('word: ' + item['word'])\n",
        "            print('tag: ' + item['tag'])\n",
        "        else:\n",
        "            data.append(item)\n",
        "      #elif len(splits) == 1\n",
        "      elif line.endswith('.conll\\n'): #alterando para considerar um arquivo por completo e não dividi-lo por sentenças; nessa alteração, sentence_id corresponderá ao id do arquivo\n",
        "        sentence_id += 1\n",
        "\n",
        "  print(len(data))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjsfAdOzwcn_"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "import argparse\n",
        "#from keras_preprocessing.sequence import pad_sequences\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import os\n",
        "from transformers import BertTokenizer, BertForTokenClassification, BertConfig\n",
        "from seqeval.metrics import classification_report, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4oAdq6gwcn_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tqdm\n",
        "import re\n",
        "\n",
        "# Create class for reading in and separating sentences from their labels\n",
        "class SentenceGetter(object):\n",
        "    def __init__(self, data_path, tag2idx):\n",
        "        self.sents = []\n",
        "        self.labels = []\n",
        "\n",
        "        #for p, _, files in tqdm.tqdm(os.walk(os.path.abspath(data_path))):\n",
        "        #  for file_in in files:\n",
        "        #    with open(os.path.join(p, file_in), encoding=\"utf-8\") as f:\n",
        "\n",
        "        with open(data_path) as f:\n",
        "            if slide_length == 0:\n",
        "              txt = f.read().split(\"\\n\\n\")\n",
        "            else:\n",
        "              #txt = re.split('.txt', f.read()) #Separa por arquivo\n",
        "              txt = [t for t in re.split(r'\\b[\\w\\d_]*\\.txt', f.read()) if len(t) > 0]\n",
        "\n",
        "        print('Texto: ' + str(len(txt)))\n",
        "        self.sents_raw = [(sent.split(\"\\n\")) for sent in txt]\n",
        "        print('Sents_raw: ' + str(len(self.sents_raw)))\n",
        "\n",
        "        qtde_tokens = 0\n",
        "\n",
        "        for sent in self.sents_raw:\n",
        "            tok_lab_pairs = [pair.split() for pair in sent if len(pair.split()) > 1]\n",
        "\n",
        "            # Handles (very rare) formatting issue causing IndexErrors\n",
        "            try:\n",
        "                toks = [pair[0] for pair in tok_lab_pairs]\n",
        "                labs = [pair[-1] for pair in tok_lab_pairs]\n",
        "\n",
        "                # In the Russian data, a few invalid labels such as '-' were produced\n",
        "                # by the spaCy preprocessing. Because of that, we generate a mask to\n",
        "                # check if there are any invalid labels in the sequence, and if there\n",
        "                # are, we reindex `toks` and `labs` to exclude them.\n",
        "                mask = [False if l not in tag2idx else True for l in labs]\n",
        "                if any(mask):\n",
        "                    toks = list(np.array(toks)[mask])\n",
        "                    labs = list(np.array(labs)[mask])\n",
        "\n",
        "            except IndexError:\n",
        "                print(sent)\n",
        "                continue\n",
        "\n",
        "            if len(toks) > 0:\n",
        "                self.sents.append(toks)\n",
        "                self.labels.append(labs)\n",
        "\n",
        "        print(f\"Constructed SentenceGetter with {len(self.sents)} examples.\")\n",
        "        print(f\"Labels {len(self.labels)}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKwQwatjwcn_"
      },
      "outputs": [],
      "source": [
        "def level_entity_new (labels, preds):\n",
        "\n",
        "  labels_cm, preds_cm = [], []\n",
        "\n",
        "  for id, lab in enumerate(labels):\n",
        "    encontrou = False\n",
        "    #verifica a predição das entidades != de O\n",
        "    if lab.startswith('B-'):\n",
        "      encontrou = False\n",
        "      id_inicio, id_fim = id, id\n",
        "\n",
        "      #verifica onde termina a entidade\n",
        "      for id_prox in range(id+1, len(labels)):\n",
        "        if not labels[id_prox].startswith('I-'):\n",
        "          id_fim = id_prox - 1\n",
        "          break\n",
        "\n",
        "      ent_pred = 'O'\n",
        "      for id_pred in range(id_inicio, id_fim+1):\n",
        "        if preds[id_pred][2:] == lab[2:]:\n",
        "          ent_pred = preds[id_pred]\n",
        "          encontrou = True\n",
        "          break\n",
        "        else:\n",
        "          ent_pred = preds[id_pred]\n",
        "\n",
        "      labels_cm.append(lab)\n",
        "      if ent_pred == 'O':\n",
        "        preds_cm.append('O')\n",
        "      else:\n",
        "        preds_cm.append('B-' + ent_pred[2:])\n",
        "    elif lab == 'O':\n",
        "      #verifica se a predição e a label são O ou se a predição é uma parte da label e já foi contada anteriormente\n",
        "      if preds[id] == lab or encontrou:\n",
        "        labels_cm.append('O')\n",
        "        preds_cm.append('O')\n",
        "      else:\n",
        "        if preds[id].startswith('B-'):\n",
        "          encontrou_pred = False\n",
        "          #verifica até onde termina a entidade se terá uma label real\n",
        "          for id_prox in range(id+1, len(labels)):\n",
        "            if preds[id_prox].startswith('I-'):\n",
        "              if labels[id_prox] != 'O':\n",
        "                encontrou_pred = True\n",
        "                break\n",
        "            else:\n",
        "              break\n",
        "          #se não tiver label anotada em toda a entidade predita, adiciona;\n",
        "          #caso contrário, não adiciona, pois será adicionado pela verificação da label\n",
        "          if not encontrou_pred:\n",
        "            labels_cm.append('O')\n",
        "            preds_cm.append('B-' + preds[id][2:])\n",
        "\n",
        "  cr = classification_report([labels_cm], [preds_cm])\n",
        "\n",
        "  header = sorted(list(set(labels_cm + preds_cm)))\n",
        "  cm = confusion_matrix(labels_cm, preds_cm, labels=header)\n",
        "  mat_formatted = [header[i] + \"\\t\" + str(row) for i, row in enumerate(cm)]\n",
        "  content_cm = \"\\t\" + \" \".join(header) + \"\\n\" + \"\\n\".join(mat_formatted)\n",
        "\n",
        "  return cr, content_cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FINgmk58wcoA"
      },
      "outputs": [],
      "source": [
        "def level_entity (labels, preds):\n",
        "\n",
        "  labels_cm, preds_cm = [], []\n",
        "  inicio = 0#, antes, depois = 0, 0, 0\n",
        "  aux_preds = {}\n",
        "\n",
        "  def add_pred_entity(aux_preds, label_true):\n",
        "    tag_pred = None\n",
        "    if (len(aux_preds) > 1 and label_true[2:] in aux_preds):\n",
        "      aux_preds.pop(label_true[2:])\n",
        "      if (len(aux_preds) == 1 and 'O' in aux_preds):\n",
        "        tag_pred = label_true[2:]\n",
        "        #antes += 1\n",
        "\n",
        "    if tag_pred == None:\n",
        "      tag_pred = max(aux_preds, key = lambda chave: aux_preds[chave])\n",
        "\n",
        "    if len(tag_pred) > 1:\n",
        "      tag_pred = 'B-' + tag_pred\n",
        "    preds_cm.append(tag_pred)\n",
        "    return 0, {}\n",
        "\n",
        "  for index in range(0, len(labels)):\n",
        "    if labels[index] == 'O':\n",
        "      if inicio == 1:\n",
        "        inicio, aux_preds = add_pred_entity(aux_preds, labels_cm[len(labels_cm)-1])\n",
        "      labels_cm.append(labels[index])\n",
        "\n",
        "      if preds[index].startswith('I'):\n",
        "        preds_cm.append('O')\n",
        "        #depois += 1\n",
        "      else:\n",
        "        preds_cm.append(preds[index])\n",
        "\n",
        "    else:\n",
        "      if labels[index].startswith('B'):\n",
        "        if inicio == 1:\n",
        "          inicio, aux_preds = add_pred_entity(aux_preds, labels_cm[len(labels_cm)-1])\n",
        "        labels_cm.append(labels[index])\n",
        "        inicio = 1\n",
        "\n",
        "        tag = preds[index]\n",
        "        if len(tag) > 1:\n",
        "          tag = tag[2:]\n",
        "\n",
        "        if tag in aux_preds:\n",
        "          aux_preds[tag] += 1\n",
        "        else:\n",
        "          aux_preds[tag] = 1\n",
        "\n",
        "      elif labels[index].startswith('I'):\n",
        "        tag = preds[index]\n",
        "        if len(tag) > 1:\n",
        "          tag = tag[2:]\n",
        "\n",
        "        if tag in aux_preds:\n",
        "          aux_preds[tag] += 1\n",
        "        else:\n",
        "          aux_preds[tag] = 1\n",
        "\n",
        "  if inicio == 1:\n",
        "    inicio, aux_preds = add_pred_entity(aux_preds, labels_cm[len(labels_cm)-1])\n",
        "\n",
        "  #print(labels_cm)\n",
        "  #print(preds_cm)\n",
        "\n",
        "  cr = classification_report([labels_cm], [preds_cm])\n",
        "\n",
        "  header = sorted(list(set(labels_cm + preds_cm)))\n",
        "  cm = confusion_matrix(labels_cm, preds_cm, labels=header)\n",
        "  mat_formatted = [header[i] + \"\\t\" + str(row) for i, row in enumerate(cm)]\n",
        "  content_cm = \"\\t\" + \" \".join(header) + \"\\n\" + \"\\n\".join(mat_formatted)\n",
        "\n",
        "  #print(cr)\n",
        "  #print(content_cm)\n",
        "\n",
        "  #print('Antes: ' + str(antes))\n",
        "  #print('Depois: ' + str(depois))\n",
        "\n",
        "  return cr, content_cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4ra3kXlwcoA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "par_vitima, par_reu, par_autor, par_testemunha = 0, 0, 0, 0\n",
        "\n",
        "class BertDataset:\n",
        "    def __init__(self, sg, tokenizer, max_len, slide_length, tag2idx):\n",
        "\n",
        "        \"\"\"\n",
        "        Takes care of the tokenization and ID-conversion steps\n",
        "        for prepping data for BERT.\n",
        "\n",
        "        Takes a SentenceGetter (sg) initialized on the data you\n",
        "        want to use as argument.\n",
        "        \"\"\"\n",
        "\n",
        "        pad_tok = tokenizer.vocab[\"[PAD]\"]\n",
        "        sep_tok = tokenizer.vocab[\"[SEP]\"]\n",
        "        o_lab = tag2idx[\"O\"]\n",
        "\n",
        "        if slide_length == 0:\n",
        "          #Tokenize the text into subwords in a label-preserving way\n",
        "          tokenized_texts = [\n",
        "              tokenize_and_preserve_labels(sent, labs, tokenizer, 0, 0)\n",
        "              for sent, labs in zip(sg.sents, sg.labels)\n",
        "          ]\n",
        "          self.toks = [[\"[CLS]\"] + text[0] for text in tokenized_texts]\n",
        "          self.labs = [[\"O\"] + text[1] for text in tokenized_texts]\n",
        "        else:\n",
        "          toks_texts = []\n",
        "          labs_texts = []\n",
        "          max_context_texts = []\n",
        "          for sent, labs in zip(sg.sents, sg.labels):\n",
        "            tokens, labels, max_context = tokenize_and_preserve_labels(sent, labs, tokenizer, max_len, slide_length)\n",
        "            for t in tokens:\n",
        "              toks_texts.append(t)\n",
        "            for l in labels:\n",
        "              labs_texts.append(l)\n",
        "            for m in max_context:\n",
        "              max_context_texts.append(m)\n",
        "\n",
        "          self.toks = [[\"[CLS]\"] + text for text in toks_texts]\n",
        "          self.labs = [[\"O\"] + text for text in labs_texts]\n",
        "          self.max_context = [[0] + text for text in max_context_texts]\n",
        "\n",
        "        #print('Vítima:', par_vitima)\n",
        "        #print('Reu:', par_reu)\n",
        "        #print('Autor:', par_autor)\n",
        "        #print('Testemunha:', par_testemunha)\n",
        "\n",
        "        # Convert tokens to IDs\n",
        "        print('Quantidade de sentenças (tokens):', len(self.toks))\n",
        "        self.input_ids = pad_sequences(\n",
        "            [tokenizer.convert_tokens_to_ids(txt) for txt in self.toks],\n",
        "            maxlen=max_len,\n",
        "            padding=\"post\",\n",
        "            dtype=\"long\",\n",
        "            truncating=\"post\",\n",
        "        )\n",
        "\n",
        "        # Convert tags to IDs\n",
        "        print('Quantidade de sentenças (labels):', len(self.labs))\n",
        "        tags_ids = [[tag2idx[l] for l in lab] for lab in self.labs]\n",
        "        self.tags = pad_sequences(\n",
        "            tags_ids,\n",
        "            maxlen=max_len,\n",
        "            value=tag2idx[\"O\"],\n",
        "            padding=\"post\",\n",
        "            dtype=\"long\",\n",
        "            truncating=\"post\",\n",
        "        )\n",
        "\n",
        "        if slide_length > 0:\n",
        "          self.max_context = pad_sequences(\n",
        "              self.max_context, maxlen=max_len,\n",
        "              value=0,\n",
        "              padding=\"post\",\n",
        "              dtype=\"long\",\n",
        "              truncating=\"post\",\n",
        "          )\n",
        "\n",
        "        # Swaps out the final token-label pair for ([SEP], O)\n",
        "        # for any sequences that reach the MAX_LEN\n",
        "        id = -1\n",
        "        for voc_ids, tag_ids in zip(self.input_ids, self.tags):\n",
        "            id += 1\n",
        "            if voc_ids[-1] == pad_tok:\n",
        "                continue\n",
        "            else:\n",
        "                voc_ids[-1] = sep_tok\n",
        "                tag_ids[-1] = o_lab\n",
        "                if slide_length > 0:\n",
        "                  self.max_context[id][-1] = -1\n",
        "\n",
        "        # Place a mask (zero) over the padding tokens\n",
        "        self.attn_masks = [[float(i > 0) for i in ii] for ii in self.input_ids]\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer, max_len, slide_length):\n",
        "\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    #print('sentence:', len(sentence))\n",
        "\n",
        "    #print('text_labels:', text_labels)\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "      # Tokenize the word and count # of subwords the word is broken into\n",
        "      tokenized_word = tokenizer.tokenize(word)\n",
        "      n_subwords = len(tokenized_word)\n",
        "\n",
        "      # Add the tokenized word to the final tokenized word list\n",
        "      tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "      # Add the same label to the new list of labels `n_subwords` times\n",
        "      if label.startswith('B-'):\n",
        "        labels.extend([label])\n",
        "        if ('I-' + label[2:] not in tag2idx):\n",
        "          add_tag('I-' + label[2:])\n",
        "        labels.extend(['I-' + label[2:]] * (n_subwords-1))\n",
        "      else:\n",
        "        labels.extend([label] * n_subwords)\n",
        "      #labels.extend([label])\n",
        "      #if ('X' not in tag2idx):\n",
        "      #    add_tag('X')\n",
        "      #labels.extend(['X'] * (n_subwords-1))\n",
        "\n",
        "    if slide_length == 0:\n",
        "      return tokenized_sentence, labels\n",
        "\n",
        "    n = max_len - 1 #conta menos um token: [CLS]\n",
        "    tokenized_limite_sentenca = []\n",
        "    labels_limite_sentenca = []\n",
        "    list_max_context = []\n",
        "    for i in range(0, len(tokenized_sentence), n-slide_length):\n",
        "        final_sentenca = i+n\n",
        "        if final_sentenca > len(tokenized_sentence):\n",
        "            final_sentenca = len(tokenized_sentence)\n",
        "        tokenized_limite_sentenca.append(tokenized_sentence[i:final_sentenca])\n",
        "        labels_limite_sentenca.append(labels[i:final_sentenca])\n",
        "        if i == 0:\n",
        "            t1 = n-(slide_length//2)\n",
        "            if t1 > final_sentenca:\n",
        "                t1 = final_sentenca\n",
        "            t2 = final_sentenca - t1\n",
        "            max_context = [True] * t1 + [False] * t2\n",
        "        elif final_sentenca >= len(tokenized_sentence):\n",
        "            t2 = final_sentenca-i-(slide_length//2)\n",
        "            max_context = [False] * (slide_length//2) + [True] * t2\n",
        "        else:\n",
        "            max_context = [False] * (slide_length//2) + [True] * (n-slide_length) + [False] * (slide_length//2)\n",
        "\n",
        "        list_max_context.append(max_context)\n",
        "        if final_sentenca <= n-slide_length//2:\n",
        "            break\n",
        "\n",
        "    #for idx, token_sent in enumerate(tokenized_limite_sentenca):\n",
        "    #  for idx_t, token in enumerate(token_sent):\n",
        "    #    print(idx_t, token, labels_limite_sentenca[idx][idx_t], list_max_context[idx][idx_t])\n",
        "    #  print('troca de sentença')\n",
        "    #  if idx == 2:\n",
        "    #      break\n",
        "    #print('tokenized_limite_sentenca:', tokenized_limite_sentenca)\n",
        "    #print('labels_limite_sentenca:', labels_limite_sentenca)\n",
        "    #print('list_max_context:', list_max_context)\n",
        "\n",
        "    #print(len(labels_limite_sentenca))\n",
        "    for id1, labs_sent in enumerate(labels_limite_sentenca):\n",
        "      enderecosEncontrados = []\n",
        "      pessoasEncontradas = []\n",
        "      for id2, label in enumerate(labs_sent):\n",
        "        if label.startswith('B-END') and list_max_context[id1][id2]:\n",
        "          #print('encontrou endereço:', label)\n",
        "          enderecosEncontrados.append(label)\n",
        "        if label.startswith('B-PES'):\n",
        "          #print('encontrou pessoa:', label)\n",
        "          pessoasEncontradas.append(label)\n",
        "\n",
        "      '''\n",
        "      if 'B-PES_VITIMA' in pessoasEncontradas and 'B-END_VITIMA' in enderecosEncontrados:\n",
        "          print('encontrou vítima:')\n",
        "          print('labs:', labs_sent)\n",
        "          print('toks:', tokenized_limite_sentenca[id1])\n",
        "          global par_vitima\n",
        "          par_vitima += 1\n",
        "      if 'B-PES_REU' in pessoasEncontradas and 'B-END_REU' in enderecosEncontrados:\n",
        "          global par_reu\n",
        "          par_reu += 1\n",
        "      if 'B-PES_AUTOR' in pessoasEncontradas and 'B-END_AUTOR' in enderecosEncontrados:\n",
        "          global par_autor\n",
        "          par_autor += 1\n",
        "      if 'B-PES_TESTEMUNHA' in pessoasEncontradas and 'B-END_TESTEMUNHA' in enderecosEncontrados:\n",
        "          global par_testemunha\n",
        "          par_testemunha += 1\n",
        "      '''\n",
        "    return tokenized_limite_sentenca, labels_limite_sentenca, list_max_context\n",
        "\n",
        "def flat_accuracy(valid_tags, pred_tags):\n",
        "    return (np.array(valid_tags) == np.array(pred_tags)).mean()\n",
        "\n",
        "\n",
        "def annot_confusion_matrix(valid_tags, pred_tags):\n",
        "    # Create header from unique tags\n",
        "    header = sorted(list(set(valid_tags + pred_tags)))\n",
        "\n",
        "    # Calculate the actual confusion matrix\n",
        "    matrix = confusion_matrix(valid_tags, pred_tags, labels=header)\n",
        "\n",
        "    # Final formatting touches for the string output\n",
        "    mat_formatted = [header[i] + \"\\t\" + str(row) for i, row in enumerate(matrix)]\n",
        "    content = \"\\t\" + \" \".join(header) + \"\\n\" + \"\\n\".join(mat_formatted)\n",
        "\n",
        "    return content\n",
        "\n",
        "\n",
        "def get_special_tokens(tokenizer, tag2idx):\n",
        "\n",
        "    pad_tok = tokenizer.vocab[\"[PAD]\"]\n",
        "    sep_tok = tokenizer.vocab[\"[SEP]\"]\n",
        "    cls_tok = tokenizer.vocab[\"[CLS]\"]\n",
        "    o_lab = tag2idx[\"O\"]\n",
        "\n",
        "    return pad_tok, sep_tok, cls_tok, o_lab\n",
        "\n",
        "\n",
        "def load_and_prepare_data(train_data_path, dev_data_path, tokenizer, max_len, slide_length, batch_size, tag2idx):\n",
        "    getter_train = SentenceGetter(train_data_path, tag2idx)\n",
        "    getter_dev = SentenceGetter(dev_data_path, tag2idx)\n",
        "\n",
        "    global par_vitima, par_reu, par_autor, par_testemunha\n",
        "    par_vitima, par_reu, par_autor, par_testemunha = 0, 0, 0, 0\n",
        "    train = BertDataset(getter_train, tokenizer, max_len, slide_length, tag2idx)\n",
        "    par_vitima, par_reu, par_autor, par_testemunha = 0, 0, 0, 0\n",
        "    dev = BertDataset(getter_dev, tokenizer, max_len, slide_length, tag2idx)\n",
        "\n",
        "    # Input IDs (tokens), tags (label IDs), attention masks\n",
        "    tr_inputs = torch.tensor(train.input_ids)\n",
        "    val_inputs = torch.tensor(dev.input_ids)\n",
        "    print('tr', len(tr_inputs))\n",
        "    print('val', len(val_inputs))\n",
        "\n",
        "    tr_tags = torch.tensor(train.tags)\n",
        "    val_tags = torch.tensor(dev.tags)\n",
        "    tr_masks = torch.tensor(train.attn_masks)\n",
        "    val_masks = torch.tensor(dev.attn_masks)\n",
        "    if slide_length > 0:\n",
        "      tr_context = torch.tensor(train.max_context)\n",
        "      val_context = torch.tensor(dev.max_context)\n",
        "      train_data = TensorDataset(tr_inputs, tr_masks, tr_tags, tr_context)\n",
        "      valid_data = TensorDataset(val_inputs, val_masks, val_tags, val_context)\n",
        "    else:\n",
        "      train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "      valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "\n",
        "    train_sampler = SequentialSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    valid_sampler = SequentialSampler(valid_data)\n",
        "    valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, valid_dataloader\n",
        "\n",
        "def matrix_confusion_class(labels, preds):\n",
        "      labels_true_cm, labels_pred_cm = [], []\n",
        "      for l in labels:\n",
        "        labels_true_cm.extend(l)\n",
        "\n",
        "      for l in preds:\n",
        "        labels_pred_cm.extend(l)\n",
        "\n",
        "      header = sorted(list(set(labels_true_cm + labels_pred_cm)))\n",
        "      matrix = confusion_matrix(labels_true_cm, labels_pred_cm, labels=header)\n",
        "      #print(header)\n",
        "      #print(matrix)\n",
        "      return str(header) + '\\n' + str(matrix)\n",
        "\n",
        "def cria_arquivos_log(epoch):\n",
        "  path_arquivo_log = path_geral + \"/output_sem_slide_window/log_legalbertpt_epoch\" + str(epoch) + \".txt\"\n",
        "  path_arquivo_log2 = path_geral + \"/output_sem_slide_window/log2_legalbertpt_epoch\" + str(epoch) + \".txt\"\n",
        "  path_arquivo_log3 = path_geral + \"/output_sem_slide_window/log3_legalbertpt_epoch\" + str(epoch) + \".txt\"\n",
        "  path_arquivo_log4 = path_geral + \"/output_sem_slide_window/log4_legalbertpt_epoch\" + str(epoch) + \".txt\"\n",
        "  path_arquivo_log5 = path_geral + \"/output_sem_slide_window/log5_legalbertpt_epoch\" + str(epoch) + \".txt\"\n",
        "  path_arquivo_log2_treino = path_geral + \"/output_sem_slide_window/log2_treino_legalbertpt_epoch\" + str(epoch) + \".txt\"\n",
        "\n",
        "  if os.path.isfile(path_arquivo_log):\n",
        "    os.remove(path_arquivo_log)\n",
        "  arquivo_log = open(path_arquivo_log, \"a\")\n",
        "\n",
        "  if os.path.isfile(path_arquivo_log2):\n",
        "    os.remove(path_arquivo_log2)\n",
        "  arquivo_log2 = open(path_arquivo_log2, \"a\")\n",
        "\n",
        "  if os.path.isfile(path_arquivo_log2_treino):\n",
        "    os.remove(path_arquivo_log2_treino)\n",
        "  arquivo_log2_treino = open(path_arquivo_log2_treino, \"a\")\n",
        "\n",
        "  if os.path.isfile(path_arquivo_log3):\n",
        "    os.remove(path_arquivo_log3)\n",
        "  arquivo_log3 = open(path_arquivo_log3, \"a\")\n",
        "\n",
        "  if os.path.isfile(path_arquivo_log4):\n",
        "    os.remove(path_arquivo_log4)\n",
        "  arquivo_log4 = open(path_arquivo_log4, \"a\")\n",
        "\n",
        "  if os.path.isfile(path_arquivo_log5):\n",
        "    os.remove(path_arquivo_log5)\n",
        "  arquivo_log5 = open(path_arquivo_log5, \"a\")\n",
        "\n",
        "  return arquivo_log, arquivo_log2, arquivo_log2_treino, arquivo_log3, arquivo_log4, arquivo_log5\n",
        "\n",
        "def ajustaPredsTokenInicial(pred_tags, wordpieces):\n",
        "  i = 0\n",
        "  for token, pred in list(zip(wordpieces, pred_tags)):\n",
        "    if token.startswith('##') and pred.startswith('I-') and \\\n",
        "       i > 0 and not wordpieces[i-1].startswith('##') and pred_tags[i-1] == 'O':\n",
        "       pred_tags[i-1] = 'B-' + pred[2:]\n",
        "    i += 1\n",
        "  return pred_tags\n",
        "\n",
        "def armazenaLog(arquivo_log, str_rep, toplevel_labels, toplevel_preds):\n",
        "  #Armazena no arquivo de log\n",
        "  lines = []\n",
        "  lines.append('-----------------------------\\n')\n",
        "  lines.append(str(len(str_rep)) + ' ' + ' ' + str(len(toplevel_labels)) + ' ' + str(len(toplevel_preds)) + '\\n')\n",
        "\n",
        "  for index in range(len(toplevel_labels)):\n",
        "    try:\n",
        "      erro = ''\n",
        "      if toplevel_labels[index] != toplevel_preds[index]:\n",
        "        erro = '*'\n",
        "      lines.append(str(str_rep[index]) + '\\t' + str(toplevel_labels[index])  + '\\t' + str(toplevel_preds[index]) + '\\t' + str(erro) + '\\n')\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "  arquivo_log.writelines(lines)\n",
        "\n",
        "def train_and_save_model(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    optimizer,\n",
        "    verbose,\n",
        "    epochs,\n",
        "    idx2tag,\n",
        "    tag2idx,\n",
        "    path_output_model,\n",
        "    device,\n",
        "    train_dataloader,\n",
        "    valid_dataloader,\n",
        "):\n",
        "    pad_tok, sep_tok, cls_tok, o_lab = get_special_tokens(tokenizer, tag2idx)\n",
        "    verbose = verbose\n",
        "    epochs = epochs\n",
        "\n",
        "    epoch = 0\n",
        "    model.to(device)\n",
        "\n",
        "    melhor_f1, melhor_epoca = 0, 0\n",
        "\n",
        "    for _ in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "        epoch += 1\n",
        "\n",
        "        log, log2, log2_treino, log3, log4, log5 = cria_arquivos_log(epoch)\n",
        "\n",
        "        # Training loop\n",
        "        print(\"Starting training loop.\")\n",
        "        model.train()\n",
        "        tr_loss, tr_accuracy = 0, 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "        tr_preds, tr_labels = [], []\n",
        "\n",
        "        #progress_bar = tqdm.tqdm(train_dataloader, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "        #for batch in progress_bar:\n",
        "        ids_treino = []\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            #try:\n",
        "            # Add batch to gpu\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            if slide_length == 0:\n",
        "              b_input_ids, b_input_mask, b_labels = batch\n",
        "            else:\n",
        "              b_input_ids, b_input_mask, b_labels, b_context = batch\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask,\n",
        "                labels=b_labels,\n",
        "            )\n",
        "            loss, tr_logits = outputs[:2]\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Compute train loss\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_examples += b_input_ids.size(0)\n",
        "            nb_tr_steps += 1\n",
        "\n",
        "            # Subset out unwanted predictions on CLS/PAD/SEP tokens\n",
        "            if slide_length == 0:\n",
        "              preds_mask = ((b_input_ids != cls_tok) & (b_input_ids != pad_tok) & (b_input_ids != sep_tok))\n",
        "            else:\n",
        "              preds_mask = ((b_input_ids != cls_tok) & (b_input_ids != pad_tok) & (b_input_ids != sep_tok) & (b_context == 1))\n",
        "            tr_logits = tr_logits.detach().cpu().numpy()\n",
        "            tr_label_ids = torch.masked_select(b_labels, (preds_mask == 1))\n",
        "\n",
        "            if len(tr_logits) == 1:\n",
        "              tr_batch_preds = np.argmax(tr_logits[0][preds_mask.cpu().squeeze()], axis=1)\n",
        "            else:\n",
        "              tr_batch_preds = np.argmax(tr_logits[preds_mask.cpu().squeeze()], axis=1)\n",
        "\n",
        "            #tr_batch_preds = np.argmax(tr_logits[preds_mask.cpu().squeeze()], axis=1)\n",
        "            tr_batch_labels = tr_label_ids.cpu().numpy()\n",
        "            tr_preds.extend(tr_batch_preds)\n",
        "            tr_labels.extend(tr_batch_labels)\n",
        "            aux_ids_treino = torch.masked_select(b_input_ids, (preds_mask == 1))\n",
        "            ids_treino.extend(aux_ids_treino.cpu().numpy())\n",
        "\n",
        "            # Compute training accuracy\n",
        "            tmp_tr_accuracy = flat_accuracy(tr_batch_labels, tr_batch_preds)\n",
        "            tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Update parameters\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            model.zero_grad()\n",
        "\n",
        "        tr_loss = tr_loss / nb_tr_steps\n",
        "        tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "\n",
        "        # Print training loss and accuracy per epoch\n",
        "        print(f\"Train loss: {tr_loss}\")\n",
        "        print(f\"Train accuracy: {tr_accuracy}\")\n",
        "\n",
        "        # Report metrics\n",
        "        # Evaluate loss, acc, conf. matrix, and class. report on devset\n",
        "        pred_tags = [[idx2tag[i] for i in tr_preds]]\n",
        "        valid_tags = [[idx2tag[i] for i in tr_labels]]\n",
        "\n",
        "        #Concatena os tokens gerados pelo WordPiece\n",
        "        wordpieces = tokenizer.convert_ids_to_tokens(ids_treino)\n",
        "\n",
        "        #Resultado com ajuste de transição inválida de entidade\n",
        "        preds = pred_tags[0].copy()\n",
        "        wp_preds = list(zip(wordpieces, preds))\n",
        "        wp_labels = list(zip(wordpieces, valid_tags[0].copy()))\n",
        "\n",
        "        str_rep = \" \".join([t[0] for t in wp_preds]).replace(\" ##\", \"\").split()\n",
        "        toplevel_preds = [pair[1] for pair in wp_preds if \"##\" not in pair[0]]\n",
        "        toplevel_labels = [pair[1] for pair in wp_labels if \"##\" not in pair[0]]\n",
        "\n",
        "        toplevel_preds = ajusta_transicao_entidades_new(toplevel_preds, wordpieces)\n",
        "\n",
        "        #Armazena no arquivo de log\n",
        "        armazenaLog(log2_treino, str_rep, toplevel_labels, toplevel_preds)\n",
        "\n",
        "        cl_report_toplevel = classification_report([toplevel_labels], [toplevel_preds])\n",
        "        log2_treino.writelines(cl_report_toplevel)\n",
        "        log2_treino.writelines(str(matrix_confusion_class([toplevel_labels], [toplevel_preds])))\n",
        "\n",
        "        #Exibe resultado com ajuste de transição a nível de entidade\n",
        "        cr_level_entity, cm_level_entity = level_entity_new(toplevel_labels, toplevel_preds)\n",
        "        log2_treino.writelines(cr_level_entity)\n",
        "        log2_treino.writelines(str(cm_level_entity))\n",
        "\n",
        "        # Validation loop\n",
        "        print(\"Starting validation loop.\")\n",
        "\n",
        "        model.eval()\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "        predictions, true_labels = [], []\n",
        "        predictions_contexto, true_labels_contexto = [], []\n",
        "\n",
        "        ids = []\n",
        "        ids_contexto = []\n",
        "\n",
        "        for batch in valid_dataloader:\n",
        "\n",
        "            #try:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            if slide_length == 0:\n",
        "              b_input_ids, b_input_mask, b_labels = batch\n",
        "            else:\n",
        "              b_input_ids, b_input_mask, b_labels, b_context = batch\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(\n",
        "                    b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels,\n",
        "                )\n",
        "                tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "            #print('ids', b_input_ids)\n",
        "\n",
        "            # Subset out unwanted predictions on CLS/PAD/SEP tokens\n",
        "            if slide_length == 0:\n",
        "              preds_mask = ((b_input_ids != cls_tok) & (b_input_ids != pad_tok) & (b_input_ids != sep_tok))\n",
        "            else:\n",
        "              preds_mask = ((b_input_ids != cls_tok) & (b_input_ids != pad_tok) & (b_input_ids != sep_tok) & (b_context == 1))\n",
        "              preds_mask_contexto = ((b_input_ids != cls_tok) & (b_input_ids != pad_tok) & (b_input_ids != sep_tok))\n",
        "\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = torch.masked_select(b_labels, (preds_mask == 1))\n",
        "            label_ids_contexto = torch.masked_select(b_labels, (preds_mask_contexto == 1))\n",
        "            #print('logits:', logits)\n",
        "            if len(logits) == 1:\n",
        "              val_batch_preds = np.argmax(logits[0][preds_mask.cpu().squeeze()], axis=1)\n",
        "              val_batch_preds_contexto = np.argmax(logits[0][preds_mask_contexto.cpu().squeeze()], axis=1)\n",
        "            else:\n",
        "              val_batch_preds = np.argmax(logits[preds_mask.cpu().squeeze()], axis=1)\n",
        "              val_batch_preds_contexto = np.argmax(logits[preds_mask_contexto.cpu().squeeze()], axis=1)\n",
        "\n",
        "            val_batch_labels = label_ids.cpu().numpy()\n",
        "            val_batch_labels_contexto = label_ids_contexto.cpu().numpy()\n",
        "            #print('val_batch_preds:', val_batch_preds)\n",
        "            #val_batch_labels = label_ids.to(\"cpu\").numpy()\n",
        "            predictions.extend(val_batch_preds)\n",
        "            true_labels.extend(val_batch_labels)\n",
        "\n",
        "            predictions_contexto.extend(val_batch_preds_contexto)\n",
        "            true_labels_contexto.extend(val_batch_labels_contexto)\n",
        "\n",
        "            aux_ids = torch.masked_select(b_input_ids, (preds_mask == 1))\n",
        "            ids.extend(aux_ids.cpu().numpy())\n",
        "\n",
        "            ids_contexto.extend(torch.masked_select(b_input_ids, (preds_mask_contexto == 1)).cpu().numpy())\n",
        "\n",
        "            exibe_dados(b_input_ids, preds_mask, b_labels, val_batch_labels, val_batch_preds, log)\n",
        "\n",
        "            tmp_eval_accuracy = flat_accuracy(val_batch_labels, val_batch_preds)\n",
        "\n",
        "            eval_loss += tmp_eval_loss.mean().item()\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "            nb_eval_examples += b_input_ids.size(0)\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "        # Evaluate loss, acc, conf. matrix, and class. report on devset\n",
        "        pred_tags = [[idx2tag[i] for i in predictions]]\n",
        "        valid_tags = [[idx2tag[i] for i in true_labels]]\n",
        "\n",
        "        #Concatena os tokens gerados pelo WordPiece\n",
        "        wordpieces = tokenizer.convert_ids_to_tokens(ids)\n",
        "\n",
        "        #pred_tags = ajustaPredsTokenInicial(pred_tags, wordpieces)\n",
        "\n",
        "        #Métricas com as predições originais\n",
        "        cl_report = classification_report(valid_tags, pred_tags)\n",
        "        log.writelines(cl_report)\n",
        "        log.writelines(str(matrix_confusion_class(valid_tags, pred_tags)))\n",
        "\n",
        "        eval_loss = eval_loss / nb_eval_steps\n",
        "        eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "\n",
        "        #print(f\"Validation loss: {eval_loss}\")\n",
        "        #print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "        #print(f\"Classification Report:\\n {cl_report}\")\n",
        "        #print(matrix_confusion_class(valid_tags, pred_tags))\n",
        "\n",
        "        #Armazena log sem retirar a janela de contexto\n",
        "        wordpieces_contexto = tokenizer.convert_ids_to_tokens(ids_contexto)\n",
        "        pred_tags_contexto = [[idx2tag[i] for i in predictions_contexto]]\n",
        "        valid_tags_contexto = [[idx2tag[i] for i in true_labels_contexto]]\n",
        "\n",
        "        wp_preds_contexto = list(zip(wordpieces_contexto, pred_tags_contexto))\n",
        "        wp_labels_contexto = list(zip(wordpieces_contexto, valid_tags_contexto[0].copy()))\n",
        "\n",
        "        #str_rep = \" \".join([t[0] for t in wp_preds_contexto]).replace(\" ##\", \"\").split()\n",
        "        #toplevel_preds = [pair[1] for pair in wp_preds_contexto if \"##\" not in pair[0]]\n",
        "        #toplevel_labels = [pair[1] for pair in wp_labels_contexto if \"##\" not in pair[0]]\n",
        "        str_rep = [t[0] for t in wp_preds_contexto]\n",
        "        toplevel_preds = [pair[1] for pair in wp_preds_contexto]\n",
        "        toplevel_labels = [pair[1] for pair in wp_labels_contexto]\n",
        "        print('log5:', len(wordpieces_contexto), len(toplevel_labels), len(toplevel_preds[0]))\n",
        "        armazenaLog(log5, wordpieces_contexto, toplevel_labels, toplevel_preds[0])\n",
        "\n",
        "        #Métricas com as predições retirando os subtokens que iniciam com ##\n",
        "        preds = pred_tags[0].copy()\n",
        "        wp_preds = list(zip(wordpieces, preds))\n",
        "        wp_labels = list(zip(wordpieces, valid_tags[0].copy()))\n",
        "\n",
        "        str_rep = \" \".join([t[0] for t in wp_preds]).replace(\" ##\", \"\").split()\n",
        "        toplevel_preds = [pair[1] for pair in wp_preds if \"##\" not in pair[0]]\n",
        "        toplevel_labels = [pair[1] for pair in wp_labels if \"##\" not in pair[0]]\n",
        "\n",
        "        cl_report_toplevel = classification_report([toplevel_labels], [toplevel_preds])\n",
        "        #print(f\"Classification Report Top Level:\\n {cl_report_toplevel}\")\n",
        "        #print(matrix_confusion_class([toplevel_labels], [toplevel_preds]))\n",
        "\n",
        "        #Resultado a nível de entidade sem transição de entidade\n",
        "        cr_level_entity, cm_level_entity = level_entity_new(toplevel_labels, toplevel_preds)\n",
        "        #print(f\"Classification Report Level Entity (Sem transição de entidades):\\n {cr_level_entity}\")\n",
        "        #print(cm_level_entity)\n",
        "\n",
        "        #Resultado com ajuste de transição inválida de entidade\n",
        "        preds = pred_tags[0].copy()\n",
        "        wp_preds = list(zip(wordpieces, preds))\n",
        "        wp_labels = list(zip(wordpieces, valid_tags[0].copy()))\n",
        "\n",
        "        str_rep = \" \".join([t[0] for t in wp_preds]).replace(\" ##\", \"\").split()\n",
        "        toplevel_preds = [pair[1] for pair in wp_preds if \"##\" not in pair[0]]\n",
        "        toplevel_labels = [pair[1] for pair in wp_labels if \"##\" not in pair[0]]\n",
        "\n",
        "        armazenaLog(log3, str_rep, toplevel_labels, toplevel_preds)\n",
        "\n",
        "        toplevel_preds = ajusta_transicao_entidades_new(toplevel_preds, wordpieces)\n",
        "\n",
        "        #Exibe resultado com ajuste de transição a nível de token\n",
        "        print('-----------------------------------------------')\n",
        "        print('Ajuste de transição inválida de entidade')\n",
        "        print('----- COMPARAÇÃO EXATA -----')\n",
        "        f1_macro = f1_score([toplevel_labels], [toplevel_preds], average='macro')\n",
        "        if f1_macro > melhor_f1:\n",
        "          melhor_f1 = f1_macro\n",
        "          melhor_epoca = epoch\n",
        "\n",
        "        cl_report_toplevel = classification_report([toplevel_labels], [toplevel_preds])\n",
        "        print(f\"Classification Report Top Level (Ajuste de transição):\\n {cl_report_toplevel}\")\n",
        "        print(matrix_confusion_class([toplevel_labels], [toplevel_preds]))\n",
        "\n",
        "        #Armazena no arquivo de log\n",
        "        armazenaLog(log2, str_rep, toplevel_labels, toplevel_preds)\n",
        "        log2.writelines(cl_report_toplevel)\n",
        "        log2.writelines(str(matrix_confusion_class([toplevel_labels], [toplevel_preds])))\n",
        "\n",
        "        #Exibe resultado com ajuste de transição a nível de entidade\n",
        "        cr_level_entity, cm_level_entity = level_entity_new(toplevel_labels, toplevel_preds)\n",
        "        log2.writelines(cr_level_entity)\n",
        "        log2.writelines(str(cm_level_entity))\n",
        "        print('----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----')\n",
        "        print(f\"Classification Report Level Entity:\\n {cr_level_entity}\")\n",
        "        print(cm_level_entity)\n",
        "\n",
        "        #Resultado com ajuste de transição inválida de entidade para O\n",
        "        preds = pred_tags[0].copy()\n",
        "        wp_preds = list(zip(wordpieces, preds))\n",
        "        wp_labels = list(zip(wordpieces, valid_tags[0].copy()))\n",
        "\n",
        "        str_rep = \" \".join([t[0] for t in wp_preds]).replace(\" ##\", \"\").split()\n",
        "        toplevel_preds = [pair[1] for pair in wp_preds if \"##\" not in pair[0]]\n",
        "        toplevel_labels = [pair[1] for pair in wp_labels if \"##\" not in pair[0]]\n",
        "\n",
        "        toplevel_preds = ajusta_transicao_entidades_O(toplevel_preds, wordpieces)\n",
        "\n",
        "        armazenaLog(log4, str_rep, toplevel_labels, toplevel_preds)\n",
        "\n",
        "        #outros tipos de métrica: exact partial\n",
        "        #print('STRICT:')\n",
        "        #print('preds:', wp_preds)\n",
        "        #calculateMetrics(wp_preds, wp_labels, 'strict')\n",
        "\n",
        "        #print('TYPE:')\n",
        "        #calculateMetrics(wp_preds, wp_labels, 'type')\n",
        "\n",
        "        #Exibe resultado a nível de entidade\n",
        "        print('-----------------------------------------------')\n",
        "        print('Ajuste de transição inválida de entidade para O')\n",
        "        print('----- COMPARAÇÃO EXATA -----')\n",
        "        cl_report_toplevel = classification_report([toplevel_labels], [toplevel_preds])\n",
        "        print(f\"Classification Report Top Level (Transição de entidades O):\\n {cl_report_toplevel}\")\n",
        "        print(matrix_confusion_class([toplevel_labels], [toplevel_preds]))\n",
        "\n",
        "        print('----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----')\n",
        "        cr_level_entity, cm_level_entity = level_entity_new(toplevel_labels, toplevel_preds)\n",
        "        print(f\"Classification Report Level Entity (Transição de entidades O):\\n {cr_level_entity}\")\n",
        "        print(cm_level_entity)\n",
        "        log4.writelines(cr_level_entity)\n",
        "        log4.writelines(str(cm_level_entity))\n",
        "        #if verbose:\n",
        "        #print(confusion_matrix(valid_tags, pred_tags))#, labels=header))\n",
        "        #print(f\"Confusion Matrix:\\n {conf_mat}\")\n",
        "\n",
        "        #matrix_confusion_class(valid_tags, pred_tags)\n",
        "\n",
        "        # Save model and optimizer state_dict following every epoch\n",
        "        #torch.save(model.state_dict(), path_output_model + '/fine_tuning_lener/' + f'/finetuned_BERT_epoch_{epoch}.tar')\n",
        "        torch.save(model.state_dict(), f'{path_geral}/output_sem_slide_window/fine_tuning_ner/finetuned_legalbertpt_epoch_{epoch}.tar')\n",
        "        #torch.save(model.state_dict(), f'/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_{entidade}/output_sem_slide_window/fine_tuning_ner/finetuned_legalbertpt_epoch_{epoch}.tar')\n",
        "        #torch.save(model.state_dict(), '/content/drive/MyDrive/Unifor/NER/cdjur/output_ner/fine_tuning_ner/' + entidade + f'finetuned_legalbertpt_epoch_{epoch}.tar')\n",
        "        #torch.save(model.state_dict(), '/content/drive/MyDrive/Unifor/NER/cdjur/output_ner/fine_tuning_ner/' + entidade + f'finetuned_legalbertpt_epoch_{epoch}.tar')\n",
        "        '''\n",
        "            {\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"train_loss\": tr_loss,\n",
        "                \"train_acc\": tr_accuracy,\n",
        "                \"eval_loss\": eval_loss,\n",
        "                \"eval_acc\": eval_accuracy,\n",
        "                \"classification_report\": cl_report,\n",
        "                \"confusion_matrix\": conf_mat,\n",
        "            },\n",
        "            ,\n",
        "            model\n",
        "            save_path,\n",
        "        )\n",
        "        '''\n",
        "    print(f'Melhor f1:{melhor_f1}\\nMelhor época:{melhor_epoca}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slaA_rlwwcoB"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "def ajusta_transicao_entidades_new(toplevel_preds, str_rep):\n",
        "\n",
        "  for id, pred in enumerate(toplevel_preds):\n",
        "    if pred.startswith('I-'):\n",
        "      #Troca para B- se a primeira entidade iniciar com I-\n",
        "      if id == 0:\n",
        "        toplevel_preds[id] = 'B-' + pred[2:]\n",
        "\n",
        "      #Transição O I\n",
        "      if toplevel_preds[id-1] == 'O':\n",
        "          encontrouAnterior = False\n",
        "          #print(id-1, id-3)\n",
        "          for id_ant in range(id-1, id-5, -1): #Janela: 3\n",
        "            if id_ant == -1:\n",
        "              break\n",
        "            if toplevel_preds[id_ant] != 'O':\n",
        "              if toplevel_preds[id_ant][2:] == pred[2:]:\n",
        "                for i in range(id_ant+1, id-1+1):\n",
        "                  toplevel_preds[i] = 'I-' + pred[2:]\n",
        "                encontrouAnterior = True\n",
        "                break\n",
        "          if not encontrouAnterior:\n",
        "            toplevel_preds[id] = 'B-' + pred[2:]\n",
        "\n",
        "      #Transição I-A I-B ou B-A I-B\n",
        "      elif toplevel_preds[id-1][2:] != pred[2:]: #ant inicia com B- ou I- e entidades são diferentes\n",
        "        #verifica se a categoria das entidades ant e atual são diferentes\n",
        "        if toplevel_preds[id-1][2:5] != pred[2:5]:\n",
        "          toplevel_preds[id] = 'B-' + pred[2:]\n",
        "        else:\n",
        "          id_comeco, id_termina = 0, len(toplevel_preds)-1\n",
        "          #obtém o id onde começa a entidade\n",
        "          for id_ant in range(id-1, 0, -1):\n",
        "            if toplevel_preds[id_ant].startswith('B-'):\n",
        "              id_comeco = id_ant\n",
        "              break\n",
        "\n",
        "          #obtém o id onde termina a entidade\n",
        "          for id_prox in range(id+1, len(toplevel_preds), 1):\n",
        "            if not toplevel_preds[id_prox].startswith('I-'):\n",
        "              id_termina = id_prox-1\n",
        "              break\n",
        "\n",
        "          #Obtém a entidade de maior ocorrência\n",
        "          ents = [toplevel_preds[i][2:] for i in range(id_comeco, id_termina+1, 1)]\n",
        "          d = {}\n",
        "          for e in ents:\n",
        "            d[e] = d.get(e, 0) + 1\n",
        "          d = sorted(d, key = d.get, reverse=True) #ordena a qtde de ocorrências de forma decrescente\n",
        "          ent_selecionada = d[0] #obtém a entidade que mais ocorre\n",
        "\n",
        "          #ajusta as entidades\n",
        "          toplevel_preds[id_comeco] = 'B-' + ent_selecionada\n",
        "          for i in range(id_comeco+1, id_termina+1):\n",
        "            toplevel_preds[i] = 'I-' + ent_selecionada\n",
        "\n",
        "\n",
        "\n",
        "    #Verifica se uma entidade (por completo) está associada a um único caracter ou se for uma Norma está associada a uma única palavra\n",
        "    if pred.startswith('B') and \\\n",
        "      (id == len(toplevel_preds)-1 or toplevel_preds[id+1] == 'O' or toplevel_preds[id+1].startswith('B-')) and \\\n",
        "      len(str_rep[id]) == 1:\n",
        "      toplevel_preds[id] = 'O'\n",
        "  return toplevel_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2RtOf8awcoB"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "def ajusta_transicao_entidades(toplevel_preds, str_rep):\n",
        "\n",
        "  for id, pred in enumerate(toplevel_preds):\n",
        "     if pred.startswith('I-'):\n",
        "      if id == 0:\n",
        "        toplevel_preds[id] = 'B-' + pred[2:]\n",
        "\n",
        "      #Transição I-A I-B ou B-A I-B\n",
        "      if not toplevel_preds[id-1] == 'O' and toplevel_preds[id-1][2:] != pred[2:]:\n",
        "        if id+1 > len(toplevel_preds) and (not toplevel_preds[id+1].startswith('I-') or \\\n",
        "           (toplevel_preds[id+1].startswith('I-') and toplevel_preds[id+1][2:] == toplevel_preds[id-1][2:])):\n",
        "          toplevel_preds[id] = 'I-' + toplevel_preds[id-1][2:]\n",
        "        elif toplevel_preds[id+1].startswith('I-') and toplevel_preds[id+1] == pred:\n",
        "          toplevel_preds[id] = 'B-' + pred[2:]\n",
        "\n",
        "      #Transição O I\n",
        "      if toplevel_preds[id-1] == 'O':\n",
        "          encontrouAnterior = False\n",
        "          #print(id-1, id-3)\n",
        "          for id_ant in range(id-1, id-5, -1): #Janela: 3\n",
        "            if id_ant == -1:\n",
        "              break\n",
        "            if toplevel_preds[id_ant] != 'O':\n",
        "              if toplevel_preds[id_ant][2:] == pred[2:]:\n",
        "                for i in range(id_ant+1, id-1+1):\n",
        "                  toplevel_preds[i] = 'I-' + pred[2:]\n",
        "                encontrouAnterior = True\n",
        "                break\n",
        "          if not encontrouAnterior:\n",
        "            toplevel_preds[id] = 'B-' + pred[2:]\n",
        "\n",
        "     #Verifica se uma entidade (por completo) está associada a um único caracter ou se for uma Norma está associada a uma única palavra\n",
        "     #print(pred)\n",
        "     #print(len(pred))\n",
        "     #print(pred)\n",
        "     #print(pred.startswith('B'))\n",
        "     #print(id == len(toplevel_preds)-1)\n",
        "     #print(toplevel_preds[id+1] == 'O')\n",
        "     #print(toplevel_preds[id+1].startswith('B-'))\n",
        "     #print(len(str_rep[id]) <= 2)\n",
        "     #print(pred[2:].startswith('NOR'))\n",
        "     if pred.startswith('B') and \\\n",
        "      (id == len(toplevel_preds)-1 or toplevel_preds[id+1] == 'O' or toplevel_preds[id+1].startswith('B-')) and \\\n",
        "      len(str_rep[id]) == 1:\n",
        "      #(len(str_rep[id]) <= 2 or pred[2:].startswith('NOR')):\n",
        "      #(len(str_rep[id]) == 1 or pred[2:].startswith('NOR')):# str_rep[id].lower() == 'artigo'):\n",
        "      toplevel_preds[id] = 'O'\n",
        "  return toplevel_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dttjg_0cwcoB"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "def ajusta_transicao_entidades_O(toplevel_preds, str_rep):\n",
        "\n",
        "  for id, pred in enumerate(toplevel_preds):\n",
        "     if pred.startswith('I-'):\n",
        "      if id == 0:\n",
        "        toplevel_preds[id] = 'O'\n",
        "\n",
        "      #Transição I-A I-B ou B-A I-B\n",
        "      if not toplevel_preds[id-1] == 'O' and toplevel_preds[id-1][2:] != pred[2:]:\n",
        "        if not toplevel_preds[id+1].startswith('I-') or \\\n",
        "           (toplevel_preds[id+1].startswith('I-') and toplevel_preds[id+1][2:] == toplevel_preds[id-1][2:]):\n",
        "          toplevel_preds[id] = 'O'\n",
        "        elif toplevel_preds[id+1].startswith('I-') and toplevel_preds[id+1] == pred:\n",
        "          toplevel_preds[id] = 'O'\n",
        "\n",
        "      #Transição O I\n",
        "      if toplevel_preds[id-1] == 'O':\n",
        "          toplevel_preds[id] = 'O'\n",
        "\n",
        "     #Verifica se uma entidade (por completo) está associada a um único caracter\n",
        "     #print(pred)\n",
        "     #print(len(pred))\n",
        "     if pred.startswith('B') and \\\n",
        "      (id == len(toplevel_preds)-1 or toplevel_preds[id+1] == 'O' or toplevel_preds[id+1].startswith('B-')) and \\\n",
        "      len(str_rep[id]) == 1:\n",
        "      #(len(str_rep[id]) <= 2 or pred[2:].startswith('NOR')):\n",
        "      toplevel_preds[id] = 'O'\n",
        "  return toplevel_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDON8B3bwcoC"
      },
      "outputs": [],
      "source": [
        "def exibe_dados(b_input_ids, preds_mask, b_labels, tr_labels, tr_preds, arquivo):\n",
        "\n",
        "  aux = []\n",
        "  for index_sentence in range(len(b_input_ids)):\n",
        "    for index_token in range(len(b_input_ids[index_sentence])):\n",
        "      if preds_mask[index_sentence][index_token]:\n",
        "        aux.append(b_input_ids[index_sentence][index_token])\n",
        "\n",
        "  ids = tokenizer.convert_ids_to_tokens(aux)\n",
        "  labels_tag = [idx2tag[l] for l in tr_labels]\n",
        "  preds_tag = [idx2tag[l] for l in tr_preds]\n",
        "\n",
        "  lines = []\n",
        "  lines.append('-----------------------------\\n')\n",
        "  lines.append(str(len(labels_tag)) + ' ' + ' ' + str(len(ids)) + ' ' + str(len(preds_tag)) + '\\n')\n",
        "  for index in range(len(labels_tag)):\n",
        "    erro = ''\n",
        "    if labels_tag[index] != preds_tag[index]:\n",
        "      erro = '*'\n",
        "    lines.append(ids[index] + '\\t' + labels_tag[index]  + '\\t' + preds_tag[index] + '\\t' + erro + '\\n')\n",
        "\n",
        "  arquivo.writelines(lines)\n",
        "  #print(classification_report([labels_tag], [preds_tag]))\n",
        "  #print(matrix_confusion_class([labels_tag], [preds_tag]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Treino"
      ],
      "metadata": {
        "id": "UClGOiefwM8i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc8_Wza-wa1R",
        "outputId": "2a9c01c7-44be-434e-e49d-2d49a4a0a0b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treino\n",
            "1325555\n",
            "validação\n",
            "381229\n",
            "teste\n",
            "355227\n"
          ]
        }
      ],
      "source": [
        "#CDJur\n",
        "entidade = 'exp1'\n",
        "\n",
        "# path_cdjur_train = '/content/drive/MyDrive/Unifor/NER/cdjur_' + entidade + '/treino_' + entidade + '.conll'\n",
        "# path_cdjur_test = '/content/drive/MyDrive/Unifor/NER/cdjur_' + entidade + '/teste_' + entidade + '.conll'\n",
        "#path_geral = '/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_revisao_210922/' + entidade\n",
        "\n",
        "\n",
        "path_cdjur_train = '/content/drive/MyDrive/UNIFOR/NER/CDJur/lener/train.txt'\n",
        "path_cdjur_val = '/content/drive/MyDrive/UNIFOR/NER/CDJur/lener/dev.txt'\n",
        "path_cdjur_test = '/content/drive/MyDrive/UNIFOR/NER/CDJur/lener/test.txt'\n",
        "#path_cdjur_train = path_geral + '/treino.conll'\n",
        "#path_cdjur_val = path_geral + '/val.conll'\n",
        "#path_cdjur_test = path_geral + '/teste.conll'\n",
        "#path_cdjur_train = '/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_revisao_090822/lener_train_ents_cdjur_lener.conll'\n",
        "#path_cdjur_val = '/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_revisao_090822/lener_dev_ents_cdjur_lener.conll'\n",
        "\n",
        "import pandas as pd\n",
        "print('treino')\n",
        "df_data_train = pd.DataFrame(get_data(path_cdjur_train))\n",
        "print('validação')\n",
        "df_data_val = pd.DataFrame(get_data(path_cdjur_val))\n",
        "print('teste')\n",
        "df_data_test = pd.DataFrame(get_data(path_cdjur_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "RUF9V-V2wa1S",
        "outputId": "9fcdb021-7170-40b4-887b-8641c45c8d2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        sentence_idx                                               word tag\n",
              "0                  0                                              PODER   O\n",
              "1                  0                                         JUDICIÁRIO   O\n",
              "2                  0                                                 DO   O\n",
              "3                  0                                             ESTADO   O\n",
              "4                  0                                                 DO   O\n",
              "...              ...                                                ...  ..\n",
              "355222             0                                              estes   O\n",
              "355223             0                                             autos,   O\n",
              "355224             0                                            Direto.   O\n",
              "355225             0                                           cretaria   O\n",
              "355226             0  ==============================FIM=============...   O\n",
              "\n",
              "[355227 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e00ca38-17ca-4919-86e7-45c4122b7b8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>PODER</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>JUDICIÁRIO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>DO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>ESTADO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>DO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355222</th>\n",
              "      <td>0</td>\n",
              "      <td>estes</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355223</th>\n",
              "      <td>0</td>\n",
              "      <td>autos,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355224</th>\n",
              "      <td>0</td>\n",
              "      <td>Direto.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355225</th>\n",
              "      <td>0</td>\n",
              "      <td>cretaria</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355226</th>\n",
              "      <td>0</td>\n",
              "      <td>==============================FIM=============...</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>355227 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e00ca38-17ca-4919-86e7-45c4122b7b8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e00ca38-17ca-4919-86e7-45c4122b7b8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e00ca38-17ca-4919-86e7-45c4122b7b8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df_data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Lm1kbORwa1S"
      },
      "outputs": [],
      "source": [
        "tags_vals = list(set(df_data_train[\"tag\"].values))\n",
        "tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
        "idx2tag = {idx: tags_vals[idx] for idx in range(0, len(tags_vals))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3YlWsCKwa1S"
      },
      "outputs": [],
      "source": [
        "def add_tag(tag):\n",
        "  indice = len(tag2idx)\n",
        "  tag2idx[tag] = indice\n",
        "  idx2tag[indice] = tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4WZw49Jwa1S",
        "outputId": "95775386-e2d1-4216-e320-49a7e29f2149"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(tag2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCqSnJA9wa1S",
        "outputId": "d554b26b-e2da-41eb-f3d9-b37fe81299f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I-NOR_JURISPRUDÊNCIA': 0,\n",
              " 'B-PES_AUTORID_POLICIAL': 1,\n",
              " 'B-SENTENÇA': 2,\n",
              " 'B-END_AUTOR': 3,\n",
              " 'I-PES_ADVOG': 4,\n",
              " 'I-END_TESTEMUNHA': 5,\n",
              " 'B-PES_VITIMA': 6,\n",
              " 'B-PES_JUIZ': 7,\n",
              " 'I-PES_JUIZ': 8,\n",
              " 'I-END_OUTROS': 9,\n",
              " 'I-PROVA': 10,\n",
              " 'I-PES_AUTOR': 11,\n",
              " 'I-PES_TESTEMUNHA': 12,\n",
              " 'I-PES_PROMOTOR_MP': 13,\n",
              " 'B-PES_REU': 14,\n",
              " 'B-END_TESTEMUNHA': 15,\n",
              " 'O': 16,\n",
              " 'B-END_DELITO': 17,\n",
              " 'I-NOR_PRINCIPAL': 18,\n",
              " 'B-PROVA': 19,\n",
              " 'I-END_AUTOR': 20,\n",
              " 'I-END_VITIMA': 21,\n",
              " 'B-NOR_ACESSORIA': 22,\n",
              " 'B-NOR_JURISPRUDÊNCIA': 23,\n",
              " 'B-PES_TESTEMUNHA': 24,\n",
              " 'I-END_REU': 25,\n",
              " 'B-END_VITIMA': 26,\n",
              " 'I-PENA': 27,\n",
              " 'I-SENTENÇA': 28,\n",
              " 'I-END_DELITO': 29,\n",
              " 'I-PES_VITIMA': 30,\n",
              " 'I-NOR_ACESSORIA': 31,\n",
              " 'B-PES_ADVOG': 32,\n",
              " 'B-PENA': 33,\n",
              " 'B-PES_AUTOR': 34,\n",
              " 'I-PES_AUTORID_POLICIAL': 35,\n",
              " 'B-END_OUTROS': 36,\n",
              " 'I-PES_OUTROS': 37,\n",
              " 'B-NOR_PRINCIPAL': 38,\n",
              " 'B-PES_PROMOTOR_MP': 39,\n",
              " 'I-PES_REU': 40,\n",
              " 'B-END_REU': 41,\n",
              " 'B-PES_OUTROS': 42}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "tag2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct4WOK5Vwa1V"
      },
      "outputs": [],
      "source": [
        "#CDJur\n",
        "from transformers import BertTokenizer\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "#path_cdjur = '/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_' + entidade + '/'\n",
        "train_data_path = path_cdjur_train #path_cdjur + 'treino.conll' #'/content/drive/MyDrive/Unifor/NER/lener/train_atualizado.txt' #path_cdjur + '/train/labeled/train.conll'\n",
        "dev_data_path = path_cdjur_test #path_cdjur + '/teste.conll'\n",
        "max_len = 512\n",
        "slide_length = 128 #0\n",
        "batch_size = 8\n",
        "epochs = 10\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')#'cuda'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtWuSijEwa1V",
        "outputId": "38d4e83f-a7e7-48cf-985f-c31fabd22149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto: 681\n",
            "Sents_raw: 681\n",
            "Constructed SentenceGetter with 681 examples.\n",
            "Labels 681.\n",
            "Texto: 170\n",
            "Sents_raw: 170\n",
            "Constructed SentenceGetter with 170 examples.\n",
            "Labels 170.\n",
            "Quantidade de sentenças (tokens): 6395\n",
            "Quantidade de sentenças (labels): 6395\n",
            "Quantidade de sentenças (tokens): 1677\n",
            "Quantidade de sentenças (labels): 1677\n",
            "tr 6395\n",
            "val 1677\n"
          ]
        }
      ],
      "source": [
        "train_dataloader, valid_dataloader = load_and_prepare_data(train_data_path, dev_data_path, tokenizer, max_len, slide_length, batch_size, tag2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9QGr_XGwa1V",
        "outputId": "0a337c19-7ba6-473d-b6bf-bbb136ec55ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/UNIFOR/LegalBert-pt/model-scratch-v4_p1/ were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at /content/drive/MyDrive/UNIFOR/LegalBert-pt/model-scratch-v4_p1/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = BertForTokenClassification.from_pretrained('neuralmind/bert-base-portuguese-cased',\n",
        "                                                   num_labels=len(tag2idx))\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8, correct_bias=False)\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=len(train_dataloader) * epochs\n",
        ")\n",
        "verbose = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO7USsnHFI87",
        "outputId": "6845d831-4696-4921-8093-3774f5dc5647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teste2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training loop.\n",
            "Train loss: 0.4932535109319724\n",
            "Train accuracy: 0.8925398414611617\n",
            "Starting validation loop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log5: 801817 801817 801817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------\n",
            "Ajuste de transição inválida de entidade\n",
            "----- COMPARAÇÃO EXATA -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Top Level (Ajuste de transição):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.00      0.00      0.00        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.00      0.00      0.00       152\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.09      0.19      0.12       990\n",
            "  NOR_JURISPRUDÊNCIA       0.06      0.19      0.09       333\n",
            "       NOR_PRINCIPAL       0.04      0.11      0.05       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.00      0.00      0.00       122\n",
            "           PES_AUTOR       0.06      0.01      0.02       169\n",
            "PES_AUTORID_POLICIAL       0.00      0.00      0.00       300\n",
            "            PES_JUIZ       0.00      0.00      0.00        83\n",
            "          PES_OUTROS       0.00      0.00      0.00      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.12      0.31      0.17      1503\n",
            "      PES_TESTEMUNHA       0.00      0.00      0.00       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.08      0.11      0.09      7443\n",
            "           macro avg       0.02      0.04      0.02      7443\n",
            "        weighted avg       0.04      0.11      0.06      7443\n",
            "\n",
            "['B-END_AUTOR', 'B-END_DELITO', 'B-END_OUTROS', 'B-END_REU', 'B-END_TESTEMUNHA', 'B-END_VITIMA', 'B-NOR_ACESSORIA', 'B-NOR_JURISPRUDÊNCIA', 'B-NOR_PRINCIPAL', 'B-PENA', 'B-PES_ADVOG', 'B-PES_AUTOR', 'B-PES_AUTORID_POLICIAL', 'B-PES_JUIZ', 'B-PES_OUTROS', 'B-PES_PROMOTOR_MP', 'B-PES_REU', 'B-PES_TESTEMUNHA', 'B-PES_VITIMA', 'B-PROVA', 'B-SENTENÇA', 'I-END_AUTOR', 'I-END_DELITO', 'I-END_OUTROS', 'I-END_REU', 'I-END_TESTEMUNHA', 'I-END_VITIMA', 'I-NOR_ACESSORIA', 'I-NOR_JURISPRUDÊNCIA', 'I-NOR_PRINCIPAL', 'I-PENA', 'I-PES_ADVOG', 'I-PES_AUTOR', 'I-PES_AUTORID_POLICIAL', 'I-PES_JUIZ', 'I-PES_OUTROS', 'I-PES_PROMOTOR_MP', 'I-PES_REU', 'I-PES_TESTEMUNHA', 'I-PES_VITIMA', 'I-PROVA', 'I-SENTENÇA', 'O']\n",
            "[[     0      0      0 ...      0      0     16]\n",
            " [     0      0      0 ...      0      0     53]\n",
            " [     0      0      0 ...      0      0     80]\n",
            " ...\n",
            " [     0      0      0 ...      0      0   3800]\n",
            " [     0      0      0 ...      0      0    237]\n",
            " [     0      0      0 ...      0      0 469228]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----\n",
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.00      0.00      0.00        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.45      0.06      0.10       152\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.50      0.77      0.60       990\n",
            "  NOR_JURISPRUDÊNCIA       0.32      0.86      0.46       333\n",
            "       NOR_PRINCIPAL       0.32      0.69      0.43       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.00      0.00      0.00       122\n",
            "           PES_AUTOR       0.26      0.05      0.08       169\n",
            "PES_AUTORID_POLICIAL       0.00      0.00      0.00       300\n",
            "            PES_JUIZ       0.00      0.00      0.00        83\n",
            "          PES_OUTROS       0.00      0.00      0.00      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.27      0.67      0.39      1503\n",
            "      PES_TESTEMUNHA       0.50      0.00      0.00       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.33      0.35      0.34      7443\n",
            "           macro avg       0.12      0.15      0.10      7443\n",
            "        weighted avg       0.22      0.35      0.23      7443\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0 17]\n",
            "B-END_DELITO\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
            "B-END_OUTROS\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0 79]\n",
            "B-END_REU\t[  0   0   0   9   0   0   0   1   1   0   0   0   0   0   0   0   4   0\n",
            "   0   0   0 137]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 68]\n",
            "B-END_VITIMA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   1   0   0 762   5 141   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0  81]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   1 288   2   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0  41]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 144  19 544   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0  83]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 82]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  2  0  1  0  0  0  0  0  0  0 44  0  0  0  0 75]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   1   3   0   0   0   8   0   0   0   0  52   0\n",
            "   0   0   0 105]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 181   0\n",
            "   0   0   0 119]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0 24  0  0  0  0 58]\n",
            "B-PES_OUTROS\t[  0   0   0   0   0   0   0  12   0   0   0   0   1   0   0   0 678   1\n",
            "   0   0   0 518]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 24  0  0  0  0 33]\n",
            "B-PES_REU\t[   0    0    0    0    0    0    1    3    0    0    0    0    6    0\n",
            "    0    0 1003    0    0    0    0  490]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0 345   1\n",
            "   0   0   0 172]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0 214   0\n",
            "   0   0   0 190]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0  10   0\n",
            "   0   0   0 448]\n",
            "B-SENTENÇA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]\n",
            "O\t[     0      0      0     10      0      0    626    579   1023      0\n",
            "      0     23      3      0      4      0   1124      0      0      0\n",
            "      0 469228]\n",
            "-----------------------------------------------\n",
            "Ajuste de transição inválida de entidade para O\n",
            "----- COMPARAÇÃO EXATA -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Top Level (Transição de entidades O):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.00      0.00      0.00        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.00      0.00      0.00       152\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.01      0.01      0.01       990\n",
            "  NOR_JURISPRUDÊNCIA       0.00      0.00      0.00       333\n",
            "       NOR_PRINCIPAL       0.01      0.01      0.01       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.00      0.00      0.00       122\n",
            "           PES_AUTOR       0.00      0.00      0.00       169\n",
            "PES_AUTORID_POLICIAL       0.00      0.00      0.00       300\n",
            "            PES_JUIZ       0.00      0.00      0.00        83\n",
            "          PES_OUTROS       0.00      0.00      0.00      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.12      0.02      0.04      1503\n",
            "      PES_TESTEMUNHA       0.00      0.00      0.00       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.02      0.01      0.01      7443\n",
            "           macro avg       0.01      0.00      0.00      7443\n",
            "        weighted avg       0.03      0.01      0.01      7443\n",
            "\n",
            "['B-END_AUTOR', 'B-END_DELITO', 'B-END_OUTROS', 'B-END_REU', 'B-END_TESTEMUNHA', 'B-END_VITIMA', 'B-NOR_ACESSORIA', 'B-NOR_JURISPRUDÊNCIA', 'B-NOR_PRINCIPAL', 'B-PENA', 'B-PES_ADVOG', 'B-PES_AUTOR', 'B-PES_AUTORID_POLICIAL', 'B-PES_JUIZ', 'B-PES_OUTROS', 'B-PES_PROMOTOR_MP', 'B-PES_REU', 'B-PES_TESTEMUNHA', 'B-PES_VITIMA', 'B-PROVA', 'B-SENTENÇA', 'I-END_AUTOR', 'I-END_DELITO', 'I-END_OUTROS', 'I-END_REU', 'I-END_TESTEMUNHA', 'I-END_VITIMA', 'I-NOR_ACESSORIA', 'I-NOR_JURISPRUDÊNCIA', 'I-NOR_PRINCIPAL', 'I-PENA', 'I-PES_ADVOG', 'I-PES_AUTOR', 'I-PES_AUTORID_POLICIAL', 'I-PES_JUIZ', 'I-PES_OUTROS', 'I-PES_PROMOTOR_MP', 'I-PES_REU', 'I-PES_TESTEMUNHA', 'I-PES_VITIMA', 'I-PROVA', 'I-SENTENÇA', 'O']\n",
            "[[     0      0      0 ...      0      0     18]\n",
            " [     0      0      0 ...      0      0     61]\n",
            " [     0      0      0 ...      0      0     81]\n",
            " ...\n",
            " [     0      0      0 ...      0      0   3884]\n",
            " [     0      0      0 ...      0      0    238]\n",
            " [     0      0      0 ...      0      0 478318]]\n",
            "----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Level Entity (Transição de entidades O):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.00      0.00      0.00        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.00      0.00      0.00       152\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.83      0.55      0.66       990\n",
            "  NOR_JURISPRUDÊNCIA       0.00      0.00      0.00       333\n",
            "       NOR_PRINCIPAL       0.77      0.39      0.52       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.00      0.00      0.00       122\n",
            "           PES_AUTOR       0.00      0.00      0.00       169\n",
            "PES_AUTORID_POLICIAL       0.00      0.00      0.00       300\n",
            "            PES_JUIZ       0.00      0.00      0.00        83\n",
            "          PES_OUTROS       0.00      0.00      0.00      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.54      0.06      0.10      1503\n",
            "      PES_TESTEMUNHA       0.00      0.00      0.00       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.77      0.13      0.22      7443\n",
            "           macro avg       0.10      0.05      0.06      7443\n",
            "        weighted avg       0.30      0.13      0.16      7443\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18]\n",
            "B-END_DELITO\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
            "B-END_OUTROS\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 81]\n",
            "B-END_REU\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 152]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 68]\n",
            "B-END_VITIMA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 547   0  22   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 421]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 333]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0   0   0 309   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 482]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 82]\n",
            "B-PES_ADVOG\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0 121]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 169]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 300]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 83]\n",
            "B-PES_OUTROS\t[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0   20    0    0    0    0 1190]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57]\n",
            "B-PES_REU\t[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0   87    0    0    0    0 1416]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18   0\n",
            "   0   0   0 501]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0\n",
            "   0   0   0 401]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 461]\n",
            "B-SENTENÇA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]\n",
            "O\t[     0      0      0      0      0      0    113      0     72      0\n",
            "      0      0      0      0      0      0     30      0      0      0\n",
            "      0 478318]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  10%|█         | 1/10 [14:15<2:08:22, 855.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training loop.\n",
            "Train loss: 0.34171747498679905\n",
            "Train accuracy: 0.9056704003121324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting validation loop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log5: 801817 801817 801817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------\n",
            "Ajuste de transição inválida de entidade\n",
            "----- COMPARAÇÃO EXATA -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Top Level (Ajuste de transição):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.00      0.00      0.00        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.00      0.00      0.00       152\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.12      0.28      0.17       990\n",
            "  NOR_JURISPRUDÊNCIA       0.04      0.13      0.07       333\n",
            "       NOR_PRINCIPAL       0.07      0.23      0.11       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.20      0.12      0.15       122\n",
            "           PES_AUTOR       0.17      0.15      0.16       169\n",
            "PES_AUTORID_POLICIAL       0.14      0.20      0.16       300\n",
            "            PES_JUIZ       0.30      0.52      0.38        83\n",
            "          PES_OUTROS       0.18      0.08      0.11      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.17      0.32      0.22      1503\n",
            "      PES_TESTEMUNHA       0.29      0.01      0.02       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.12      0.16      0.14      7443\n",
            "           macro avg       0.08      0.10      0.07      7443\n",
            "        weighted avg       0.12      0.16      0.12      7443\n",
            "\n",
            "['B-END_AUTOR', 'B-END_DELITO', 'B-END_OUTROS', 'B-END_REU', 'B-END_TESTEMUNHA', 'B-END_VITIMA', 'B-NOR_ACESSORIA', 'B-NOR_JURISPRUDÊNCIA', 'B-NOR_PRINCIPAL', 'B-PENA', 'B-PES_ADVOG', 'B-PES_AUTOR', 'B-PES_AUTORID_POLICIAL', 'B-PES_JUIZ', 'B-PES_OUTROS', 'B-PES_PROMOTOR_MP', 'B-PES_REU', 'B-PES_TESTEMUNHA', 'B-PES_VITIMA', 'B-PROVA', 'B-SENTENÇA', 'I-END_AUTOR', 'I-END_DELITO', 'I-END_OUTROS', 'I-END_REU', 'I-END_TESTEMUNHA', 'I-END_VITIMA', 'I-NOR_ACESSORIA', 'I-NOR_JURISPRUDÊNCIA', 'I-NOR_PRINCIPAL', 'I-PENA', 'I-PES_ADVOG', 'I-PES_AUTOR', 'I-PES_AUTORID_POLICIAL', 'I-PES_JUIZ', 'I-PES_OUTROS', 'I-PES_PROMOTOR_MP', 'I-PES_REU', 'I-PES_TESTEMUNHA', 'I-PES_VITIMA', 'I-PROVA', 'I-SENTENÇA', 'O']\n",
            "[[     6      0      0 ...      0      0     10]\n",
            " [     0      9      0 ...      0      0     47]\n",
            " [     1      1      0 ...      0      0     78]\n",
            " ...\n",
            " [     0      0      0 ...      0      0   3805]\n",
            " [     0      0      0 ...      0      0    234]\n",
            " [    20      4      0 ...     20      0 463123]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----\n",
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.38      0.61      0.47        18\n",
            "          END_DELITO       0.82      0.30      0.43        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.51      0.24      0.32       152\n",
            "      END_TESTEMUNHA       1.00      0.07      0.14        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.35      0.74      0.48       990\n",
            "  NOR_JURISPRUDÊNCIA       0.34      0.97      0.50       333\n",
            "       NOR_PRINCIPAL       0.37      0.85      0.51       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.71      0.43      0.54       122\n",
            "           PES_AUTOR       0.50      0.41      0.45       169\n",
            "PES_AUTORID_POLICIAL       0.30      0.38      0.33       300\n",
            "            PES_JUIZ       0.53      0.76      0.62        83\n",
            "          PES_OUTROS       0.51      0.21      0.29      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.36      0.65      0.47      1503\n",
            "      PES_TESTEMUNHA       0.75      0.02      0.04       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.33      0.01      0.02       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.37      0.45      0.41      7443\n",
            "           macro avg       0.37      0.32      0.27      7443\n",
            "        weighted avg       0.40      0.45      0.34      7443\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7]\n",
            "B-END_DELITO\t[ 0 18  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 42]\n",
            "B-END_OUTROS\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 81]\n",
            "B-END_REU\t[  0   0   0  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 116]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 63]\n",
            "B-END_VITIMA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 730   9 195   0   0   0   0   0   0   0   2   0\n",
            "   0   0   0  54]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   1 322   2   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   8]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0  85  12 671   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0  23]\n",
            "B-PENA\t[ 0  0  0  0  0  0  2  0  2  0  0  0  0  0  0  0  0  0  0  0  0 78]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 53  3  0  0  0  0  4  0  0  0  0 62]\n",
            "B-PES_AUTOR\t[ 0  0  0  0  0  0  0  1  1  0  0 69  0  0  0  0 23  0  0  0  0 75]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0 115   2  15   0 122   0\n",
            "   0   0   0  46]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  1  0  0  0  0  0 63  0  0  8  0  0  0  0 11]\n",
            "B-PES_OUTROS\t[  0   0   0   1   0   0   4  18   0   0   0   2  68   4 250   0 469   0\n",
            "   0   0   0 394]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  0  1  5  0  0 21  1  0  0  0 29]\n",
            "B-PES_REU\t[  0   0   0   0   0   0   1   0   0   0   0   6  29   7  42   0 981   0\n",
            "   0   0   0 437]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   1   0   0   0  38   7  23   0 296  12\n",
            "   0   0   0 142]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   9   0  23   0 210   0\n",
            "   0   0   0 163]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   6   0\n",
            "   0   5   0 445]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 9]\n",
            "O\t[    18      4      0     33      0      0   1252    594    957      0\n",
            "     22     59    122     32    138      0    546      3      0     10\n",
            "      0 463123]\n",
            "-----------------------------------------------\n",
            "Ajuste de transição inválida de entidade para O\n",
            "----- COMPARAÇÃO EXATA -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Top Level (Transição de entidades O):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.00      0.00      0.00        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.00      0.00      0.00       152\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.19      0.16      0.18       990\n",
            "  NOR_JURISPRUDÊNCIA       0.22      0.03      0.06       333\n",
            "       NOR_PRINCIPAL       0.07      0.13      0.09       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.00      0.00      0.00       122\n",
            "           PES_AUTOR       0.16      0.05      0.07       169\n",
            "PES_AUTORID_POLICIAL       0.00      0.00      0.00       300\n",
            "            PES_JUIZ       0.00      0.00      0.00        83\n",
            "          PES_OUTROS       0.12      0.01      0.03      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.18      0.12      0.15      1503\n",
            "      PES_TESTEMUNHA       0.33      0.00      0.00       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.13      0.06      0.09      7443\n",
            "           macro avg       0.06      0.02      0.03      7443\n",
            "        weighted avg       0.13      0.06      0.07      7443\n",
            "\n",
            "['B-END_AUTOR', 'B-END_DELITO', 'B-END_OUTROS', 'B-END_REU', 'B-END_TESTEMUNHA', 'B-END_VITIMA', 'B-NOR_ACESSORIA', 'B-NOR_JURISPRUDÊNCIA', 'B-NOR_PRINCIPAL', 'B-PENA', 'B-PES_ADVOG', 'B-PES_AUTOR', 'B-PES_AUTORID_POLICIAL', 'B-PES_JUIZ', 'B-PES_OUTROS', 'B-PES_PROMOTOR_MP', 'B-PES_REU', 'B-PES_TESTEMUNHA', 'B-PES_VITIMA', 'B-PROVA', 'B-SENTENÇA', 'I-END_AUTOR', 'I-END_DELITO', 'I-END_OUTROS', 'I-END_REU', 'I-END_TESTEMUNHA', 'I-END_VITIMA', 'I-NOR_ACESSORIA', 'I-NOR_JURISPRUDÊNCIA', 'I-NOR_PRINCIPAL', 'I-PENA', 'I-PES_ADVOG', 'I-PES_AUTOR', 'I-PES_AUTORID_POLICIAL', 'I-PES_JUIZ', 'I-PES_OUTROS', 'I-PES_PROMOTOR_MP', 'I-PES_REU', 'I-PES_TESTEMUNHA', 'I-PES_VITIMA', 'I-PROVA', 'I-SENTENÇA', 'O']\n",
            "[[     0      0      0 ...      0      0     18]\n",
            " [     0      0      0 ...      0      0     59]\n",
            " [     0      0      0 ...      0      0     81]\n",
            " ...\n",
            " [     0      0      0 ...      0      0   3871]\n",
            " [     0      0      0 ...      0      0    238]\n",
            " [     0      0      0 ...      0      0 476999]]\n",
            "----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Level Entity (Transição de entidades O):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.00      0.00      0.00        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       1.00      0.01      0.01       152\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.84      0.59      0.69       990\n",
            "  NOR_JURISPRUDÊNCIA       0.83      0.12      0.21       333\n",
            "       NOR_PRINCIPAL       0.65      0.77      0.70       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.00      0.00      0.00       122\n",
            "           PES_AUTOR       0.53      0.16      0.25       169\n",
            "PES_AUTORID_POLICIAL       1.00      0.01      0.03       300\n",
            "            PES_JUIZ       0.00      0.00      0.00        83\n",
            "          PES_OUTROS       0.63      0.06      0.10      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.55      0.27      0.36      1503\n",
            "      PES_TESTEMUNHA       1.00      0.00      0.01       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.67      0.23      0.35      7443\n",
            "           macro avg       0.33      0.09      0.11      7443\n",
            "        weighted avg       0.57      0.23      0.27      7443\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18]\n",
            "B-END_DELITO\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
            "B-END_OUTROS\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 81]\n",
            "B-END_REU\t[  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 151]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 68]\n",
            "B-END_VITIMA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 582   0  96   0   0   0   0   0   0   0   2   0\n",
            "   0   0   0 310]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   0  40   1   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 292]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0  25   0 606   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 160]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 82]\n",
            "B-PES_ADVOG\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0 121]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   0   0   1   0   0  27   0   0   0   0   2   0\n",
            "   0   0   0 139]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0  14   0\n",
            "   0   0   0 282]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 82]\n",
            "B-PES_OUTROS\t[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   67    0   85    0    0    0    0 1058]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0 54]\n",
            "B-PES_REU\t[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    2    0  410    0    0    0    0 1091]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  79   2\n",
            "   0   0   0 438]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  27   0\n",
            "   0   0   0 378]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
            "   0   0   0 459]\n",
            "B-SENTENÇA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]\n",
            "O\t[     0      0      0      0      0      0     85      8    232      0\n",
            "      0     24      0      0     37      0    124      0      0      0\n",
            "      0 476999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [28:36<1:54:28, 858.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training loop.\n",
            "Train loss: 0.2778511834418168\n",
            "Train accuracy: 0.9177192639738132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting validation loop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log5: 801817 801817 801817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------\n",
            "Ajuste de transição inválida de entidade\n",
            "----- COMPARAÇÃO EXATA -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Top Level (Ajuste de transição):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.08      0.28      0.13        18\n",
            "          END_DELITO       0.03      0.08      0.04        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.03      0.05      0.04       152\n",
            "      END_TESTEMUNHA       0.12      0.13      0.13        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.11      0.26      0.16       990\n",
            "  NOR_JURISPRUDÊNCIA       0.10      0.20      0.13       333\n",
            "       NOR_PRINCIPAL       0.09      0.22      0.12       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.24      0.19      0.21       122\n",
            "           PES_AUTOR       0.18      0.17      0.17       169\n",
            "PES_AUTORID_POLICIAL       0.24      0.51      0.33       300\n",
            "            PES_JUIZ       0.32      0.55      0.40        83\n",
            "          PES_OUTROS       0.18      0.12      0.14      1210\n",
            "     PES_PROMOTOR_MP       0.08      0.02      0.03        57\n",
            "             PES_REU       0.20      0.29      0.24      1503\n",
            "      PES_TESTEMUNHA       0.23      0.03      0.05       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.01      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.14      0.19      0.16      7443\n",
            "           macro avg       0.11      0.15      0.11      7443\n",
            "        weighted avg       0.14      0.19      0.14      7443\n",
            "\n",
            "['B-END_AUTOR', 'B-END_DELITO', 'B-END_OUTROS', 'B-END_REU', 'B-END_TESTEMUNHA', 'B-END_VITIMA', 'B-NOR_ACESSORIA', 'B-NOR_JURISPRUDÊNCIA', 'B-NOR_PRINCIPAL', 'B-PENA', 'B-PES_ADVOG', 'B-PES_AUTOR', 'B-PES_AUTORID_POLICIAL', 'B-PES_JUIZ', 'B-PES_OUTROS', 'B-PES_PROMOTOR_MP', 'B-PES_REU', 'B-PES_TESTEMUNHA', 'B-PES_VITIMA', 'B-PROVA', 'B-SENTENÇA', 'I-END_AUTOR', 'I-END_DELITO', 'I-END_OUTROS', 'I-END_REU', 'I-END_TESTEMUNHA', 'I-END_VITIMA', 'I-NOR_ACESSORIA', 'I-NOR_JURISPRUDÊNCIA', 'I-NOR_PRINCIPAL', 'I-PENA', 'I-PES_ADVOG', 'I-PES_AUTOR', 'I-PES_AUTORID_POLICIAL', 'I-PES_JUIZ', 'I-PES_OUTROS', 'I-PES_PROMOTOR_MP', 'I-PES_REU', 'I-PES_TESTEMUNHA', 'I-PES_VITIMA', 'I-PROVA', 'I-SENTENÇA', 'O']\n",
            "[[     7      0      0 ...      0      0      7]\n",
            " [     0     23      0 ...      0      0     30]\n",
            " [     3      1      0 ...      0      0     72]\n",
            " ...\n",
            " [     0      0      0 ...    450      0   3328]\n",
            " [     0      0      0 ...      0      0    234]\n",
            " [    23     43      0 ...    453      0 463300]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----\n",
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.38      0.72      0.50        18\n",
            "          END_DELITO       0.45      0.74      0.56        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.43      0.53      0.48       152\n",
            "      END_TESTEMUNHA       0.59      0.47      0.52        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.39      0.81      0.52       990\n",
            "  NOR_JURISPRUDÊNCIA       0.46      0.96      0.62       333\n",
            "       NOR_PRINCIPAL       0.43      0.85      0.57       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.69      0.55      0.61       122\n",
            "           PES_AUTOR       0.49      0.43      0.46       169\n",
            "PES_AUTORID_POLICIAL       0.37      0.72      0.49       300\n",
            "            PES_JUIZ       0.49      0.78      0.60        83\n",
            "          PES_OUTROS       0.53      0.35      0.42      1210\n",
            "     PES_PROMOTOR_MP       0.43      0.05      0.09        57\n",
            "             PES_REU       0.45      0.60      0.52      1503\n",
            "      PES_TESTEMUNHA       0.70      0.08      0.14       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.27      0.09      0.13       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.44      0.51      0.47      7443\n",
            "           macro avg       0.36      0.42      0.34      7443\n",
            "        weighted avg       0.43      0.51      0.42      7443\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[13  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3]\n",
            "B-END_DELITO\t[ 0 45  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15]\n",
            "B-END_OUTROS\t[ 2  1  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 76]\n",
            "B-END_REU\t[ 0  5  0 81  2  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0 63]\n",
            "B-END_TESTEMUNHA\t[ 0  1  0  4 32  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 31]\n",
            "B-END_VITIMA\t[ 0  4  0  1  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 805   7 141   0   0   0   0   0   0   0   2   0\n",
            "   0   0   0  35]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   3 320   4   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   6]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0  92   6 676   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0  17]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0 80]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 67  1  0  0  0  1  2  0  0  0  0 51]\n",
            "B-PES_AUTOR\t[ 0  0  0  0  0  0  0  0  0  0  0 73  0  0  1  0 19  0  0  0  0 76]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0 217   1  13   0  32   0\n",
            "   0   0   0  37]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  1  0  0  0  0  0 65  0  0  3  0  0  0  0 14]\n",
            "B-PES_OUTROS\t[  0   1   0   2   0   0   3  17   0   0   0   2 119   5 421   0 253   1\n",
            "   0   0   0 386]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1  3  8  0  3  9  3  0  0  0 30]\n",
            "B-PES_REU\t[  0   0   0   0   0   0   2   0   2   0   0  12  65   8  72   0 905   5\n",
            "   0   1   0 431]\n",
            "B-PES_TESTEMUNHA\t[  0   1   0   0   1   0   0   0   0   0   0   0  51   0  51   2 218  40\n",
            "   0   2   0 153]\n",
            "B-PES_VITIMA\t[  0   0   0   1   0   0   0   0   0   0   0   0  14   1  37   0 183   3\n",
            "   0   2   0 164]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   5   0\n",
            "   0  40   0 412]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 9]\n",
            "O\t[    19     41      0     95     14      0   1182    345    761      0\n",
            "     30     60    118     44    196      1    361      5      0    104\n",
            "      0 463300]\n",
            "-----------------------------------------------\n",
            "Ajuste de transição inválida de entidade para O\n",
            "----- COMPARAÇÃO EXATA -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Top Level (Transição de entidades O):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.00      0.00      0.00        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.01      0.01      0.01       152\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.26      0.23      0.24       990\n",
            "  NOR_JURISPRUDÊNCIA       0.27      0.08      0.12       333\n",
            "       NOR_PRINCIPAL       0.10      0.19      0.13       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.00      0.00      0.00       122\n",
            "           PES_AUTOR       0.16      0.07      0.09       169\n",
            "PES_AUTORID_POLICIAL       0.04      0.00      0.01       300\n",
            "            PES_JUIZ       1.00      0.01      0.02        83\n",
            "          PES_OUTROS       0.21      0.07      0.11      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.21      0.15      0.18      1503\n",
            "      PES_TESTEMUNHA       0.57      0.01      0.02       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.17      0.10      0.13      7443\n",
            "           macro avg       0.13      0.04      0.04      7443\n",
            "        weighted avg       0.19      0.10      0.11      7443\n",
            "\n",
            "['B-END_AUTOR', 'B-END_DELITO', 'B-END_OUTROS', 'B-END_REU', 'B-END_TESTEMUNHA', 'B-END_VITIMA', 'B-NOR_ACESSORIA', 'B-NOR_JURISPRUDÊNCIA', 'B-NOR_PRINCIPAL', 'B-PENA', 'B-PES_ADVOG', 'B-PES_AUTOR', 'B-PES_AUTORID_POLICIAL', 'B-PES_JUIZ', 'B-PES_OUTROS', 'B-PES_PROMOTOR_MP', 'B-PES_REU', 'B-PES_TESTEMUNHA', 'B-PES_VITIMA', 'B-PROVA', 'B-SENTENÇA', 'I-END_AUTOR', 'I-END_DELITO', 'I-END_OUTROS', 'I-END_REU', 'I-END_TESTEMUNHA', 'I-END_VITIMA', 'I-NOR_ACESSORIA', 'I-NOR_JURISPRUDÊNCIA', 'I-NOR_PRINCIPAL', 'I-PENA', 'I-PES_ADVOG', 'I-PES_AUTOR', 'I-PES_AUTORID_POLICIAL', 'I-PES_JUIZ', 'I-PES_OUTROS', 'I-PES_PROMOTOR_MP', 'I-PES_REU', 'I-PES_TESTEMUNHA', 'I-PES_VITIMA', 'I-PROVA', 'I-SENTENÇA', 'O']\n",
            "[[     0      0      0 ...      0      0     18]\n",
            " [     0      0      0 ...      0      0     53]\n",
            " [     0      0      0 ...      0      0     77]\n",
            " ...\n",
            " [     0      0      0 ...      0      0   3875]\n",
            " [     0      0      0 ...      0      0    238]\n",
            " [     0      0      0 ...      0      0 476331]]\n",
            "----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Level Entity (Transição de entidades O):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.00      0.00      0.00        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.46      0.17      0.25       152\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.83      0.64      0.72       990\n",
            "  NOR_JURISPRUDÊNCIA       0.84      0.23      0.37       333\n",
            "       NOR_PRINCIPAL       0.66      0.81      0.73       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.00      0.00      0.00       122\n",
            "           PES_AUTOR       0.43      0.17      0.24       169\n",
            "PES_AUTORID_POLICIAL       0.45      0.02      0.03       300\n",
            "            PES_JUIZ       1.00      0.01      0.02        83\n",
            "          PES_OUTROS       0.60      0.15      0.24      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.59      0.33      0.42      1503\n",
            "      PES_TESTEMUNHA       1.00      0.01      0.02       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.68      0.28      0.40      7443\n",
            "           macro avg       0.33      0.12      0.15      7443\n",
            "        weighted avg       0.55      0.28      0.33      7443\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18]\n",
            "B-END_DELITO\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
            "B-END_OUTROS\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 81]\n",
            "B-END_REU\t[  0   0   0  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 126]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 68]\n",
            "B-END_VITIMA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 631   0  86   0   0   0   0   0   0   0   2   0\n",
            "   0   0   0 271]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   0  78   0   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0 254]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0  41   0 643   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 107]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 82]\n",
            "B-PES_ADVOG\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0 121]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   0   0   0   0   0  29   0   0   0   0   4   0\n",
            "   0   0   0 136]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0   5   0   1   0   3   0\n",
            "   0   0   0 291]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0 81]\n",
            "B-PES_OUTROS\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0 180   0  63   0\n",
            "   0   0   0 967]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  2  0  0  0  0 54]\n",
            "B-PES_REU\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  20   0 491   0\n",
            "   0   0   0 992]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   0   0   0   0   1   0   8   0  83   6\n",
            "   0   0   0 421]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   1   0   3   0  44   0\n",
            "   0   0   0 357]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 461]\n",
            "B-SENTENÇA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]\n",
            "O\t[     0      0      0     31      0      0     89     15    238      0\n",
            "      0     38      4      0     86      0    137      0      0      0\n",
            "      0 476331]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [42:54<1:40:09, 858.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training loop.\n",
            "Train loss: 0.24372134747740348\n",
            "Train accuracy: 0.9257614672084961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting validation loop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log5: 801817 801817 801817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------\n",
            "Ajuste de transição inválida de entidade\n",
            "----- COMPARAÇÃO EXATA -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Top Level (Ajuste de transição):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.11      0.33      0.16        18\n",
            "          END_DELITO       0.06      0.20      0.09        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.07      0.15      0.10       152\n",
            "      END_TESTEMUNHA       0.18      0.26      0.22        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.12      0.25      0.16       990\n",
            "  NOR_JURISPRUDÊNCIA       0.11      0.20      0.14       333\n",
            "       NOR_PRINCIPAL       0.11      0.25      0.15       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.30      0.26      0.28       122\n",
            "           PES_AUTOR       0.15      0.15      0.15       169\n",
            "PES_AUTORID_POLICIAL       0.31      0.58      0.41       300\n",
            "            PES_JUIZ       0.35      0.53      0.42        83\n",
            "          PES_OUTROS       0.22      0.16      0.19      1210\n",
            "     PES_PROMOTOR_MP       0.15      0.07      0.10        57\n",
            "             PES_REU       0.22      0.29      0.25      1503\n",
            "      PES_TESTEMUNHA       0.28      0.11      0.16       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.01      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.16      0.21      0.18      7443\n",
            "           macro avg       0.13      0.18      0.14      7443\n",
            "        weighted avg       0.16      0.21      0.17      7443\n",
            "\n",
            "['B-END_AUTOR', 'B-END_DELITO', 'B-END_OUTROS', 'B-END_REU', 'B-END_TESTEMUNHA', 'B-END_VITIMA', 'B-NOR_ACESSORIA', 'B-NOR_JURISPRUDÊNCIA', 'B-NOR_PRINCIPAL', 'B-PENA', 'B-PES_ADVOG', 'B-PES_AUTOR', 'B-PES_AUTORID_POLICIAL', 'B-PES_JUIZ', 'B-PES_OUTROS', 'B-PES_PROMOTOR_MP', 'B-PES_REU', 'B-PES_TESTEMUNHA', 'B-PES_VITIMA', 'B-PROVA', 'B-SENTENÇA', 'I-END_AUTOR', 'I-END_DELITO', 'I-END_OUTROS', 'I-END_REU', 'I-END_TESTEMUNHA', 'I-END_VITIMA', 'I-NOR_ACESSORIA', 'I-NOR_JURISPRUDÊNCIA', 'I-NOR_PRINCIPAL', 'I-PENA', 'I-PES_ADVOG', 'I-PES_AUTOR', 'I-PES_AUTORID_POLICIAL', 'I-PES_JUIZ', 'I-PES_OUTROS', 'I-PES_PROMOTOR_MP', 'I-PES_REU', 'I-PES_TESTEMUNHA', 'I-PES_VITIMA', 'I-PROVA', 'I-SENTENÇA', 'O']\n",
            "[[     8      0      0 ...      0      0      5]\n",
            " [     0     26      0 ...      0      0     21]\n",
            " [     2      3      0 ...      0      0     68]\n",
            " ...\n",
            " [     0      0      0 ...    570      0   3219]\n",
            " [     0      0      0 ...      0      0    234]\n",
            " [    25     72      2 ...    620      0 463568]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----\n",
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.39      0.78      0.52        18\n",
            "          END_DELITO       0.36      0.82      0.50        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.43      0.66      0.52       152\n",
            "      END_TESTEMUNHA       0.57      0.68      0.62        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.45      0.80      0.57       990\n",
            "  NOR_JURISPRUDÊNCIA       0.52      0.96      0.67       333\n",
            "       NOR_PRINCIPAL       0.46      0.88      0.60       791\n",
            "                PENA       1.00      0.01      0.02        82\n",
            "           PES_ADVOG       0.68      0.58      0.63       122\n",
            "           PES_AUTOR       0.50      0.46      0.48       169\n",
            "PES_AUTORID_POLICIAL       0.48      0.81      0.60       300\n",
            "            PES_JUIZ       0.59      0.81      0.68        83\n",
            "          PES_OUTROS       0.54      0.37      0.44      1210\n",
            "     PES_PROMOTOR_MP       0.61      0.25      0.35        57\n",
            "             PES_REU       0.47      0.60      0.53      1503\n",
            "      PES_TESTEMUNHA       0.61      0.23      0.34       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.32      0.09      0.14       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.48      0.54      0.51      7443\n",
            "           macro avg       0.43      0.47      0.39      7443\n",
            "        weighted avg       0.46      0.54      0.46      7443\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[14  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2]\n",
            "B-END_DELITO\t[ 0 50  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7]\n",
            "B-END_OUTROS\t[ 1  2  0  3  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 73]\n",
            "B-END_REU\t[  1  10   0 101   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0  37]\n",
            "B-END_TESTEMUNHA\t[ 0  3  0  4 46  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15]\n",
            "B-END_VITIMA\t[ 0  4  0  4  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 796   8 152   0   0   0   0   0   0   0   2   0\n",
            "   0   0   0  32]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   2 321   5   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   5]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0  68   5 696   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0  22]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0 80]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 71  1  0  0  0  1  2  0  0  0  0 47]\n",
            "B-PES_AUTOR\t[ 0  0  0  0  0  0  0  1  0  0  0 77  0  0  0  0 16  0  0  0  0 75]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0 243   0  17   0  20   1\n",
            "   0   0   0  19]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  1  0  0  0  0  0 67  0  0  1  0  0  0  0 14]\n",
            "B-PES_OUTROS\t[  0   1   0   5   0   0   1  14   0   0   0   2  87   3 449   1 249  16\n",
            "   0   0   0 382]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  1  1  4  5  1 14  5  2  0  0  0 24]\n",
            "B-PES_REU\t[  0   1   0   1   0   0   2   0   1   0   0  23  31   4  81   1 907  22\n",
            "   0   1   0 428]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   1   0   0   0   0   0   0   0  23   1  46   1 183 121\n",
            "   0   1   0 142]\n",
            "B-PES_VITIMA\t[  0   1   0   0   0   0   0   0   0   0   0   0   8   1  34   0 187  12\n",
            "   0   0   0 162]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   0   6   0\n",
            "   0  43   0 408]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 9]\n",
            "O\t[    20     66      2    111     21      0    912    272    666      0\n",
            "     33     51    107     33    200      5    333     24      0     88\n",
            "      0 463568]\n",
            "-----------------------------------------------\n",
            "Ajuste de transição inválida de entidade para O\n",
            "----- COMPARAÇÃO EXATA -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Top Level (Transição de entidades O):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.00      0.00      0.00        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.01      0.01      0.01       152\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.27      0.24      0.26       990\n",
            "  NOR_JURISPRUDÊNCIA       0.25      0.08      0.12       333\n",
            "       NOR_PRINCIPAL       0.14      0.24      0.18       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.00      0.00      0.00       122\n",
            "           PES_AUTOR       0.12      0.04      0.06       169\n",
            "PES_AUTORID_POLICIAL       0.20      0.05      0.08       300\n",
            "            PES_JUIZ       0.40      0.02      0.05        83\n",
            "          PES_OUTROS       0.25      0.11      0.15      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.23      0.17      0.19      1503\n",
            "      PES_TESTEMUNHA       0.38      0.03      0.05       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.20      0.12      0.15      7443\n",
            "           macro avg       0.11      0.05      0.05      7443\n",
            "        weighted avg       0.19      0.12      0.13      7443\n",
            "\n",
            "['B-END_AUTOR', 'B-END_DELITO', 'B-END_OUTROS', 'B-END_REU', 'B-END_TESTEMUNHA', 'B-END_VITIMA', 'B-NOR_ACESSORIA', 'B-NOR_JURISPRUDÊNCIA', 'B-NOR_PRINCIPAL', 'B-PENA', 'B-PES_ADVOG', 'B-PES_AUTOR', 'B-PES_AUTORID_POLICIAL', 'B-PES_JUIZ', 'B-PES_OUTROS', 'B-PES_PROMOTOR_MP', 'B-PES_REU', 'B-PES_TESTEMUNHA', 'B-PES_VITIMA', 'B-PROVA', 'B-SENTENÇA', 'I-END_AUTOR', 'I-END_DELITO', 'I-END_OUTROS', 'I-END_REU', 'I-END_TESTEMUNHA', 'I-END_VITIMA', 'I-NOR_ACESSORIA', 'I-NOR_JURISPRUDÊNCIA', 'I-NOR_PRINCIPAL', 'I-PENA', 'I-PES_ADVOG', 'I-PES_AUTOR', 'I-PES_AUTORID_POLICIAL', 'I-PES_JUIZ', 'I-PES_OUTROS', 'I-PES_PROMOTOR_MP', 'I-PES_REU', 'I-PES_TESTEMUNHA', 'I-PES_VITIMA', 'I-PROVA', 'I-SENTENÇA', 'O']\n",
            "[[     0      0      0 ...      0      0     13]\n",
            " [     0      1      0 ...      0      0     48]\n",
            " [     0      1      0 ...      0      0     74]\n",
            " ...\n",
            " [     0      0      0 ...      0      0   3865]\n",
            " [     0      0      0 ...      0      0    238]\n",
            " [     0      3      0 ...      0      0 476080]]\n",
            "----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Level Entity (Transição de entidades O):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.25      0.02      0.03        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.58      0.39      0.47       152\n",
            "      END_TESTEMUNHA       1.00      0.01      0.03        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.84      0.67      0.74       990\n",
            "  NOR_JURISPRUDÊNCIA       0.79      0.24      0.37       333\n",
            "       NOR_PRINCIPAL       0.70      0.82      0.75       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.00      0.00      0.00       122\n",
            "           PES_AUTOR       0.47      0.17      0.24       169\n",
            "PES_AUTORID_POLICIAL       0.66      0.13      0.22       300\n",
            "            PES_JUIZ       1.00      0.04      0.07        83\n",
            "          PES_OUTROS       0.60      0.19      0.29      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.64      0.34      0.44      1503\n",
            "      PES_TESTEMUNHA       0.91      0.06      0.11       519\n",
            "          PES_VITIMA       1.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.70      0.31      0.43      7443\n",
            "           macro avg       0.45      0.15      0.18      7443\n",
            "        weighted avg       0.64      0.31      0.37      7443\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18]\n",
            "B-END_DELITO\t[ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60]\n",
            "B-END_OUTROS\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 81]\n",
            "B-END_REU\t[ 0  0  0 59  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 93]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 67]\n",
            "B-END_VITIMA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 659   1  83   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0 246]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   0  81   0   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0 251]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0  40   0 649   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 102]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 82]\n",
            "B-PES_ADVOG\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
            "   0   0   0 120]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   0   0   0   0   0  28   0   0   0   0   4   0\n",
            "   0   0   0 137]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0  40   0   1   0   5   0\n",
            "   0   0   0 254]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0 80]\n",
            "B-PES_OUTROS\t[  0   0   0   0   0   0   0   1   0   0   0   0   5   0 231   0  45   0\n",
            "   0   0   0 928]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 56]\n",
            "B-PES_REU\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0 509   0\n",
            "   0   0   0 963]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   0   0   0   0   1   0  15   0  59  29\n",
            "   0   0   0 415]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   1   0   5   0  42   1\n",
            "   1   0   0 355]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   2   0\n",
            "   0   0   0 457]\n",
            "B-SENTENÇA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]\n",
            "O\t[     0      3      0     42      0      0     87     19    197      0\n",
            "      0     31     13      0    100      0    123      2      0      0\n",
            "      0 476080]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 4/10 [57:15<1:25:55, 859.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training loop.\n",
            "Train loss: 0.22090198634119587\n",
            "Train accuracy: 0.9317365850323125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting validation loop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log5: 801817 801817 801817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------\n",
            "Ajuste de transição inválida de entidade\n",
            "----- COMPARAÇÃO EXATA -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Top Level (Ajuste de transição):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.10      0.28      0.15        18\n",
            "          END_DELITO       0.05      0.15      0.08        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.08      0.17      0.11       152\n",
            "      END_TESTEMUNHA       0.21      0.26      0.23        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.15      0.27      0.19       990\n",
            "  NOR_JURISPRUDÊNCIA       0.15      0.23      0.18       333\n",
            "       NOR_PRINCIPAL       0.12      0.27      0.17       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.34      0.30      0.32       122\n",
            "           PES_AUTOR       0.14      0.12      0.13       169\n",
            "PES_AUTORID_POLICIAL       0.41      0.64      0.50       300\n",
            "            PES_JUIZ       0.38      0.52      0.44        83\n",
            "          PES_OUTROS       0.23      0.16      0.19      1210\n",
            "     PES_PROMOTOR_MP       0.30      0.21      0.25        57\n",
            "             PES_REU       0.22      0.30      0.26      1503\n",
            "      PES_TESTEMUNHA       0.33      0.19      0.24       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.01      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.19      0.23      0.20      7443\n",
            "           macro avg       0.15      0.19      0.16      7443\n",
            "        weighted avg       0.18      0.23      0.19      7443\n",
            "\n",
            "['B-END_AUTOR', 'B-END_DELITO', 'B-END_OUTROS', 'B-END_REU', 'B-END_TESTEMUNHA', 'B-END_VITIMA', 'B-NOR_ACESSORIA', 'B-NOR_JURISPRUDÊNCIA', 'B-NOR_PRINCIPAL', 'B-PENA', 'B-PES_ADVOG', 'B-PES_AUTOR', 'B-PES_AUTORID_POLICIAL', 'B-PES_JUIZ', 'B-PES_OUTROS', 'B-PES_PROMOTOR_MP', 'B-PES_REU', 'B-PES_TESTEMUNHA', 'B-PES_VITIMA', 'B-PROVA', 'B-SENTENÇA', 'I-END_AUTOR', 'I-END_DELITO', 'I-END_OUTROS', 'I-END_REU', 'I-END_TESTEMUNHA', 'I-END_VITIMA', 'I-NOR_ACESSORIA', 'I-NOR_JURISPRUDÊNCIA', 'I-NOR_PRINCIPAL', 'I-PENA', 'I-PES_ADVOG', 'I-PES_AUTOR', 'I-PES_AUTORID_POLICIAL', 'I-PES_JUIZ', 'I-PES_OUTROS', 'I-PES_PROMOTOR_MP', 'I-PES_REU', 'I-PES_TESTEMUNHA', 'I-PES_VITIMA', 'I-PROVA', 'I-SENTENÇA', 'O']\n",
            "[[     6      0      0 ...      0      0      5]\n",
            " [     0     22      0 ...      0      0     27]\n",
            " [     0      2      0 ...      0      0     69]\n",
            " ...\n",
            " [     0      1      0 ...    676      0   3120]\n",
            " [     0      0      0 ...      0      0    237]\n",
            " [    24     58      4 ...    946      0 464718]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----\n",
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.41      0.78      0.54        18\n",
            "          END_DELITO       0.41      0.84      0.55        61\n",
            "          END_OUTROS       0.20      0.01      0.02        81\n",
            "             END_REU       0.43      0.67      0.53       152\n",
            "      END_TESTEMUNHA       0.61      0.63      0.62        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.50      0.82      0.62       990\n",
            "  NOR_JURISPRUDÊNCIA       0.59      0.97      0.73       333\n",
            "       NOR_PRINCIPAL       0.49      0.87      0.63       791\n",
            "                PENA       0.25      0.01      0.02        82\n",
            "           PES_ADVOG       0.68      0.60      0.63       122\n",
            "           PES_AUTOR       0.51      0.42      0.46       169\n",
            "PES_AUTORID_POLICIAL       0.60      0.85      0.70       300\n",
            "            PES_JUIZ       0.65      0.83      0.73        83\n",
            "          PES_OUTROS       0.59      0.39      0.47      1210\n",
            "     PES_PROMOTOR_MP       0.76      0.49      0.60        57\n",
            "             PES_REU       0.50      0.63      0.56      1503\n",
            "      PES_TESTEMUNHA       0.64      0.36      0.46       519\n",
            "          PES_VITIMA       0.33      0.00      0.00       405\n",
            "               PROVA       0.32      0.11      0.16       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.52      0.56      0.54      7443\n",
            "           macro avg       0.45      0.49      0.43      7443\n",
            "        weighted avg       0.51      0.56      0.50      7443\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[14  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2]\n",
            "B-END_DELITO\t[ 0 51  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8]\n",
            "B-END_OUTROS\t[ 1  2  1  3  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 72]\n",
            "B-END_REU\t[  2  10   0 102   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0  35]\n",
            "B-END_TESTEMUNHA\t[ 0  2  0  7 43  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16]\n",
            "B-END_VITIMA\t[ 0  3  0  6  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 808   6 138   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0  37]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   1 322   5   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   5]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0  76   5 691   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0  19]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 81]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 73  1  0  0  0  1  1  0  0  0  0 46]\n",
            "B-PES_AUTOR\t[ 0  0  0  0  0  0  0  1  0  0  0 71  0  0  1  0 21  0  0  0  0 75]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0 256   0  11   0  13   2\n",
            "   0   0   0  18]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0 69  0  0  1  0  0  0  0 13]\n",
            "B-PES_OUTROS\t[  0   1   0   5   0   0   1  14   0   0   2   1  71   2 472   1 240  16\n",
            "   0   0   0 384]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1  2  4  0 28  3  0  0  0  0 19]\n",
            "B-PES_REU\t[  0   1   0   2   0   0   1   0   2   0   0  16   7   4  58   1 953  34\n",
            "   0   3   0 421]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   1   0   0   0   0   0   0   0   3   2  29   0 153 189\n",
            "   0   0   0 142]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   5   1  29   0 198  14\n",
            "   1   1   0 156]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   7   2\n",
            "   0  49   0 402]\n",
            "B-SENTENÇA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 10]\n",
            "O\t[    17     53      4    106     14      0    743    198    573      3\n",
            "     33     48     86     24    200      6    321     40      2     98\n",
            "      0 464718]\n",
            "-----------------------------------------------\n",
            "Ajuste de transição inválida de entidade para O\n",
            "----- COMPARAÇÃO EXATA -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Top Level (Transição de entidades O):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.00      0.00      0.00        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.05      0.05      0.05       152\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.28      0.27      0.27       990\n",
            "  NOR_JURISPRUDÊNCIA       0.24      0.08      0.12       333\n",
            "       NOR_PRINCIPAL       0.17      0.26      0.21       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.50      0.01      0.02       122\n",
            "           PES_AUTOR       0.07      0.02      0.04       169\n",
            "PES_AUTORID_POLICIAL       0.38      0.17      0.23       300\n",
            "            PES_JUIZ       0.36      0.05      0.09        83\n",
            "          PES_OUTROS       0.27      0.11      0.16      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.24      0.19      0.21      1503\n",
            "      PES_TESTEMUNHA       0.43      0.07      0.13       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.23      0.14      0.17      7443\n",
            "           macro avg       0.14      0.06      0.07      7443\n",
            "        weighted avg       0.22      0.14      0.15      7443\n",
            "\n",
            "['B-END_AUTOR', 'B-END_DELITO', 'B-END_OUTROS', 'B-END_REU', 'B-END_TESTEMUNHA', 'B-END_VITIMA', 'B-NOR_ACESSORIA', 'B-NOR_JURISPRUDÊNCIA', 'B-NOR_PRINCIPAL', 'B-PENA', 'B-PES_ADVOG', 'B-PES_AUTOR', 'B-PES_AUTORID_POLICIAL', 'B-PES_JUIZ', 'B-PES_OUTROS', 'B-PES_PROMOTOR_MP', 'B-PES_REU', 'B-PES_TESTEMUNHA', 'B-PES_VITIMA', 'B-PROVA', 'B-SENTENÇA', 'I-END_AUTOR', 'I-END_DELITO', 'I-END_OUTROS', 'I-END_REU', 'I-END_TESTEMUNHA', 'I-END_VITIMA', 'I-NOR_ACESSORIA', 'I-NOR_JURISPRUDÊNCIA', 'I-NOR_PRINCIPAL', 'I-PENA', 'I-PES_ADVOG', 'I-PES_AUTOR', 'I-PES_AUTORID_POLICIAL', 'I-PES_JUIZ', 'I-PES_OUTROS', 'I-PES_PROMOTOR_MP', 'I-PES_REU', 'I-PES_TESTEMUNHA', 'I-PES_VITIMA', 'I-PROVA', 'I-SENTENÇA', 'O']\n",
            "[[     0      0      0 ...      0      0     13]\n",
            " [     0      4      0 ...      0      0     50]\n",
            " [     0      1      0 ...      0      0     73]\n",
            " ...\n",
            " [     0      0      0 ...      0      0   3861]\n",
            " [     0      0      0 ...      0      0    238]\n",
            " [     0      3      0 ...      0      0 476035]]\n",
            "----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Level Entity (Transição de entidades O):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.75      0.15      0.25        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.58      0.39      0.46       152\n",
            "      END_TESTEMUNHA       1.00      0.07      0.14        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.84      0.71      0.77       990\n",
            "  NOR_JURISPRUDÊNCIA       0.82      0.27      0.40       333\n",
            "       NOR_PRINCIPAL       0.72      0.80      0.76       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.50      0.01      0.02       122\n",
            "           PES_AUTOR       0.51      0.17      0.26       169\n",
            "PES_AUTORID_POLICIAL       0.79      0.30      0.43       300\n",
            "            PES_JUIZ       0.89      0.10      0.17        83\n",
            "          PES_OUTROS       0.63      0.21      0.32      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.63      0.37      0.47      1503\n",
            "      PES_TESTEMUNHA       0.88      0.13      0.23       519\n",
            "          PES_VITIMA       0.50      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.72      0.34      0.46      7443\n",
            "           macro avg       0.48      0.18      0.22      7443\n",
            "        weighted avg       0.63      0.34      0.40      7443\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18]\n",
            "B-END_DELITO\t[ 0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 52]\n",
            "B-END_OUTROS\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 81]\n",
            "B-END_REU\t[ 0  0  0 59  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 93]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  1  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 62]\n",
            "B-END_VITIMA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 702   1  73   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0 213]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   0  89   0   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0 243]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0  41   0 636   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 114]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 82]\n",
            "B-PES_ADVOG\t[  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0\n",
            "   0   0   0 120]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   0   0   0   0   0  29   0   0   0   0   4   0\n",
            "   0   0   0 136]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0  90   0   1   0   1   0\n",
            "   0   0   0 208]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  1  0  0  0  0 74]\n",
            "B-PES_OUTROS\t[  0   0   0   0   0   0   0   1   0   0   0   0   5   0 258   0  59   1\n",
            "   0   0   0 886]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 56]\n",
            "B-PES_REU\t[  0   0   0   0   0   0   0   0   0   0   0   0   1   0  31   0 555   1\n",
            "   0   0   0 915]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0  63  70\n",
            "   0   0   0 377]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   1   0   3   0  57   3\n",
            "   1   0   0 340]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   3   1\n",
            "   0   0   0 456]\n",
            "B-SENTENÇA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]\n",
            "O\t[     0      3      0     42      0      0     94     18    171      0\n",
            "      1     27     17      1    106      0    131      4      1      0\n",
            "      0 476035]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 5/10 [1:11:32<1:11:32, 858.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training loop.\n",
            "Train loss: 0.20399358874492463\n",
            "Train accuracy: 0.9362127630635477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting validation loop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log5: 801817 801817 801817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------\n",
            "Ajuste de transição inválida de entidade\n",
            "----- COMPARAÇÃO EXATA -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Top Level (Ajuste de transição):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.11      0.33      0.17        18\n",
            "          END_DELITO       0.07      0.21      0.11        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.10      0.22      0.14       152\n",
            "      END_TESTEMUNHA       0.28      0.35      0.31        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.17      0.29      0.22       990\n",
            "  NOR_JURISPRUDÊNCIA       0.19      0.28      0.23       333\n",
            "       NOR_PRINCIPAL       0.15      0.29      0.19       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.34      0.30      0.31       122\n",
            "           PES_AUTOR       0.13      0.11      0.12       169\n",
            "PES_AUTORID_POLICIAL       0.43      0.60      0.50       300\n",
            "            PES_JUIZ       0.45      0.54      0.49        83\n",
            "          PES_OUTROS       0.27      0.21      0.24      1210\n",
            "     PES_PROMOTOR_MP       0.26      0.25      0.25        57\n",
            "             PES_REU       0.23      0.31      0.26      1503\n",
            "      PES_TESTEMUNHA       0.30      0.20      0.24       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.21      0.24      0.22      7443\n",
            "           macro avg       0.17      0.21      0.18      7443\n",
            "        weighted avg       0.20      0.24      0.21      7443\n",
            "\n",
            "['B-END_AUTOR', 'B-END_DELITO', 'B-END_OUTROS', 'B-END_REU', 'B-END_TESTEMUNHA', 'B-END_VITIMA', 'B-NOR_ACESSORIA', 'B-NOR_JURISPRUDÊNCIA', 'B-NOR_PRINCIPAL', 'B-PENA', 'B-PES_ADVOG', 'B-PES_AUTOR', 'B-PES_AUTORID_POLICIAL', 'B-PES_JUIZ', 'B-PES_OUTROS', 'B-PES_PROMOTOR_MP', 'B-PES_REU', 'B-PES_TESTEMUNHA', 'B-PES_VITIMA', 'B-PROVA', 'B-SENTENÇA', 'I-END_AUTOR', 'I-END_DELITO', 'I-END_OUTROS', 'I-END_REU', 'I-END_TESTEMUNHA', 'I-END_VITIMA', 'I-NOR_ACESSORIA', 'I-NOR_JURISPRUDÊNCIA', 'I-NOR_PRINCIPAL', 'I-PENA', 'I-PES_ADVOG', 'I-PES_AUTOR', 'I-PES_AUTORID_POLICIAL', 'I-PES_JUIZ', 'I-PES_OUTROS', 'I-PES_PROMOTOR_MP', 'I-PES_REU', 'I-PES_TESTEMUNHA', 'I-PES_VITIMA', 'I-PROVA', 'I-SENTENÇA', 'O']\n",
            "[[     6      0      0 ...      0      0      5]\n",
            " [     0     24      0 ...      0      0     22]\n",
            " [     0      2      0 ...      0      0     69]\n",
            " ...\n",
            " [     0      1      0 ...    747      0   3028]\n",
            " [     0      0      0 ...      0      0    237]\n",
            " [    22     65     10 ...   1093      0 465773]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----\n",
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.43      0.83      0.57        18\n",
            "          END_DELITO       0.42      0.85      0.56        61\n",
            "          END_OUTROS       0.09      0.01      0.02        81\n",
            "             END_REU       0.46      0.73      0.57       152\n",
            "      END_TESTEMUNHA       0.56      0.62      0.59        68\n",
            "          END_VITIMA       1.00      0.07      0.14        27\n",
            "       NOR_ACESSORIA       0.55      0.84      0.67       990\n",
            "  NOR_JURISPRUDÊNCIA       0.63      0.97      0.77       333\n",
            "       NOR_PRINCIPAL       0.53      0.87      0.66       791\n",
            "                PENA       0.38      0.04      0.07        82\n",
            "           PES_ADVOG       0.69      0.61      0.65       122\n",
            "           PES_AUTOR       0.52      0.41      0.46       169\n",
            "PES_AUTORID_POLICIAL       0.69      0.86      0.77       300\n",
            "            PES_JUIZ       0.74      0.84      0.79        83\n",
            "          PES_OUTROS       0.60      0.43      0.51      1210\n",
            "     PES_PROMOTOR_MP       0.74      0.68      0.71        57\n",
            "             PES_REU       0.51      0.63      0.57      1503\n",
            "      PES_TESTEMUNHA       0.65      0.40      0.50       519\n",
            "          PES_VITIMA       0.31      0.01      0.02       405\n",
            "               PROVA       0.36      0.13      0.19       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.56      0.58      0.57      7443\n",
            "           macro avg       0.52      0.52      0.46      7443\n",
            "        weighted avg       0.54      0.58      0.53      7443\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[15  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2]\n",
            "B-END_DELITO\t[ 0 52  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6]\n",
            "B-END_OUTROS\t[ 1  1  1  5  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 70]\n",
            "B-END_REU\t[  2   7   0 111   4   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0  28]\n",
            "B-END_TESTEMUNHA\t[ 0  2  0  8 42  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16]\n",
            "B-END_VITIMA\t[ 0  2  0  6  7  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 833   4 118   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0  35]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   1 323   3   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   6]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0  75   3 691   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0  22]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0 79]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 74  1  0  1  0  1  1  0  0  0  0 44]\n",
            "B-PES_AUTOR\t[ 0  0  0  0  0  0  0  1  0  0  0 70  0  0  2  0 20  0  0  0  0 76]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0 258   0  12   0  12   2\n",
            "   0   0   0  16]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0 70  0  0  0  0  0  0  0 13]\n",
            "B-PES_OUTROS\t[  1   2   0   4   0   0   1  14   0   0   2   2  38   2 525   1 212  12\n",
            "   2   1   0 391]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1  0  3  0 39  3  0  0  0  0 11]\n",
            "B-PES_REU\t[  0   0   0   2   0   0   2   0   1   0   0  13   4   3  64   1 951  31\n",
            "   1   3   0 427]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   1   0   0   0   0   0   1   0   0   1  26   2 136 209\n",
            "   2   0   0 141]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   2   0  26   0 200  17\n",
            "   4   2   0 154]\n",
            "B-PROVA\t[  0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   5   5\n",
            "   0  59   0 390]\n",
            "B-SENTENÇA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 10]\n",
            "O\t[    16     58     10     99     18      0    594    166    482      5\n",
            "     30     47     72     15    213      9    310     48      4    100\n",
            "      0 465773]\n",
            "-----------------------------------------------\n",
            "Ajuste de transição inválida de entidade para O\n",
            "----- COMPARAÇÃO EXATA -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Top Level (Transição de entidades O):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.17      0.07      0.09        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.10      0.12      0.11       152\n",
            "      END_TESTEMUNHA       0.27      0.04      0.08        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.28      0.28      0.28       990\n",
            "  NOR_JURISPRUDÊNCIA       0.21      0.08      0.12       333\n",
            "       NOR_PRINCIPAL       0.19      0.27      0.23       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.25      0.01      0.02       122\n",
            "           PES_AUTOR       0.12      0.04      0.06       169\n",
            "PES_AUTORID_POLICIAL       0.40      0.24      0.30       300\n",
            "            PES_JUIZ       0.44      0.05      0.09        83\n",
            "          PES_OUTROS       0.28      0.13      0.17      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.24      0.19      0.21      1503\n",
            "      PES_TESTEMUNHA       0.41      0.11      0.17       519\n",
            "          PES_VITIMA       0.00      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.25      0.15      0.19      7443\n",
            "           macro avg       0.16      0.08      0.09      7443\n",
            "        weighted avg       0.22      0.15      0.17      7443\n",
            "\n",
            "['B-END_AUTOR', 'B-END_DELITO', 'B-END_OUTROS', 'B-END_REU', 'B-END_TESTEMUNHA', 'B-END_VITIMA', 'B-NOR_ACESSORIA', 'B-NOR_JURISPRUDÊNCIA', 'B-NOR_PRINCIPAL', 'B-PENA', 'B-PES_ADVOG', 'B-PES_AUTOR', 'B-PES_AUTORID_POLICIAL', 'B-PES_JUIZ', 'B-PES_OUTROS', 'B-PES_PROMOTOR_MP', 'B-PES_REU', 'B-PES_TESTEMUNHA', 'B-PES_VITIMA', 'B-PROVA', 'B-SENTENÇA', 'I-END_AUTOR', 'I-END_DELITO', 'I-END_OUTROS', 'I-END_REU', 'I-END_TESTEMUNHA', 'I-END_VITIMA', 'I-NOR_ACESSORIA', 'I-NOR_JURISPRUDÊNCIA', 'I-NOR_PRINCIPAL', 'I-PENA', 'I-PES_ADVOG', 'I-PES_AUTOR', 'I-PES_AUTORID_POLICIAL', 'I-PES_JUIZ', 'I-PES_OUTROS', 'I-PES_PROMOTOR_MP', 'I-PES_REU', 'I-PES_TESTEMUNHA', 'I-PES_VITIMA', 'I-PROVA', 'I-SENTENÇA', 'O']\n",
            "[[     0      0      0 ...      0      0     13]\n",
            " [     0      8      0 ...      0      0     46]\n",
            " [     0      1      0 ...      0      0     72]\n",
            " ...\n",
            " [     0      0      0 ...      0      0   3861]\n",
            " [     0      0      0 ...      0      0    238]\n",
            " [     0      4      0 ...      0      0 475955]]\n",
            "----- COMPARAÇÃO PARCIAL A NÍVEL DE ENTIDADE -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report Level Entity (Transição de entidades O):\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        18\n",
            "          END_DELITO       0.75      0.20      0.31        61\n",
            "          END_OUTROS       0.00      0.00      0.00        81\n",
            "             END_REU       0.57      0.43      0.49       152\n",
            "      END_TESTEMUNHA       0.70      0.10      0.18        68\n",
            "          END_VITIMA       0.00      0.00      0.00        27\n",
            "       NOR_ACESSORIA       0.85      0.74      0.79       990\n",
            "  NOR_JURISPRUDÊNCIA       0.83      0.32      0.46       333\n",
            "       NOR_PRINCIPAL       0.73      0.79      0.76       791\n",
            "                PENA       0.00      0.00      0.00        82\n",
            "           PES_ADVOG       0.67      0.02      0.03       122\n",
            "           PES_AUTOR       0.51      0.15      0.23       169\n",
            "PES_AUTORID_POLICIAL       0.85      0.43      0.57       300\n",
            "            PES_JUIZ       0.89      0.10      0.17        83\n",
            "          PES_OUTROS       0.64      0.23      0.34      1210\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        57\n",
            "             PES_REU       0.63      0.37      0.47      1503\n",
            "      PES_TESTEMUNHA       0.84      0.19      0.31       519\n",
            "          PES_VITIMA       0.25      0.00      0.00       405\n",
            "               PROVA       0.00      0.00      0.00       461\n",
            "            SENTENÇA       0.00      0.00      0.00        11\n",
            "\n",
            "           micro avg       0.73      0.36      0.48      7443\n",
            "           macro avg       0.46      0.19      0.24      7443\n",
            "        weighted avg       0.62      0.36      0.42      7443\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18]\n",
            "B-END_DELITO\t[ 0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 49]\n",
            "B-END_OUTROS\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 81]\n",
            "B-END_REU\t[ 0  0  0 65  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 84]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  2  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 59]\n",
            "B-END_VITIMA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 736   1  71   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 182]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   0 105   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 228]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0  32   0 628   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 131]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 82]\n",
            "B-PES_ADVOG\t[  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1   0\n",
            "   0   0   0 119]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0   4   0\n",
            "   0   0   0 140]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0 129   0   1   0   0   0\n",
            "   0   0   0 170]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0 75]\n",
            "B-PES_OUTROS\t[  0   0   0   0   0   0   0   1   0   0   0   0   3   0 283   0  55   1\n",
            "   0   0   0 867]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57]\n",
            "B-PES_REU\t[  0   0   0   0   0   0   0   0   0   0   0   0   1   0  31   0 557   4\n",
            "   0   0   0 910]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   7   0  70  97\n",
            "   2   0   0 343]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0  63   4\n",
            "   1   0   0 335]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   3   1\n",
            "   0   0   0 456]\n",
            "B-SENTENÇA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]\n",
            "O\t[     0      4      0     47      0      0    100     20    165      0\n",
            "      1     24     18      1    115      0    136      8      1      0\n",
            "      0 475955]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 6/10 [1:25:44<57:05, 856.32s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training loop.\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda'\n",
        "\n",
        "#Colab Checkpoint 40k\n",
        "path_output_model = ''\n",
        "train_and_save_model(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    optimizer,\n",
        "    verbose,\n",
        "    epochs,\n",
        "    idx2tag,\n",
        "    tag2idx,\n",
        "    path_output_model,\n",
        "    device,\n",
        "    train_dataloader,\n",
        "    valid_dataloader\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SpaCy"
      ],
      "metadata": {
        "id": "4h5lyLorxL-l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3biSU47DYrbc",
        "outputId": "94e56d14-7ed2-4f8a-a512-2deb0d350d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 563 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=4cd6be2ccb7145bf3e7a40b1761b1cce01e16278bc0fd2f96d723ec758ca1e2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POB3YOmGYvu4",
        "outputId": "be1aeb97-cae0-4d24-fe78-34f11836ea51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWG-WPxOYjoy"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.lang.pt.examples import sentences\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import random\n",
        "from spacy.util import minibatch, compounding\n",
        "from spacy.training import Example\n",
        "import tqdm\n",
        "import re\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJapAUWzd7wv"
      },
      "outputs": [],
      "source": [
        "data_revisao = '131022'\n",
        "\n",
        "model_train = '/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_spacy/model/'\n",
        "path_train = f'/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_revisao_{data_revisao}/exp1/treino.conll'\n",
        "path_teste = f'/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_revisao_{data_revisao}/exp1/teste.conll'\n",
        "path_train_saida = f'/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_revisao_{data_revisao}/spacy/examples_train.txt'\n",
        "path_teste_saida = f'/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_revisao_{data_revisao}/spacy/teste_output.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUDarlzIg9tw",
        "outputId": "52d49d92-04dd-4017-a7b7-c88d12ab8fc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-14 09:44:57.941711: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pt-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.4.0/pt_core_news_sm-3.4.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.0 MB 463 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from pt-core-news-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (8.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.1)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download pt_core_news_sm\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmjhyNsDdX_i"
      },
      "outputs": [],
      "source": [
        "def get_train_data(test, input_train_file, output_train_file):\n",
        "    train_data, labels_cdjur, entities = [], [], []\n",
        "    start, end, index = 0, 0, 0\n",
        "    text = ''\n",
        "\n",
        "    file_reader = open(input_train_file)\n",
        "    label = ''\n",
        "    for line in tqdm.tqdm(file_reader.readlines()):\n",
        "        #quebra de linha\n",
        "        if line.endswith('.txt\\n'): #if (line == '\\n'):#len(tokens) < 2 or line == '\\n':\n",
        "            if label != '':\n",
        "                entities.append((start, end, label))\n",
        "\n",
        "            #Verifica se na sentença tem entidades nomeadas\n",
        "            #if test == 1 or len(entities) > 0:\n",
        "            train_data.append((text, {\"entities\" : entities}))\n",
        "\n",
        "            #reinicializa variaveis\n",
        "            entities = []\n",
        "            text, label = '', ''\n",
        "            index, start, end = 0, 0, 0\n",
        "        else:\n",
        "            tokens = line.split()\n",
        "            if len(tokens) == 2:\n",
        "                text_token = tokens[0]\n",
        "                label_token = tokens[-1]\n",
        "\n",
        "                text += text_token + ' '\n",
        "\n",
        "                #Verifica se finalizou a entidade\n",
        "                if (label_token == 'O' or label_token.startswith('B')):\n",
        "                    if label != '':\n",
        "                      entities.append((start, end, label))\n",
        "                      if label not in labels_cdjur:\n",
        "                          labels_cdjur.append(label)\n",
        "                    label = ''\n",
        "                    start = 0\n",
        "                    end = 0\n",
        "\n",
        "                if label_token.startswith('B'):\n",
        "                    start = index\n",
        "                    end = index + len(text_token)\n",
        "                    label = label_token[2:]\n",
        "\n",
        "                if label_token.startswith('I'):\n",
        "                    end = index + len(text_token)\n",
        "\n",
        "                index = len(text)\n",
        "\n",
        "            if len(tokens) > 2:\n",
        "                print('error')\n",
        "\n",
        "    if label != '':\n",
        "      entities.append((start, end, label))\n",
        "\n",
        "    if len(entities) > 0:\n",
        "      #Verifica se na sentença tem entidades nomeadas\n",
        "      #if test == 1 or len(entities) > 0:\n",
        "      train_data.append((text, {\"entities\" : entities}))\n",
        "\n",
        "    with open(output_train_file, 'wb') as fp:\n",
        "        pickle.dump(train_data, fp)\n",
        "\n",
        "    print('Salvou os dados de treinamnto!')\n",
        "    return train_data, labels_cdjur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-26LNKYddjET"
      },
      "outputs": [],
      "source": [
        "#Train the spaCy with new data\n",
        "#model = model used to load spaCy (None = considers model blank)\n",
        "#n_iter = number iterations\n",
        "#train_data = data with new entities\n",
        "#output_dir = diretory to save the model\n",
        "def train(model, n_iter, train_data, output_dir, labels_cdjur):\n",
        "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
        "    if model is not None:\n",
        "        nlp = spacy.load(model)  # load existing spaCy model\n",
        "        print(\"Loaded model '%s'\" % model)\n",
        "    else:\n",
        "        nlp = spacy.blank(\"pt\")  # create blank Language class\n",
        "        print(\"Created blank 'pt' model\")\n",
        "\n",
        "    # create the built-in pipeline components and add them to the pipeline\n",
        "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
        "    if \"ner\" not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe(\"ner\")\n",
        "        nlp.add_pipe(\"ner\", last=True)\n",
        "    # otherwise, get it so we can add labels\n",
        "    else:\n",
        "        ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "    # Add new entity labels to entity recognizer\n",
        "    for i in labels_cdjur:\n",
        "        ner.add_label(i)\n",
        "    move_names = list(ner.move_names)\n",
        "\n",
        "    # add labels\n",
        "    #for _,annotations in train_data:\n",
        "    #    for ent in annotations.get(\"entities\"):\n",
        "    #        ner.add_label(ent[2])\n",
        "\n",
        "    # get names of other pipes to disable them during training\n",
        "    #pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "    #other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    # only train NER\n",
        "    with nlp.disable_pipes(*other_pipes):\n",
        "        # reset and initialize the weights randomly – but only if we're\n",
        "        # training a new model\n",
        "        if model is None:\n",
        "            optimizer = nlp.begin_training()\n",
        "            #optimizer = nlp.create_optimizer()\n",
        "        else:\n",
        "            #optimizer = nlp.initialize()\n",
        "            optimizer = nlp.resume_training()\n",
        "\n",
        "        for i in range(n_iter):\n",
        "            random.shuffle(train_data)\n",
        "            losses = {}\n",
        "            batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
        "            for batch in tqdm.tqdm(batches):\n",
        "                examples = []\n",
        "                for text, annots in batch:\n",
        "                    examples.append(Example.from_dict(nlp.make_doc(text), annots))\n",
        "                losses = nlp.update(examples, sgd=optimizer)\n",
        "            print(\"Losses\", losses)\n",
        "\n",
        "    # test the trained model\n",
        "    #for text, _ in train_data:\n",
        "        #doc = nlp(text)\n",
        "        #print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "        #print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
        "\n",
        "    # save model to output directory\n",
        "    if output_dir is not None:\n",
        "        output_dir = Path(output_dir)\n",
        "        if not output_dir.exists():\n",
        "            output_dir.mkdir()\n",
        "        nlp.to_disk(output_dir)\n",
        "        print(\"Saved model to\", output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr4WlGOTd-tC"
      },
      "outputs": [],
      "source": [
        "def run_train():\n",
        "  model_spacy_pt = \"pt_core_news_sm\"\n",
        "\n",
        "  train_data, labels_cdjur = get_train_data(0, path_train, path_train_saida)\n",
        "  with open (path_train_saida, 'rb') as fp:\n",
        "      train_data = pickle.load(fp)\n",
        "\n",
        "  print(len(train_data))\n",
        "\n",
        "  train(model_spacy_pt, 20, train_data, model_train, labels_cdjur)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a8FNOJSYfGM"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def level_entity_new (labels, preds):\n",
        "\n",
        "  labels_cm, preds_cm = [], []\n",
        "\n",
        "  for id, lab in enumerate(labels):\n",
        "    encontrou = False\n",
        "    #verifica a predição das entidades != de O\n",
        "    if lab.startswith('B-'):\n",
        "      encontrou = False\n",
        "      id_inicio, id_fim = id, id\n",
        "\n",
        "      #verifica onde termina a entidade\n",
        "      for id_prox in range(id+1, len(labels)):\n",
        "        if not labels[id_prox].startswith('I-'):\n",
        "          id_fim = id_prox - 1\n",
        "          break\n",
        "\n",
        "      ent_pred = 'O'\n",
        "      for id_pred in range(id_inicio, id_fim+1):\n",
        "        if preds[id_pred][2:] == lab[2:]:\n",
        "          ent_pred = preds[id_pred]\n",
        "          encontrou = True\n",
        "          break\n",
        "        else:\n",
        "          ent_pred = preds[id_pred]\n",
        "\n",
        "      labels_cm.append(lab)\n",
        "      if ent_pred == 'O':\n",
        "        preds_cm.append('O')\n",
        "      else:\n",
        "        preds_cm.append('B-' + ent_pred[2:])\n",
        "    elif lab == 'O':\n",
        "      #verifica se a predição e a label são O ou se a predição é uma parte da label e já foi contada anteriormente\n",
        "      if preds[id] == lab or encontrou:\n",
        "        labels_cm.append('O')\n",
        "        preds_cm.append('O')\n",
        "      else:\n",
        "        if preds[id].startswith('B-'):\n",
        "          encontrou_pred = False\n",
        "          #verifica até onde termina a entidade se terá uma label real\n",
        "          for id_prox in range(id+1, len(labels)):\n",
        "            if preds[id_prox].startswith('I-'):\n",
        "              if labels[id_prox] != 'O':\n",
        "                encontrou_pred = True\n",
        "                break\n",
        "            else:\n",
        "              break\n",
        "          #se não tiver label anotada em toda a entidade predita, adiciona;\n",
        "          #caso contrário, não adiciona, pois será adicionado pela verificação da label\n",
        "          if not encontrou_pred:\n",
        "            labels_cm.append('O')\n",
        "            preds_cm.append('B-' + preds[id][2:])\n",
        "\n",
        "  cr = classification_report([labels_cm], [preds_cm])\n",
        "\n",
        "  header = sorted(list(set(labels_cm + preds_cm)))\n",
        "  cm = confusion_matrix(labels_cm, preds_cm, labels=header)\n",
        "  mat_formatted = [header[i] + \"\\t\" + str(row) for i, row in enumerate(cm)]\n",
        "  content_cm = \"\\t\" + \" \".join(header) + \"\\n\" + \"\\n\".join(mat_formatted)\n",
        "\n",
        "  return cr, content_cm\n",
        "\n",
        "def level_entity (labels, preds):\n",
        "\n",
        "  labels_cm, preds_cm = [], []\n",
        "  inicio = 0#, antes, depois = 0, 0, 0\n",
        "  aux_preds = {}\n",
        "\n",
        "  def add_pred_entity(aux_preds, label_true):\n",
        "    tag_pred = None\n",
        "    if (len(aux_preds) > 1 and label_true[2:] in aux_preds):\n",
        "      aux_preds.pop(label_true[2:])\n",
        "      if (len(aux_preds) == 1 and 'O' in aux_preds):\n",
        "        tag_pred = label_true[2:]\n",
        "        #antes += 1\n",
        "\n",
        "    if tag_pred == None:\n",
        "      tag_pred = max(aux_preds, key = lambda chave: aux_preds[chave])\n",
        "\n",
        "    if len(tag_pred) > 1:\n",
        "      tag_pred = 'B-' + tag_pred\n",
        "    preds_cm.append(tag_pred)\n",
        "    return 0, {}\n",
        "\n",
        "  for index in range(0, len(labels)):\n",
        "    if labels[index] == 'O':\n",
        "      if inicio == 1:\n",
        "        inicio, aux_preds = add_pred_entity(aux_preds, labels_cm[len(labels_cm)-1])\n",
        "      labels_cm.append(labels[index])\n",
        "\n",
        "      if preds[index].startswith('I'):\n",
        "        preds_cm.append('O')\n",
        "        #depois += 1\n",
        "      else:\n",
        "        preds_cm.append(preds[index])\n",
        "\n",
        "    else:\n",
        "      if labels[index].startswith('B'):\n",
        "        if inicio == 1:\n",
        "          inicio, aux_preds = add_pred_entity(aux_preds, labels_cm[len(labels_cm)-1])\n",
        "        labels_cm.append(labels[index])\n",
        "        inicio = 1\n",
        "\n",
        "        tag = preds[index]\n",
        "        if len(tag) > 1:\n",
        "          tag = tag[2:]\n",
        "\n",
        "        if tag in aux_preds:\n",
        "          aux_preds[tag] += 1\n",
        "        else:\n",
        "          aux_preds[tag] = 1\n",
        "\n",
        "      elif labels[index].startswith('I'):\n",
        "        tag = preds[index]\n",
        "        if len(tag) > 1:\n",
        "          tag = tag[2:]\n",
        "\n",
        "        if tag in aux_preds:\n",
        "          aux_preds[tag] += 1\n",
        "        else:\n",
        "          aux_preds[tag] = 1\n",
        "\n",
        "  if inicio == 1:\n",
        "    inicio, aux_preds = add_pred_entity(aux_preds, labels_cm[len(labels_cm)-1])\n",
        "\n",
        "  #print(labels_cm)\n",
        "  #print(preds_cm)\n",
        "\n",
        "  cr = classification_report([labels_cm], [preds_cm])\n",
        "\n",
        "  header = sorted(list(set(labels_cm + preds_cm)))\n",
        "  cm = confusion_matrix(labels_cm, preds_cm, labels=header)\n",
        "  mat_formatted = [header[i] + \"\\t\" + str(row) for i, row in enumerate(cm)]\n",
        "  content_cm = \"\\t\" + \" \".join(header) + \"\\n\" + \"\\n\".join(mat_formatted)\n",
        "\n",
        "  #print(cr)\n",
        "  #print(content_cm)\n",
        "\n",
        "  #print('Antes: ' + str(antes))\n",
        "  #print('Depois: ' + str(depois))\n",
        "\n",
        "  return cr, content_cm\n",
        "\n",
        "def run_test():\n",
        "    nlp = spacy.load(model_train)\n",
        "\n",
        "    # Carrega configurações básicas\n",
        "    punkt_param = PunktParameters()\n",
        "    with open(\"/content/drive/MyDrive/UNIFOR/NER/abbrev_list.pkl\", \"rb\") as fp:\n",
        "        abbrev_list = pickle.load(fp)\n",
        "\n",
        "    punkt_param.abbrev_types = set(abbrev_list)\n",
        "    tokenizer = PunktSentenceTokenizer(punkt_param)\n",
        "\n",
        "    labels_true = []\n",
        "    labels_predicted = []\n",
        "\n",
        "    with open(path_teste, 'r', errors=\"surrogateescape\") as txt_file:\n",
        "        data = {}\n",
        "        data['ner'] = []\n",
        "        sentence = ''\n",
        "        label_true_sentence = []\n",
        "        tokens_true_sentence = []\n",
        "        linhas = txt_file.readlines()\n",
        "        id_linha = -1\n",
        "        for linha in linhas:\n",
        "            id_linha += 1\n",
        "            if linha.endswith('.txt\\n') or id_linha == len(linhas)-1: #Condição que representa a finalização da sentença\n",
        "                doc = nlp(sentence)\n",
        "                entities_file = []\n",
        "                for ent in doc.ents:\n",
        "                    entities = {}\n",
        "                    entities['start'] = ent.start_char\n",
        "                    entities['end'] = ent.end_char\n",
        "                    entities['label'] = ent.label_\n",
        "                    entities['entity'] = ent.text\n",
        "                    entities_file.append(entities)\n",
        "\n",
        "                tokens = sentence.split() #word_tokenize(sentence, language='portuguese')\n",
        "                label_predicted_sentence = []\n",
        "                idx_start, idx_end, idx_token = 0, 0, 0\n",
        "                for t in tokens:\n",
        "                    idx_end += len(t)\n",
        "                    label_predicted_sentence.append(check_entity(entities_file, idx_start, idx_end))\n",
        "                    idx_end += 1 #Aumenta 1 por conta do espaço\n",
        "                    idx_start = idx_end\n",
        "\n",
        "                    if t != tokens_true_sentence[idx_token]:\n",
        "                        print('verificar')\n",
        "\n",
        "                    #print(t + ' -> ' + label_predicted_sentence[idx_token] + ' -> ' + tokens_true_sentence[idx_token] + ' -> ' + label_true_sentence[idx_token])\n",
        "                    idx_token += 1\n",
        "\n",
        "                data['ner'].append({'sentence': sentence, 'label_true': label_true_sentence, 'label_predicted': label_predicted_sentence, 'entities': entities_file})\n",
        "                labels_true.append(label_true_sentence)\n",
        "                labels_predicted.append(label_predicted_sentence)\n",
        "\n",
        "                sentence = ''\n",
        "                label_true_sentence = []\n",
        "                tokens_true_sentence = []\n",
        "\n",
        "            else:\n",
        "                if linha == '\\n':\n",
        "                  continue\n",
        "                sentence += linha.split()[0].strip() + ' '\n",
        "                tokens_true_sentence.append(linha.split()[0].strip())\n",
        "                label_true_sentence.append(linha.split()[-1])\n",
        "\n",
        "    with open(path_teste_saida, 'w', encoding=\"utf-8\") as f:\n",
        "            json.dump(data, f, ensure_ascii=False)\n",
        "\n",
        "    print('Avaliação exata:')\n",
        "    print(classification_report(labels_true, labels_predicted))\n",
        "\n",
        "    print('Avaliação parcial:')\n",
        "    labels_, predicted_ = [], []\n",
        "    for l in labels_true:\n",
        "      labels_.extend(l)\n",
        "\n",
        "    for l in labels_predicted:\n",
        "      predicted_.extend(l)\n",
        "\n",
        "    cr, content_cm = level_entity_new(labels_, predicted_)\n",
        "    print(cr)\n",
        "    print(content_cm)\n",
        "\n",
        "    return labels_true, labels_predicted\n",
        "\n",
        "def check_entity(entities, start, end):\n",
        "    for e in entities:\n",
        "        if start >= e['start'] and end <= e['end']:\n",
        "            if start == e['start']:\n",
        "                return 'B-' + e['label']\n",
        "            else:\n",
        "                return 'I-' + e['label']\n",
        "    return 'O'\n",
        "\n",
        "def calculate_metrics():\n",
        "\n",
        "    predictions, true_labels = [], []\n",
        "    arquivo_labeled = open(path_teste).readlines()\n",
        "    id_linha = 0\n",
        "    with open(path_teste_saida, \"r\") as json_file:\n",
        "        dados = json.load(json_file)\n",
        "        ner = dados['ner']\n",
        "        id_token = 0\n",
        "        for item in ner:\n",
        "            text = item['sentence']\n",
        "            entities = item['entities']\n",
        "\n",
        "            tokens = word_tokenize(text, language='portuguese')#text.split()\n",
        "            predict_labels = []\n",
        "            idx_start = 0\n",
        "            idx_end = 0\n",
        "\n",
        "            for t in tokens:\n",
        "                while arquivo_labeled[id_linha] == '\\n': #or t != arquivo_labeled[id_linha].split()[0]:\n",
        "                    id_linha += 1\n",
        "\n",
        "                if t != arquivo_labeled[id_linha].split()[0]:\n",
        "                    print('verificar')\n",
        "                    if t == '.' or t == ',':\n",
        "                        continue\n",
        "                    if t == 's/n-':\n",
        "                        t = 's/n'\n",
        "\n",
        "                idx_end += len(t)\n",
        "                label_predicted = check_entity(entities, idx_start, idx_end)\n",
        "                label_true = arquivo_labeled[id_linha].split()[-1]\n",
        "                predict_labels.append(label_predicted)\n",
        "                true_labels.append(label_true)\n",
        "                idx_end += 1 #Aumenta 1 por conta do espaço\n",
        "                idx_start = idx_end\n",
        "\n",
        "                print(t + ' -> ' + label_predicted + ' -> texto ' + arquivo_labeled[id_linha].split()[0] + ' -> ' + label_true + ' ' + str(id_linha))\n",
        "                id_token += 1\n",
        "                id_linha += 1\n",
        "            #id_linha += 1\n",
        "    print(classification_report(label_true, predict_labels))\n",
        "            #arquivo_ner = pd.read_json(os.path.join(p, file)) #open(file).read()\n",
        "            #texto = arquivo_ner['text']\n",
        "            #entities = arquivo_ner['entities']\n",
        "            #print(file)\n",
        "\n",
        "def check_train():\n",
        "\n",
        "    arquivo = open(path_train)\n",
        "    #753\n",
        "    #1763\n",
        "    #881\n",
        "    #851\n",
        "    q = 0\n",
        "    for linha in arquivo.readlines():\n",
        "    #print(linha)\n",
        "        if (linha == '\\n'):\n",
        "            q += 1\n",
        "    print(q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1ICIeiFiYW9",
        "outputId": "f09d7f93-dc46-4126-f1ec-b8223855529e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 809031/809031 [00:01<00:00, 600541.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Salvou os dados de treinamnto!\n",
            "479\n",
            "Loaded model 'pt_core_news_sm'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:27,  1.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 194.17085361602494}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:23,  1.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 250.53025011718273}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:21,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 476.5297223329544}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:21,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 275.50438294233754}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:21,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 78.14579775697348}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:22,  1.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 35.57692730750861}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:21,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 142.6809968839807}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:22,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 33.6059890614122}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:22,  1.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 202.6519670067355}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:23,  1.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 270.2744608440553}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:21,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 71.87824034427467}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:22,  1.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 184.63363794970792}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:21,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 26.67282293823026}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:23,  1.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 892.3872776031494}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:21,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 356.1851268680766}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:22,  1.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 25.586703288049236}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:21,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 38.34211225478701}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:21,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 92.86686859592555}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:22,  1.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 181.3635348661337}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "120it [02:22,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 29.124611595515262}\n",
            "Saved model to /content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_spacy/model\n"
          ]
        }
      ],
      "source": [
        "run_train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77DPsNMSimFq",
        "outputId": "0ce06053-4a67-4919-da00-9c257f050b00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avaliação exata:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.03      0.03      0.03        40\n",
            "          END_DELITO       0.37      0.24      0.29       156\n",
            "          END_OUTROS       0.00      0.00      0.00       153\n",
            "             END_REU       0.29      0.50      0.37       283\n",
            "      END_TESTEMUNHA       0.56      0.12      0.20       120\n",
            "          END_VITIMA       0.00      0.00      0.00        69\n",
            "       NOR_ACESSORIA       0.61      0.66      0.63      2365\n",
            "  NOR_JURISPRUDÊNCIA       0.43      0.42      0.42       753\n",
            "       NOR_PRINCIPAL       0.65      0.58      0.61      2747\n",
            "                PENA       0.38      0.37      0.38       139\n",
            "           PES_ADVOG       0.07      0.13      0.09       228\n",
            "           PES_AUTOR       0.45      0.42      0.43       481\n",
            "PES_AUTORID_POLICIAL       0.69      0.24      0.36       822\n",
            "            PES_JUIZ       0.61      0.30      0.40       183\n",
            "          PES_OUTROS       0.41      0.26      0.32      2652\n",
            "     PES_PROMOTOR_MP       0.39      0.12      0.18       158\n",
            "             PES_REU       0.55      0.55      0.55      3522\n",
            "      PES_TESTEMUNHA       0.37      0.40      0.38      1140\n",
            "          PES_VITIMA       0.43      0.26      0.32       781\n",
            "               PROVA       0.15      0.07      0.09      1132\n",
            "            SENTENÇA       0.08      0.03      0.05        29\n",
            "\n",
            "           micro avg       0.50      0.42      0.46     17953\n",
            "           macro avg       0.36      0.27      0.29     17953\n",
            "        weighted avg       0.49      0.42      0.44     17953\n",
            "\n",
            "Avaliação parcial:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.29      0.23      0.25        40\n",
            "          END_DELITO       0.47      0.29      0.36       156\n",
            "          END_OUTROS       0.00      0.00      0.00       153\n",
            "             END_REU       0.45      0.72      0.56       283\n",
            "      END_TESTEMUNHA       0.71      0.14      0.24       120\n",
            "          END_VITIMA       1.00      0.01      0.03        69\n",
            "       NOR_ACESSORIA       0.74      0.78      0.76      2365\n",
            "  NOR_JURISPRUDÊNCIA       0.87      0.84      0.85       753\n",
            "       NOR_PRINCIPAL       0.82      0.72      0.76      2747\n",
            "                PENA       0.43      0.42      0.42       139\n",
            "           PES_ADVOG       0.12      0.21      0.16       228\n",
            "           PES_AUTOR       0.50      0.47      0.48       481\n",
            "PES_AUTORID_POLICIAL       0.91      0.32      0.47       822\n",
            "            PES_JUIZ       0.72      0.34      0.46       183\n",
            "          PES_OUTROS       0.50      0.31      0.38      2652\n",
            "     PES_PROMOTOR_MP       0.54      0.16      0.25       158\n",
            "             PES_REU       0.64      0.62      0.63      3522\n",
            "      PES_TESTEMUNHA       0.47      0.47      0.47      1140\n",
            "          PES_VITIMA       0.51      0.29      0.37       781\n",
            "               PROVA       0.45      0.19      0.27      1132\n",
            "            SENTENÇA       0.43      0.21      0.28        29\n",
            "\n",
            "           micro avg       0.64      0.52      0.57     17953\n",
            "           macro avg       0.55      0.37      0.40     17953\n",
            "        weighted avg       0.63      0.52      0.56     17953\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 9  1  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18]\n",
            "B-END_DELITO\t[ 0 46  0 21  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0  0  0 87]\n",
            "B-END_OUTROS\t[  0   6   0  19   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0 128]\n",
            "B-END_REU\t[  2   2   0 205   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
            "   0   1   0  72]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0 71 17  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0 31]\n",
            "B-END_VITIMA\t[ 0  2  0 28  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 38]\n",
            "B-NOR_ACESSORIA\t[   0    0    0    0    0    0 1850    6  319    0    0    0    0    0\n",
            "    0    0    0    1    0    0    0  189]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   1   0   0   3 631   0   0   0   0   0   0   0   0   0   1\n",
            "   0   1   0 116]\n",
            "B-NOR_PRINCIPAL\t[   0    0    0    3    1    0  493    3 1973    1    0    0    0    0\n",
            "    0    0    2    0    2    2    0  267]\n",
            "B-PENA\t[ 1  0  1  0  0  0  0  0  1 58  0  0  0  0  0  0  0  0  0  0  0 78]\n",
            "B-PES_ADVOG\t[  0   0   0   0   0   0   0   0   0   0  49   2   0   3  13   0  22   9\n",
            "   4   0   0 126]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   0   0   0   3   0 225   0   0  23   2  29   4\n",
            "   2   0   0 193]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   1 118   0 263   1  38   6  58  27\n",
            "   9   5   0 296]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0 36  0  0 63  7  3  2  2  2  0  0 68]\n",
            "B-PES_OUTROS\t[   0    5    0    1    0    0    0    4    2    0   41   15    8    4\n",
            "  817    0  331  109   39    0    0 1276]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0 44  6  0  1  6 25  6  4  7  0  0 59]\n",
            "B-PES_REU\t[   0    2    0    0    0    0    1    3    0    0   12   13    3    0\n",
            "  181    0 2181  215   64    9    2  836]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   1   0   0   0   5   0   0   6   1   5   0  58   0 184 536\n",
            "  31   0   0 313]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   1   2   2   0  90   4 111  86\n",
            " 228   2   0 255]\n",
            "B-PROVA\t[  0   2   0   0   0   0   0   0   1   2   0   1   0   0   2   0   4   7\n",
            "   1 215   0 897]\n",
            "B-SENTENÇA\t[ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  6 22]\n",
            "O\t[    19     31     11     89      6      0    146     73    123     68\n",
            "     89    185      9     16    391      6    477    147     62    244\n",
            "      6 726462]\n"
          ]
        }
      ],
      "source": [
        "labels_true, labels_predicted = run_test()\n",
        "#calculate_metrics()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM + CRF"
      ],
      "metadata": {
        "id": "G8D5UpKIxVyl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKbx9uZdhAZz"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Code modified by the authors of leNER-Br:\n",
        "    Line split on space instead of tab\n",
        "    Add preprocessing step of replacing digits with zeros\n",
        "    Add function create_tag_dict\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "\n",
        "\n",
        "# shared global variables to be imported from model also\n",
        "UNK = \"$UNK$\"\n",
        "NUM = \"$NUM$\"\n",
        "NONE = \"O\"\n",
        "\n",
        "\n",
        "# special error message\n",
        "class MyIOError(Exception):\n",
        "    def __init__(self, filename):\n",
        "        # custom error message\n",
        "        message = \"\"\"\n",
        "ERROR: Unable to locate file {}.\n",
        "\n",
        "FIX: Have you tried running python build_data.py first?\n",
        "This will build vocab file from your train, test and dev sets and\n",
        "trimm your word vectors.\n",
        "\"\"\".format(filename)\n",
        "        super(MyIOError, self).__init__(message)\n",
        "\n",
        "\n",
        "class CoNLLDataset(object):\n",
        "    \"\"\"Class that iterates over CoNLL Dataset\n",
        "\n",
        "    __iter__ method yields a tuple (words, tags)\n",
        "        words: list of raw words\n",
        "        tags: list of raw tags\n",
        "\n",
        "    If processing_word and processing_tag are not None,\n",
        "    optional preprocessing is appplied\n",
        "\n",
        "    Example:\n",
        "        ```python\n",
        "        data = CoNLLDataset(filename)\n",
        "        for sentence, tags in data:\n",
        "            pass\n",
        "        ```\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, filename, processing_word=None, processing_tag=None,\n",
        "                 max_iter=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            filename: path to the file\n",
        "            processing_words: (optional) function that takes a word as input\n",
        "            processing_tags: (optional) function that takes a tag as input\n",
        "            max_iter: (optional) max number of sentences to yield\n",
        "\n",
        "        \"\"\"\n",
        "        self.filename = filename\n",
        "        self.processing_word = processing_word\n",
        "        self.processing_tag = processing_tag\n",
        "        self.max_iter = max_iter\n",
        "        self.length = None\n",
        "\n",
        "\n",
        "    def __iter__(self):\n",
        "        niter = 0\n",
        "        n_line = 0\n",
        "        #print('começando a ler o arquivo')\n",
        "        with open(self.filename) as f:\n",
        "            words, tags = [], []\n",
        "            linhas = f.readlines()\n",
        "            id_linha = -1\n",
        "            for line in linhas:\n",
        "                id_linha += 1\n",
        "                n_line += 1\n",
        "                #line = line.strip()\n",
        "                if (len(line.split()) == 0 or line.startswith(\"-DOCSTART-\") or line.endswith('.txt\\n') or id_linha == len(linhas)-1):\n",
        "                #if line.endswith('.txt\\n') or id_linha == len(linhas)-1:\n",
        "                    #print('line:', line)\n",
        "                    if len(words) != 0:\n",
        "                        niter += 1\n",
        "                        if self.max_iter is not None and niter > self.max_iter:\n",
        "                            break\n",
        "                        #print('words', words)\n",
        "                        #print('tags', tags)\n",
        "                        yield words, tags\n",
        "                        words, tags = [], []\n",
        "                else:\n",
        "                    ls = line.split()\n",
        "                    if len(ls) == 2:\n",
        "                      word, tag = ls[0], ls[-1]\n",
        "                      if tag == ',':\n",
        "                          print(n_line)\n",
        "                      if self.processing_word is not None:\n",
        "                          word = self.processing_word(word)\n",
        "                      try:\n",
        "                        if self.processing_tag is not None:\n",
        "                            tag = self.processing_tag(tag)\n",
        "                      except:\n",
        "                        print('erro ao obter a tag', tag)\n",
        "                      words += [word]\n",
        "                      tags += [tag]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Iterates once over the corpus to set and store length\"\"\"\n",
        "        if self.length is None:\n",
        "            self.length = 0\n",
        "            for _ in self:\n",
        "                self.length += 1\n",
        "\n",
        "        return self.length\n",
        "\n",
        "\n",
        "def get_vocabs(datasets):\n",
        "    \"\"\"Build vocabulary from an iterable of datasets objects\n",
        "\n",
        "    Args:\n",
        "        datasets: a list of dataset objects\n",
        "\n",
        "    Returns:\n",
        "        a set of all the words in the dataset\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"Building vocab...\")\n",
        "    vocab_words = set()\n",
        "    vocab_tags = set()\n",
        "    for dataset in datasets:\n",
        "        for words, tags in dataset:\n",
        "          #print('words:')\n",
        "          #print(words)\n",
        "          #print('tags')\n",
        "          #print(tags)\n",
        "          if words != '' and tags != '':\n",
        "            vocab_words.update(words)\n",
        "            vocab_tags.update(tags)\n",
        "    print(\"- done. {} tokens\".format(len(vocab_words)))\n",
        "    return vocab_words, vocab_tags\n",
        "\n",
        "\n",
        "def get_char_vocab(dataset):\n",
        "    \"\"\"Build char vocabulary from an iterable of datasets objects\n",
        "\n",
        "    Args:\n",
        "        dataset: a iterator yielding tuples (sentence, tags)\n",
        "\n",
        "    Returns:\n",
        "        a set of all the characters in the dataset\n",
        "\n",
        "    \"\"\"\n",
        "    vocab_char = set()\n",
        "    for words, _ in dataset:\n",
        "        for word in words:\n",
        "            vocab_char.update(word)\n",
        "\n",
        "    return vocab_char\n",
        "\n",
        "\n",
        "def get_glove_vocab(filename):\n",
        "    \"\"\"Load vocab from file\n",
        "\n",
        "    Args:\n",
        "        filename: path to the glove vectors\n",
        "\n",
        "    Returns:\n",
        "        vocab: set() of strings\n",
        "    \"\"\"\n",
        "    print(\"Building vocab...\")\n",
        "    vocab = set()\n",
        "    with open(filename) as f:\n",
        "        for line in f:\n",
        "            words = line.strip().split(' ')\n",
        "            if (len(words) == 2):\n",
        "              word = words[0]\n",
        "              vocab.add(word)\n",
        "    print(\"- done. {} tokens\".format(len(vocab)))\n",
        "    return vocab\n",
        "\n",
        "\n",
        "def write_vocab(vocab, filename):\n",
        "    \"\"\"Writes a vocab to a file\n",
        "\n",
        "    Writes one word per line.\n",
        "\n",
        "    Args:\n",
        "        vocab: iterable that yields word\n",
        "        filename: path to vocab file\n",
        "\n",
        "    Returns:\n",
        "        write a word per line\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"Writing vocab...\")\n",
        "    with open(filename, \"w\") as f:\n",
        "        for i, word in enumerate(vocab):\n",
        "            if i != len(vocab) - 1:\n",
        "                f.write(\"{}\\n\".format(word))\n",
        "            else:\n",
        "                f.write(word)\n",
        "    print(\"- done. {} tokens\".format(len(vocab)))\n",
        "\n",
        "\n",
        "def load_vocab(filename):\n",
        "    \"\"\"Loads vocab from a file\n",
        "\n",
        "    Args:\n",
        "        filename: (string) the format of the file must be one word per line.\n",
        "\n",
        "    Returns:\n",
        "        d: dict[word] = index\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "        d = dict()\n",
        "        with open(filename) as f:\n",
        "            for idx, word in enumerate(f):\n",
        "                word = word.strip()\n",
        "                d[word] = idx\n",
        "\n",
        "    except IOError:\n",
        "        raise MyIOError(filename)\n",
        "    return d\n",
        "\n",
        "\n",
        "def export_trimmed_glove_vectors(vocab, glove_filename, trimmed_filename, dim):\n",
        "    \"\"\"Saves glove vectors in numpy array\n",
        "\n",
        "    Args:\n",
        "        vocab: dictionary vocab[word] = index\n",
        "        glove_filename: a path to a glove file\n",
        "        trimmed_filename: a path where to store a matrix in npy\n",
        "        dim: (int) dimension of embeddings\n",
        "\n",
        "    \"\"\"\n",
        "    embeddings = np.zeros([len(vocab), dim])\n",
        "    with open(glove_filename) as f:\n",
        "        for line in f:\n",
        "            line = line.strip().split(' ')\n",
        "            word = line[0]\n",
        "            embedding = [float(x) for x in line[1:]]\n",
        "            if word in vocab:\n",
        "                word_idx = vocab[word]\n",
        "                embeddings[word_idx] = np.asarray(embedding)\n",
        "\n",
        "    np.savez_compressed(trimmed_filename, embeddings=embeddings)\n",
        "\n",
        "\n",
        "def get_trimmed_glove_vectors(filename):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        filename: path to the npz file\n",
        "\n",
        "    Returns:\n",
        "        matrix of embeddings (np array)\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with np.load(filename) as data:\n",
        "            return data[\"embeddings\"]\n",
        "\n",
        "    except IOError:\n",
        "        raise MyIOError(filename)\n",
        "\n",
        "\n",
        "def get_processing_word(vocab_words=None, vocab_chars=None,\n",
        "                    lowercase=False, chars=False, allow_unk=True):\n",
        "    \"\"\"Return lambda function that transform a word (string) into list,\n",
        "    or tuple of (list, id) of int corresponding to the ids of the word and\n",
        "    its corresponding characters.\n",
        "\n",
        "    Args:\n",
        "        vocab: dict[word] = idx\n",
        "\n",
        "    Returns:\n",
        "        f(\"cat\") = ([12, 4, 32], 12345)\n",
        "                 = (list of char ids, word id)\n",
        "\n",
        "    \"\"\"\n",
        "    def f(word):\n",
        "        # 0. get chars of words\n",
        "        if vocab_chars is not None and chars == True:\n",
        "            char_ids = []\n",
        "            for char in word:\n",
        "                # ignore chars out of vocabulary\n",
        "                if char in vocab_chars:\n",
        "                    char_ids += [vocab_chars[char]]\n",
        "\n",
        "        # 1. preprocess word\n",
        "        if lowercase:\n",
        "            word = word.lower()\n",
        "        word = re.sub('\\d', '0', word)\n",
        "\n",
        "        # 2. get id of word\n",
        "        if vocab_words is not None:\n",
        "            if word in vocab_words:\n",
        "                word = vocab_words[word]\n",
        "            else:\n",
        "                if word.isdigit():\n",
        "                    word = vocab_words[NUM]\n",
        "                elif allow_unk:\n",
        "                    word = vocab_words[UNK]\n",
        "                else:\n",
        "                    print(word)\n",
        "                    raise Exception(\"Unknow key is not allowed. Check that \"\\\n",
        "                                    \"your vocab (tags?) is correct\")\n",
        "\n",
        "        # 3. return tuple char ids, word id\n",
        "        if vocab_chars is not None and chars == True:\n",
        "            return char_ids, word\n",
        "        else:\n",
        "            return word\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _pad_sequences(sequences, pad_tok, max_length):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        sequences: a generator of list or tuple\n",
        "        pad_tok: the char to pad with\n",
        "\n",
        "    Returns:\n",
        "        a list of list where each sublist has same length\n",
        "    \"\"\"\n",
        "    sequence_padded, sequence_length = [], []\n",
        "\n",
        "    for seq in sequences:\n",
        "        seq = list(seq)\n",
        "        seq_ = seq[:max_length] + [pad_tok]*max(max_length - len(seq), 0)\n",
        "        sequence_padded +=  [seq_]\n",
        "        sequence_length += [min(len(seq), max_length)]\n",
        "\n",
        "    return sequence_padded, sequence_length\n",
        "\n",
        "\n",
        "def pad_sequences(sequences, pad_tok, nlevels=1):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        sequences: a generator of list or tuple\n",
        "        pad_tok: the char to pad with\n",
        "        nlevels: \"depth\" of padding, for the case where we have characters ids\n",
        "\n",
        "    Returns:\n",
        "        a list of list where each sublist has same length\n",
        "\n",
        "    \"\"\"\n",
        "    if nlevels == 1:\n",
        "        max_length = max(map(lambda x : len(x), sequences))\n",
        "        sequence_padded, sequence_length = _pad_sequences(sequences,\n",
        "                                            pad_tok, max_length)\n",
        "\n",
        "    elif nlevels == 2:\n",
        "        max_length_word = max([max(map(lambda x: len(x), seq))\n",
        "                               for seq in sequences])\n",
        "        sequence_padded, sequence_length = [], []\n",
        "        for seq in sequences:\n",
        "            # all words are same length now\n",
        "            sp, sl = _pad_sequences(seq, pad_tok, max_length_word)\n",
        "            sequence_padded += [sp]\n",
        "            sequence_length += [sl]\n",
        "\n",
        "        max_length_sentence = max(map(lambda x : len(x), sequences))\n",
        "        sequence_padded, _ = _pad_sequences(sequence_padded,\n",
        "                [pad_tok]*max_length_word, max_length_sentence)\n",
        "        sequence_length, _ = _pad_sequences(sequence_length, 0,\n",
        "                max_length_sentence)\n",
        "\n",
        "    return sequence_padded, sequence_length\n",
        "\n",
        "\n",
        "def minibatches(data, minibatch_size):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        data: generator of (sentence, tags) tuples\n",
        "        minibatch_size: (int)\n",
        "\n",
        "    Yields:\n",
        "        list of tuples\n",
        "\n",
        "    \"\"\"\n",
        "    x_batch, y_batch = [], []\n",
        "    for (x, y) in data:\n",
        "        if len(x_batch) == minibatch_size:\n",
        "            yield x_batch, y_batch\n",
        "            x_batch, y_batch = [], []\n",
        "\n",
        "        if type(x[0]) == tuple:\n",
        "            x = zip(*x)\n",
        "        x_batch += [x]\n",
        "        y_batch += [y]\n",
        "\n",
        "    if len(x_batch) != 0:\n",
        "        yield x_batch, y_batch\n",
        "\n",
        "\n",
        "def get_chunk_type(tok, idx_to_tag):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        tok: id of token, ex 4\n",
        "        idx_to_tag: dictionary {4: \"B-PER\", ...}\n",
        "\n",
        "    Returns:\n",
        "        tuple: \"B\", \"PER\"\n",
        "\n",
        "    \"\"\"\n",
        "    tag_name = idx_to_tag[tok]\n",
        "    tag_class = tag_name.split('-')[0]\n",
        "    tag_type = tag_name.split('-')[-1]\n",
        "    return tag_class, tag_type\n",
        "\n",
        "\n",
        "def get_chunks(seq, tags):\n",
        "    \"\"\"Given a sequence of tags, group entities and their position\n",
        "\n",
        "    Args:\n",
        "        seq: [4, 4, 0, 0, ...] sequence of labels\n",
        "        tags: dict[\"O\"] = 4\n",
        "\n",
        "    Returns:\n",
        "        list of (chunk_type, chunk_start, chunk_end)\n",
        "\n",
        "    Example:\n",
        "        seq = [4, 5, 0, 3]\n",
        "        tags = {\"B-PER\": 4, \"I-PER\": 5, \"B-LOC\": 3}\n",
        "        result = [(\"PER\", 0, 2), (\"LOC\", 3, 4)]\n",
        "\n",
        "    \"\"\"\n",
        "    default = tags[NONE]\n",
        "    idx_to_tag = {idx: tag for tag, idx in tags.items()}\n",
        "    chunks = []\n",
        "    chunk_type, chunk_start = None, None\n",
        "    for i, tok in enumerate(seq):\n",
        "        # End of a chunk 1\n",
        "        if tok == default and chunk_type is not None:\n",
        "            # Add a chunk.\n",
        "            chunk = (chunk_type, chunk_start, i)\n",
        "            chunks.append(chunk)\n",
        "            chunk_type, chunk_start = None, None\n",
        "\n",
        "        # End of a chunk + start of a chunk!\n",
        "        elif tok != default:\n",
        "            tok_chunk_class, tok_chunk_type = get_chunk_type(tok, idx_to_tag)\n",
        "            if chunk_type is None:\n",
        "                chunk_type, chunk_start = tok_chunk_type, i\n",
        "            elif tok_chunk_type != chunk_type or tok_chunk_class == \"B\":\n",
        "                chunk = (chunk_type, chunk_start, i)\n",
        "                chunks.append(chunk)\n",
        "                chunk_type, chunk_start = tok_chunk_type, i\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    # end condition\n",
        "    if chunk_type is not None:\n",
        "        chunk = (chunk_type, chunk_start, len(seq))\n",
        "        chunks.append(chunk)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def create_tag_dict(filename):\n",
        "    '''\n",
        "    From tags create dictionary grouping same classes\n",
        "    '''\n",
        "    # index to tag dic\n",
        "    indxToTag = dict()\n",
        "    with open(filename) as tags:\n",
        "        i = 0\n",
        "        for line in tags:\n",
        "            tag = line.rstrip('\\n')\n",
        "            #if tag[0:2] in [\"B-\", \"I-\"]:\n",
        "            #    tag = tag[2:]\n",
        "            indxToTag[i] = tag\n",
        "            i +=1\n",
        "    return indxToTag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EaQrVvchK_j"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import sys\n",
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_logger(filename):\n",
        "    \"\"\"Return a logger instance that writes in filename\n",
        "\n",
        "    Args:\n",
        "        filename: (string) path to log.txt\n",
        "\n",
        "    Returns:\n",
        "        logger: (instance of logger)\n",
        "\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger('logger')\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    logging.basicConfig(format='%(message)s', level=logging.DEBUG)\n",
        "    handler = logging.FileHandler(filename)\n",
        "    handler.setLevel(logging.DEBUG)\n",
        "    handler.setFormatter(logging.Formatter(\n",
        "            '%(asctime)s:%(levelname)s: %(message)s'))\n",
        "    logging.getLogger().addHandler(handler)\n",
        "\n",
        "    return logger\n",
        "\n",
        "\n",
        "class Progbar(object):\n",
        "    \"\"\"Progbar class copied from keras (https://github.com/fchollet/keras/)\n",
        "\n",
        "    Displays a progress bar.\n",
        "    Small edit : added strict arg to update\n",
        "    # Arguments\n",
        "        target: Total number of steps expected.\n",
        "        interval: Minimum visual progress update interval (in seconds).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, target, width=30, verbose=1):\n",
        "        self.width = width\n",
        "        self.target = target\n",
        "        self.sum_values = {}\n",
        "        self.unique_values = []\n",
        "        self.start = time.time()\n",
        "        self.total_width = 0\n",
        "        self.seen_so_far = 0\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def update(self, current, values=[], exact=[], strict=[]):\n",
        "        \"\"\"\n",
        "        Updates the progress bar.\n",
        "        # Arguments\n",
        "            current: Index of current step.\n",
        "            values: List of tuples (name, value_for_last_step).\n",
        "                The progress bar will display averages for these values.\n",
        "            exact: List of tuples (name, value_for_last_step).\n",
        "                The progress bar will display these values directly.\n",
        "        \"\"\"\n",
        "\n",
        "        for k, v in values:\n",
        "            if k not in self.sum_values:\n",
        "                self.sum_values[k] = [v * (current - self.seen_so_far),\n",
        "                                      current - self.seen_so_far]\n",
        "                self.unique_values.append(k)\n",
        "            else:\n",
        "                self.sum_values[k][0] += v * (current - self.seen_so_far)\n",
        "                self.sum_values[k][1] += (current - self.seen_so_far)\n",
        "        for k, v in exact:\n",
        "            if k not in self.sum_values:\n",
        "                self.unique_values.append(k)\n",
        "            self.sum_values[k] = [v, 1]\n",
        "\n",
        "        for k, v in strict:\n",
        "            if k not in self.sum_values:\n",
        "                self.unique_values.append(k)\n",
        "            self.sum_values[k] = v\n",
        "\n",
        "        self.seen_so_far = current\n",
        "\n",
        "        now = time.time()\n",
        "        if self.verbose == 1:\n",
        "            prev_total_width = self.total_width\n",
        "            sys.stdout.write(\"\\b\" * prev_total_width)\n",
        "            sys.stdout.write(\"\\r\")\n",
        "\n",
        "            numdigits = int(np.floor(np.log10(self.target))) + 1\n",
        "            barstr = '%%%dd/%%%dd [' % (numdigits, numdigits)\n",
        "            bar = barstr % (current, self.target)\n",
        "            prog = float(current)/self.target\n",
        "            prog_width = int(self.width*prog)\n",
        "            if prog_width > 0:\n",
        "                bar += ('='*(prog_width-1))\n",
        "                if current < self.target:\n",
        "                    bar += '>'\n",
        "                else:\n",
        "                    bar += '='\n",
        "            bar += ('.'*(self.width-prog_width))\n",
        "            bar += ']'\n",
        "            sys.stdout.write(bar)\n",
        "            self.total_width = len(bar)\n",
        "\n",
        "            if current:\n",
        "                time_per_unit = (now - self.start) / current\n",
        "            else:\n",
        "                time_per_unit = 0\n",
        "            eta = time_per_unit*(self.target - current)\n",
        "            info = ''\n",
        "            if current < self.target:\n",
        "                info += ' - ETA: %ds' % eta\n",
        "            else:\n",
        "                info += ' - %ds' % (now - self.start)\n",
        "            for k in self.unique_values:\n",
        "                if type(self.sum_values[k]) is list:\n",
        "                    info += ' - %s: %.4f' % (k,\n",
        "                        self.sum_values[k][0] / max(1, self.sum_values[k][1]))\n",
        "                else:\n",
        "                    info += ' - %s: %s' % (k, self.sum_values[k])\n",
        "\n",
        "            self.total_width += len(info)\n",
        "            if prev_total_width > self.total_width:\n",
        "                info += ((prev_total_width-self.total_width) * \" \")\n",
        "\n",
        "            sys.stdout.write(info)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "            if current >= self.target:\n",
        "                sys.stdout.write(\"\\n\")\n",
        "\n",
        "        if self.verbose == 2:\n",
        "            if current >= self.target:\n",
        "                info = '%ds' % (now - self.start)\n",
        "                for k in self.unique_values:\n",
        "                    info += ' - %s: %.4f' % (k,\n",
        "                        self.sum_values[k][0] / max(1, self.sum_values[k][1]))\n",
        "                sys.stdout.write(info + \"\\n\")\n",
        "\n",
        "    def add(self, n, values=[]):\n",
        "        self.update(self.seen_so_far+n, values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiPfqxFauCbg",
        "outputId": "92acfa14-3a9e-4f75-db4f-12098b6cfef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.14.0\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 80 kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.49.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 71.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (2.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow==1.14.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYx8o1lSuKsw",
        "outputId": "56c91f11-99fe-4fee-f247-7c58bd5cbd0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYz8QxLMuQN_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class BaseModel(object):\n",
        "    \"\"\"Generic class for general methods that are not specific to NER\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        \"\"\"Defines self.config and self.logger\n",
        "\n",
        "        Args:\n",
        "            config: (Config instance) class with hyper parameters,\n",
        "                vocab and embeddings\n",
        "\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.logger = config.logger\n",
        "        self.sess   = None\n",
        "        self.saver  = None\n",
        "\n",
        "\n",
        "    def reinitialize_weights(self, scope_name):\n",
        "        \"\"\"Reinitializes the weights of a given layer\"\"\"\n",
        "        variables = tf.contrib.framework.get_variables(scope_name)\n",
        "        init = tf.variables_initializer(variables)\n",
        "        self.sess.run(init)\n",
        "\n",
        "\n",
        "    def add_train_op(self, lr_method, lr, loss, clip=-1):\n",
        "        \"\"\"Defines self.train_op that performs an update on a batch\n",
        "\n",
        "        Args:\n",
        "            lr_method: (string) sgd method, for example \"adam\"\n",
        "            lr: (tf.placeholder) tf.float32, learning rate\n",
        "            loss: (tensor) tf.float32 loss to minimize\n",
        "            clip: (python float) clipping of gradient. If < 0, no clipping\n",
        "\n",
        "        \"\"\"\n",
        "        _lr_m = lr_method.lower() # lower to make sure\n",
        "\n",
        "        with tf.variable_scope(\"train_step\"):\n",
        "            if _lr_m == 'adam': # sgd method\n",
        "                optimizer = tf.train.AdamOptimizer(lr)\n",
        "            elif _lr_m == 'adagrad':\n",
        "                optimizer = tf.train.AdagradOptimizer(lr)\n",
        "            elif _lr_m == 'sgd':\n",
        "                optimizer = tf.train.MomentumOptimizer(lr, 0.9)\n",
        "            elif _lr_m == 'rmsprop':\n",
        "                optimizer = tf.train.RMSPropOptimizer(lr)\n",
        "            else:\n",
        "                raise NotImplementedError(\"Unknown method {}\".format(_lr_m))\n",
        "\n",
        "            if clip > 0: # gradient clipping if clip is positive\n",
        "                grads, vs     = zip(*optimizer.compute_gradients(loss))\n",
        "                grads, gnorm  = tf.clip_by_global_norm(grads, clip)\n",
        "                self.train_op = optimizer.apply_gradients(zip(grads, vs))\n",
        "            else:\n",
        "                self.train_op = optimizer.minimize(loss)\n",
        "\n",
        "\n",
        "    def initialize_session(self):\n",
        "        \"\"\"Defines self.sess and initialize the variables\"\"\"\n",
        "        self.logger.info(\"Initializing tf session\")\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "        self.saver = tf.train.Saver()\n",
        "\n",
        "\n",
        "    def restore_session(self, dir_model):\n",
        "        \"\"\"Reload weights into session\n",
        "\n",
        "        Args:\n",
        "            sess: tf.Session()\n",
        "            dir_model: dir with weights\n",
        "\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Reloading the latest trained model...\")\n",
        "        self.saver.restore(self.sess, dir_model)\n",
        "\n",
        "\n",
        "    def save_session(self):\n",
        "        \"\"\"Saves session = weights\"\"\"\n",
        "        if not os.path.exists(self.config.dir_model):\n",
        "            os.makedirs(self.config.dir_model)\n",
        "        self.saver.save(self.sess, self.config.dir_model)\n",
        "\n",
        "\n",
        "    def close_session(self):\n",
        "        \"\"\"Closes the session\"\"\"\n",
        "        self.sess.close()\n",
        "\n",
        "\n",
        "    def add_summary(self):\n",
        "        \"\"\"Defines variables for Tensorboard\n",
        "\n",
        "        Args:\n",
        "            dir_output: (string) where the results are written\n",
        "\n",
        "        \"\"\"\n",
        "        self.merged      = tf.summary.merge_all()\n",
        "        self.file_writer = tf.summary.FileWriter(self.config.dir_output,\n",
        "                self.sess.graph)\n",
        "\n",
        "\n",
        "    def train(self, train, dev, best_score=0):\n",
        "        \"\"\"Performs training with early stopping and lr exponential decay\n",
        "\n",
        "        Args:\n",
        "            train: dataset that yields tuple of (sentences, tags)\n",
        "            dev: dataset\n",
        "\n",
        "        \"\"\"\n",
        "        nepoch_no_imprv = 0 # for early stopping\n",
        "        self.add_summary() # tensorboard\n",
        "\n",
        "        for epoch in range(self.config.nepochs):\n",
        "            self.logger.info(\"Epoch {:} out of {:}\".format(epoch + 1,\n",
        "                        self.config.nepochs))\n",
        "\n",
        "            score = self.run_epoch(train, dev, epoch)\n",
        "            self.config.lr *= self.config.lr_decay # decay learning rate\n",
        "\n",
        "            # early stopping and saving best parameters\n",
        "            if score >= best_score:\n",
        "                nepoch_no_imprv = 0\n",
        "                self.save_session()\n",
        "                best_score = score\n",
        "                self.logger.info(\"- new best score!\")\n",
        "            else:\n",
        "                nepoch_no_imprv += 1\n",
        "                if nepoch_no_imprv >= self.config.nepoch_no_imprv:\n",
        "                    self.logger.info(\"- early stopping {} epochs without \"\\\n",
        "                            \"improvement\".format(nepoch_no_imprv))\n",
        "                    break\n",
        "\n",
        "\n",
        "    def evaluate(self, test):\n",
        "        \"\"\"Evaluate model on test set\n",
        "\n",
        "        Args:\n",
        "            test: instance of class Dataset\n",
        "\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Testing model over test set: \")\n",
        "        metrics = self.run_evaluate(test)\n",
        "        msg = \" - \".join([\"{} {:04.2f}\".format(k, v)\n",
        "                for k, v in metrics.items()])\n",
        "        self.logger.info(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D31y6oEccL6",
        "outputId": "4a4b9f89-713c-4b1b-d58d-406c1870fc5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=7c26a142522fbe3648ae1e3f174c7a69eaf5b2a1ee1634e351b9e64b6eda7ee2\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvTlqcFYwT_Z"
      },
      "outputs": [],
      "source": [
        "def level_entity_new (labels, preds):\n",
        "\n",
        "  labels_cm, preds_cm = [], []\n",
        "\n",
        "  for id, lab in enumerate(labels):\n",
        "    encontrou = False\n",
        "    #verifica a predição das entidades != de O\n",
        "    if lab.startswith('B-'):\n",
        "      encontrou = False\n",
        "      id_inicio, id_fim = id, id\n",
        "\n",
        "      #verifica onde termina a entidade\n",
        "      for id_prox in range(id+1, len(labels)):\n",
        "        if not labels[id_prox].startswith('I-'):\n",
        "          id_fim = id_prox - 1\n",
        "          break\n",
        "\n",
        "      ent_pred = 'O'\n",
        "      for id_pred in range(id_inicio, id_fim+1):\n",
        "        if preds[id_pred][2:] == lab[2:]:\n",
        "          ent_pred = preds[id_pred]\n",
        "          encontrou = True\n",
        "          break\n",
        "        else:\n",
        "          ent_pred = preds[id_pred]\n",
        "\n",
        "      labels_cm.append(lab)\n",
        "      if ent_pred == 'O':\n",
        "        preds_cm.append('O')\n",
        "      else:\n",
        "        preds_cm.append('B-' + ent_pred[2:])\n",
        "    elif lab == 'O':\n",
        "      #verifica se a predição e a label são O ou se a predição é uma parte da label e já foi contada anteriormente\n",
        "      if preds[id] == lab or encontrou:\n",
        "        labels_cm.append('O')\n",
        "        preds_cm.append('O')\n",
        "      else:\n",
        "        if preds[id].startswith('B-'):\n",
        "          encontrou_pred = False\n",
        "          #verifica até onde termina a entidade se terá uma label real\n",
        "          for id_prox in range(id+1, len(labels)):\n",
        "            if preds[id_prox].startswith('I-'):\n",
        "              if labels[id_prox] != 'O':\n",
        "                encontrou_pred = True\n",
        "                break\n",
        "            else:\n",
        "              break\n",
        "          #se não tiver label anotada em toda a entidade predita, adiciona;\n",
        "          #caso contrário, não adiciona, pois será adicionado pela verificação da label\n",
        "          if not encontrou_pred:\n",
        "            labels_cm.append('O')\n",
        "            preds_cm.append('B-' + preds[id][2:])\n",
        "\n",
        "  cr = classification_report([labels_cm], [preds_cm])\n",
        "\n",
        "  header = sorted(list(set(labels_cm + preds_cm)))\n",
        "  cm = confusion_matrix(labels_cm, preds_cm, labels=header)\n",
        "  mat_formatted = [header[i] + \"\\t\" + str(row) for i, row in enumerate(cm)]\n",
        "  content_cm = \"\\t\" + \" \".join(header) + \"\\n\" + \"\\n\".join(mat_formatted)\n",
        "\n",
        "  return cr, content_cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHIjrg82uVox"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Code modified by the authors of leNER-Br paper:\n",
        "    modify run_evaluate to base score on token correctness\n",
        "'''\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from seqeval.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "class NERModel(BaseModel):\n",
        "    \"\"\"Specialized class of Model for NER\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(NERModel, self).__init__(config)\n",
        "        self.idx_to_tag = {idx: tag for tag, idx in\n",
        "                           self.config.vocab_tags.items()}\n",
        "\n",
        "\n",
        "    def add_placeholders(self):\n",
        "        \"\"\"Define placeholders = entries to computational graph\"\"\"\n",
        "        # shape = (batch size, max length of sentence in batch)\n",
        "        self.word_ids = tf.placeholder(tf.int32, shape=[None, None],\n",
        "                        name=\"word_ids\")\n",
        "\n",
        "        # shape = (batch size)\n",
        "        self.sequence_lengths = tf.placeholder(tf.int32, shape=[None],\n",
        "                        name=\"sequence_lengths\")\n",
        "\n",
        "        # shape = (batch size, max length of sentence, max length of word)\n",
        "        self.char_ids = tf.placeholder(tf.int32, shape=[None, None, None],\n",
        "                        name=\"char_ids\")\n",
        "\n",
        "        # shape = (batch_size, max_length of sentence)\n",
        "        self.word_lengths = tf.placeholder(tf.int32, shape=[None, None],\n",
        "                        name=\"word_lengths\")\n",
        "\n",
        "        # shape = (batch size, max length of sentence in batch)\n",
        "        self.labels = tf.placeholder(tf.int32, shape=[None, None],\n",
        "                        name=\"labels\")\n",
        "\n",
        "        # hyper parameters\n",
        "        self.dropout = tf.placeholder(dtype=tf.float32, shape=[],\n",
        "                        name=\"dropout\")\n",
        "        self.lr = tf.placeholder(dtype=tf.float32, shape=[],\n",
        "                        name=\"lr\")\n",
        "\n",
        "\n",
        "    def get_feed_dict(self, words, labels=None, lr=None, dropout=None):\n",
        "        \"\"\"Given some data, pad it and build a feed dictionary\n",
        "\n",
        "        Args:\n",
        "            words: list of sentences. A sentence is a list of ids of a list of\n",
        "                words. A word is a list of ids\n",
        "            labels: list of ids\n",
        "            lr: (float) learning rate\n",
        "            dropout: (float) keep prob\n",
        "\n",
        "        Returns:\n",
        "            dict {placeholder: value}\n",
        "\n",
        "        \"\"\"\n",
        "        # perform padding of the given data\n",
        "        if self.config.use_chars:\n",
        "            char_ids, word_ids = zip(*words)\n",
        "            word_ids, sequence_lengths = pad_sequences(word_ids, 0)\n",
        "            char_ids, word_lengths = pad_sequences(char_ids, pad_tok=0,\n",
        "                nlevels=2)\n",
        "        else:\n",
        "            word_ids, sequence_lengths = pad_sequences(words, 0)\n",
        "\n",
        "        # build feed dictionary\n",
        "        feed = {\n",
        "            self.word_ids: word_ids,\n",
        "            self.sequence_lengths: sequence_lengths\n",
        "        }\n",
        "\n",
        "        if self.config.use_chars:\n",
        "            feed[self.char_ids] = char_ids\n",
        "            feed[self.word_lengths] = word_lengths\n",
        "\n",
        "        if labels is not None:\n",
        "            labels, _ = pad_sequences(labels, 0)\n",
        "            feed[self.labels] = labels\n",
        "\n",
        "        if lr is not None:\n",
        "            feed[self.lr] = lr\n",
        "\n",
        "        if dropout is not None:\n",
        "            feed[self.dropout] = dropout\n",
        "\n",
        "        return feed, sequence_lengths\n",
        "\n",
        "\n",
        "    def add_word_embeddings_op(self):\n",
        "        \"\"\"Defines self.word_embeddings\n",
        "\n",
        "        If self.config.embeddings is not None and is a np array initialized\n",
        "        with pre-trained word vectors, the word embeddings is just a look-up\n",
        "        and we don't train the vectors. Otherwise, a random matrix with\n",
        "        the correct shape is initialized.\n",
        "        \"\"\"\n",
        "        with tf.variable_scope(\"words\"):\n",
        "            if self.config.embeddings is None:\n",
        "                self.logger.info(\"WARNING: randomly initializing word vectors\")\n",
        "                _word_embeddings = tf.get_variable(\n",
        "                        name=\"_word_embeddings\",\n",
        "                        dtype=tf.float32,\n",
        "                        shape=[self.config.nwords, self.config.dim_word])\n",
        "            else:\n",
        "                _word_embeddings = tf.Variable(\n",
        "                        self.config.embeddings,\n",
        "                        name=\"_word_embeddings\",\n",
        "                        dtype=tf.float32,\n",
        "                        trainable=self.config.train_embeddings)\n",
        "\n",
        "            word_embeddings = tf.nn.embedding_lookup(_word_embeddings,\n",
        "                    self.word_ids, name=\"word_embeddings\")\n",
        "\n",
        "        with tf.variable_scope(\"chars\"):\n",
        "            if self.config.use_chars:\n",
        "                # get char embeddings matrix\n",
        "                _char_embeddings = tf.get_variable(\n",
        "                        name=\"_char_embeddings\",\n",
        "                        dtype=tf.float32,\n",
        "                        shape=[self.config.nchars, self.config.dim_char])\n",
        "                char_embeddings = tf.nn.embedding_lookup(_char_embeddings,\n",
        "                        self.char_ids, name=\"char_embeddings\")\n",
        "\n",
        "                # put the time dimension on axis=1\n",
        "                s = tf.shape(char_embeddings)\n",
        "                char_embeddings = tf.reshape(char_embeddings,\n",
        "                        shape=[s[0]*s[1], s[-2], self.config.dim_char])\n",
        "                word_lengths = tf.reshape(self.word_lengths, shape=[s[0]*s[1]])\n",
        "\n",
        "                # bi lstm on chars\n",
        "                cell_fw = tf.contrib.rnn.LSTMCell(self.config.hidden_size_char,\n",
        "                        state_is_tuple=True)\n",
        "                cell_bw = tf.contrib.rnn.LSTMCell(self.config.hidden_size_char,\n",
        "                        state_is_tuple=True)\n",
        "                _output = tf.nn.bidirectional_dynamic_rnn(\n",
        "                        cell_fw, cell_bw, char_embeddings,\n",
        "                        sequence_length=word_lengths, dtype=tf.float32)\n",
        "\n",
        "                # read and concat output\n",
        "                _, ((_, output_fw), (_, output_bw)) = _output\n",
        "                output = tf.concat([output_fw, output_bw], axis=-1)\n",
        "\n",
        "                # shape = (batch size, max sentence length, char hidden size)\n",
        "                output = tf.reshape(output,\n",
        "                        shape=[s[0], s[1], 2*self.config.hidden_size_char])\n",
        "                word_embeddings = tf.concat([word_embeddings, output], axis=-1)\n",
        "\n",
        "        self.word_embeddings =  tf.nn.dropout(word_embeddings, self.dropout)\n",
        "\n",
        "\n",
        "    def add_logits_op(self):\n",
        "        \"\"\"Defines self.logits\n",
        "\n",
        "        For each word in each sentence of the batch, it corresponds to a vector\n",
        "        of scores, of dimension equal to the number of tags.\n",
        "        \"\"\"\n",
        "        with tf.variable_scope(\"bi-lstm\"):\n",
        "            cell_fw = tf.contrib.rnn.LSTMCell(self.config.hidden_size_lstm)\n",
        "            cell_bw = tf.contrib.rnn.LSTMCell(self.config.hidden_size_lstm)\n",
        "            (output_fw, output_bw), _ = tf.nn.bidirectional_dynamic_rnn(\n",
        "                    cell_fw, cell_bw, self.word_embeddings,\n",
        "                    sequence_length=self.sequence_lengths, dtype=tf.float32)\n",
        "            output = tf.concat([output_fw, output_bw], axis=-1)\n",
        "            output = tf.nn.dropout(output, self.dropout)\n",
        "\n",
        "        with tf.variable_scope(\"proj\"):\n",
        "            W = tf.get_variable(\"W\", dtype=tf.float32,\n",
        "                    shape=[2*self.config.hidden_size_lstm, self.config.ntags])\n",
        "\n",
        "            b = tf.get_variable(\"b\", shape=[self.config.ntags],\n",
        "                    dtype=tf.float32, initializer=tf.zeros_initializer())\n",
        "\n",
        "            nsteps = tf.shape(output)[1]\n",
        "            output = tf.reshape(output, [-1, 2*self.config.hidden_size_lstm])\n",
        "            pred = tf.matmul(output, W) + b\n",
        "            self.logits = tf.reshape(pred, [-1, nsteps, self.config.ntags])\n",
        "\n",
        "\n",
        "    def add_pred_op(self):\n",
        "        \"\"\"Defines self.labels_pred\n",
        "\n",
        "        This op is defined only in the case where we don't use a CRF since in\n",
        "        that case we can make the prediction \"in the graph\" (thanks to tf\n",
        "        functions in other words). With theCRF, as the inference is coded\n",
        "        in python and not in pure tensroflow, we have to make the prediciton\n",
        "        outside the graph.\n",
        "        \"\"\"\n",
        "        if not self.config.use_crf:\n",
        "            self.labels_pred = tf.cast(tf.argmax(self.logits, axis=-1),\n",
        "                    tf.int32)\n",
        "\n",
        "\n",
        "    def add_loss_op(self):\n",
        "        \"\"\"Defines the loss\"\"\"\n",
        "        if self.config.use_crf:\n",
        "            log_likelihood, trans_params = tf.contrib.crf.crf_log_likelihood(\n",
        "                    self.logits, self.labels, self.sequence_lengths)\n",
        "            self.trans_params = trans_params # need to evaluate it for decoding\n",
        "            self.loss = tf.reduce_mean(-log_likelihood)\n",
        "        else:\n",
        "            losses = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                    logits=self.logits, labels=self.labels)\n",
        "            mask = tf.sequence_mask(self.sequence_lengths)\n",
        "            losses = tf.boolean_mask(losses, mask)\n",
        "            self.loss = tf.reduce_mean(losses)\n",
        "\n",
        "        # for tensorboard\n",
        "        tf.summary.scalar(\"loss\", self.loss)\n",
        "\n",
        "\n",
        "    def build(self):\n",
        "        # NER specific functions\n",
        "        self.add_placeholders()\n",
        "        self.add_word_embeddings_op()\n",
        "        self.add_logits_op()\n",
        "        self.add_pred_op()\n",
        "        self.add_loss_op()\n",
        "\n",
        "        # Generic functions that add training op and initialize session\n",
        "        self.add_train_op(self.config.lr_method, self.lr, self.loss,\n",
        "                self.config.clip)\n",
        "        self.initialize_session() # now self.sess is defined and vars are init\n",
        "\n",
        "\n",
        "    def predict_batch(self, words):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            words: list of sentences\n",
        "\n",
        "        Returns:\n",
        "            labels_pred: list of labels for each sentence\n",
        "            sequence_length\n",
        "\n",
        "        \"\"\"\n",
        "        fd, sequence_lengths = self.get_feed_dict(words, dropout=1.0)\n",
        "\n",
        "        if self.config.use_crf:\n",
        "            # get tag scores and transition params of CRF\n",
        "            viterbi_sequences = []\n",
        "            logits, trans_params = self.sess.run(\n",
        "                    [self.logits, self.trans_params], feed_dict=fd)\n",
        "\n",
        "            # iterate over the sentences because no batching in vitervi_decode\n",
        "            for logit, sequence_length in zip(logits, sequence_lengths):\n",
        "                logit = logit[:sequence_length] # keep only the valid steps\n",
        "                viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode(\n",
        "                        logit, trans_params)\n",
        "                viterbi_sequences += [viterbi_seq]\n",
        "\n",
        "            return viterbi_sequences, sequence_lengths\n",
        "\n",
        "        else:\n",
        "            labels_pred = self.sess.run(self.labels_pred, feed_dict=fd)\n",
        "\n",
        "            return labels_pred, sequence_lengths\n",
        "\n",
        "\n",
        "    def run_epoch(self, train, dev, epoch):\n",
        "        \"\"\"Performs one complete pass over the train set and evaluate on dev\n",
        "\n",
        "        Args:\n",
        "            train: dataset that yields tuple of sentences, tags\n",
        "            dev: dataset\n",
        "            epoch: (int) index of the current epoch\n",
        "\n",
        "        Returns:\n",
        "            f1: (python float), score to select model on, higher is better\n",
        "\n",
        "        \"\"\"\n",
        "        # progbar stuff for logging\n",
        "        batch_size = self.config.batch_size\n",
        "        nbatches = (len(train) + batch_size - 1) // batch_size\n",
        "        prog = Progbar(target=nbatches)\n",
        "\n",
        "        # iterate over dataset\n",
        "        for i, (words, labels) in enumerate(minibatches(train, batch_size)):\n",
        "            fd, _ = self.get_feed_dict(words, labels, self.config.lr,\n",
        "                    self.config.dropout)\n",
        "\n",
        "            _, train_loss, summary = self.sess.run(\n",
        "                    [self.train_op, self.loss, self.merged], feed_dict=fd)\n",
        "\n",
        "            prog.update(i + 1, [(\"train loss\", train_loss)])\n",
        "\n",
        "            # tensorboard\n",
        "            if i % 10 == 0:\n",
        "                self.file_writer.add_summary(summary, epoch*nbatches + i)\n",
        "\n",
        "        metrics = self.run_evaluate(dev)\n",
        "        msg = \" - \".join([\"{} {:04.2f}\".format(k, v)\n",
        "                for k, v in metrics.items()])\n",
        "        self.logger.info(msg)\n",
        "\n",
        "        return metrics[\"f1\"]\n",
        "\n",
        "\n",
        "    def run_evaluate(self, test):\n",
        "        \"\"\"Evaluates performance on test set\n",
        "\n",
        "        Args:\n",
        "            test: dataset that yields tuple of (sentences, tags)\n",
        "\n",
        "        Returns:\n",
        "            metrics: (dict) metrics[\"acc\"] = 98.4, ...\n",
        "\n",
        "        \"\"\"\n",
        "        preds = []\n",
        "        labels = []\n",
        "\n",
        "        # index to tag dic\n",
        "        indxToTag = create_tag_dict(\"/content/drive/MyDrive/UNIFOR/NER/CDJur/results_lstm/tags.txt\")\n",
        "\n",
        "        for words, labs in minibatches(test, self.config.batch_size):\n",
        "            labels_pred, sequence_lengths = self.predict_batch(words)\n",
        "\n",
        "            for lab, lab_pred, length in zip(labs, labels_pred,\n",
        "                                             sequence_lengths):\n",
        "                lab_pred = lab_pred[:length]\n",
        "                lab = lab[:length]\n",
        "                preds.append(lab_pred)\n",
        "                labels.append(lab)\n",
        "\n",
        "        preds_t = [indxToTag.get(item, item) for items in preds for item in items]\n",
        "        labels_t = [indxToTag.get(item, item) for items in labels for item in items]\n",
        "        f1 = f1_score(labels_t, preds_t, average='micro', labels=['JURISPRUDENCIA', 'LOCAL', 'TEMPO',  'PESSOA', 'LEGISLACAO', 'ORGANIZACAO'])\n",
        "        acc = accuracy_score(labels_t, preds_t)\n",
        "        print('Labels:')\n",
        "        print(labels_t)\n",
        "        print('Preds:')\n",
        "        print(preds_t)\n",
        "        print('Classification_report:')\n",
        "        print(classification_report([labels_t], [preds_t]))\n",
        "        l_aux = labels_t\n",
        "        p_aux = preds_t\n",
        "\n",
        "        #Ajusta as transições de tags inválidas do padrão IOB2 (O I ; B-X I-Y; I-X I-Y)\n",
        "        for idx_pred in range(len(preds_t)):\n",
        "          if preds_t[idx_pred].startswith('I-') and \\\n",
        "              (idx_pred == 0 or (idx_pred > 0 and preds_t[idx_pred-1] == 'O')):\n",
        "            #print('mudou: ' + toplevel_preds[0][idx_pred])\n",
        "            preds_t[idx_pred] = 'B-' + preds_t[idx_pred][2:]\n",
        "            #print('para: ' + toplevel_preds[0][idx_pred])\n",
        "          elif idx_pred > 0 and preds_t[idx_pred].startswith('I-') and \\\n",
        "              (preds_t[idx_pred-1].startswith('I-') or preds_t[idx_pred-1].startswith('B-')) and \\\n",
        "               preds_t[idx_pred][2:] != preds_t[idx_pred-1][2:]:\n",
        "            #print('mudou: ' + toplevel_preds[0][idx_pred])\n",
        "            preds_t[idx_pred] = 'I-' + preds_t[idx_pred-1][2:]\n",
        "            #print('para: ' + toplevel_preds[0][idx_pred]\n",
        "\n",
        "        cr_level_entity, cm_level_entity = level_entity_new(labels_t, preds_t)\n",
        "        print(f\"Classification Report Level Entity:\\n {cr_level_entity}\")\n",
        "        print(cm_level_entity)\n",
        "\n",
        "        #matrix_confusion_class(labels, preds)\n",
        "        #print(confusion_matrix([labels],[preds]))\n",
        "\n",
        "        return {\"acc\": 100*acc, \"f1\": 100*f1}\n",
        "\n",
        "    def matrix_confusion_class(labels, preds):\n",
        "      labels_true_cm, labels_pred_cm = [], []\n",
        "      for l in labels:\n",
        "        labels_true_cm.extend(l)\n",
        "\n",
        "      for l in preds:\n",
        "        labels_pred_cm.extend(l)\n",
        "\n",
        "      header = sorted(list(set(labels_true_cm + labels_pred_cm)))\n",
        "      matrix = confusion_matrix(labels_true_cm, labels_pred_cm, labels=header)\n",
        "      print(header)\n",
        "      print(matrix)\n",
        "\n",
        "    #def matrix_confusion_class(preds, labels):\n",
        "    #  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    #  labels_flat = labels.flatten()\n",
        "    #  print(confusion_matrix(labels_flat,preds_flat))\n",
        "\n",
        "    def predict(self, words_raw):\n",
        "        \"\"\"Returns list of tags\n",
        "\n",
        "        Args:\n",
        "            words_raw: list of words (string), just one sentence (no batch)\n",
        "\n",
        "        Returns:\n",
        "            preds: list of tags (string), one for each word in the sentence\n",
        "\n",
        "        \"\"\"\n",
        "        words = [self.config.processing_word(w) for w in words_raw]\n",
        "        if type(words[0]) == tuple:\n",
        "            words = zip(*words)\n",
        "        pred_ids, _ = self.predict_batch([words])\n",
        "        preds = [self.idx_to_tag[idx] for idx in list(pred_ids[0])]\n",
        "\n",
        "        return preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0KGcRKYqVjM"
      },
      "outputs": [],
      "source": [
        "l_aux = []\n",
        "p_aux = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t2Qcu3QhrMr"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Configs set by the authors of leNER-Br paper\n",
        "'''\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "class Config():\n",
        "    def __init__(self, load=True):\n",
        "        \"\"\"Initialize hyperparameters and load vocabs\n",
        "\n",
        "        Args:\n",
        "            load_embeddings: (bool) if True, load embeddings into\n",
        "                np array, else None\n",
        "\n",
        "        \"\"\"\n",
        "        # directory for training outputs\n",
        "        if not os.path.exists(self.dir_output):\n",
        "            os.makedirs(self.dir_output)\n",
        "\n",
        "        # create instance of logger\n",
        "        self.logger = get_logger(self.path_log)\n",
        "\n",
        "        # load if requested (default)\n",
        "        if load:\n",
        "            self.load()\n",
        "\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\"Loads vocabulary, processing functions and embeddings\n",
        "\n",
        "        Supposes that build_data.py has been run successfully and that\n",
        "        the corresponding files have been created (vocab and trimmed GloVe\n",
        "        vectors)\n",
        "\n",
        "        \"\"\"\n",
        "        # 1. vocabulary\n",
        "        self.vocab_words = load_vocab(self.filename_words)\n",
        "        self.vocab_tags  = load_vocab(self.filename_tags)\n",
        "        self.vocab_chars = load_vocab(self.filename_chars)\n",
        "\n",
        "        self.nwords     = len(self.vocab_words)\n",
        "        self.nchars     = len(self.vocab_chars)\n",
        "        self.ntags      = len(self.vocab_tags)\n",
        "\n",
        "        # 2. get processing functions that map str -> id\n",
        "        self.processing_word = get_processing_word(self.vocab_words,\n",
        "                self.vocab_chars, lowercase=True, chars=self.use_chars)\n",
        "        self.processing_tag  = get_processing_word(self.vocab_tags,\n",
        "                lowercase=False, allow_unk=False)\n",
        "\n",
        "        # 3. get pre-trained embeddings\n",
        "        self.embeddings = (get_trimmed_glove_vectors(self.filename_trimmed)\n",
        "                if self.use_pretrained else None)\n",
        "\n",
        "\n",
        "    # general config\n",
        "    dir_output = \"/content/drive/MyDrive/UNIFOR/NER/CDJur/results_lstm/prototype_revised/\"\n",
        "    dir_model  = dir_output + \"model.weights/\"\n",
        "    path_log   = dir_output + \"log.txt\"\n",
        "\n",
        "    # embeddings\n",
        "    dim_word = 300\n",
        "    dim_char = 50\n",
        "\n",
        "    # glove files\n",
        "    filename_glove = \"/content/drive/MyDrive/UNIFOR/NER/CDJur/lener/glove_s300.txt\" #enviar para jorge - ok\n",
        "    # trimmed embeddings (created from glove_filename with build_data.py)\n",
        "    filename_trimmed = \"/content/drive/MyDrive/UNIFOR/NER/CDJur/results_lstm/glove.6B.{}d.trimmed.npz\".format(dim_word)\n",
        "    use_pretrained = True\n",
        "\n",
        "    # dataset\n",
        "    # filename_dev = \"data/coNLL/eng/eng.testa.iob\"\n",
        "    # filename_test = \"data/coNLL/eng/eng.testb.iob\"\n",
        "    # filename_train = \"data/coNLL/eng/eng.train.iob\"\n",
        "\n",
        "    #filename_dev = '/content/drive/MyDrive/Unifor/NER/lener/dev.txt'\n",
        "    #filename_test = '/content/drive/MyDrive/Unifor/NER/lener/test.txt'\n",
        "    #filename_train = '/content/drive/MyDrive/Unifor/NER/lener/train.txt'\n",
        "\n",
        "\n",
        "    #entidade = 'exp1/'\n",
        "    #path_geral = '/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_revisao_210922/' + entidade\n",
        "    #filename_dev = f'{path_geral}val.conll'\n",
        "    #filename_test = f'{path_geral}teste.conll'\n",
        "    #filename_train = f'{path_geral}treino.conll'\n",
        "\n",
        "    data_revisao = '131022'\n",
        "    filename_train = f'/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_revisao_{data_revisao}/exp1/treino.conll'\n",
        "    filename_dev = f'/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_revisao_{data_revisao}/exp1/val.conll'\n",
        "    filename_test = f'/content/drive/MyDrive/UNIFOR/NER/CDJur/cdjur_revisao_{data_revisao}/exp1/teste.conll'\n",
        "\n",
        "\n",
        "    #filename_train = '/content/drive/MyDrive/Unifor/NER/lener/train_atualizado.txt'\n",
        "\n",
        "    max_iter = None # if not None, max number of examples in Dataset\n",
        "\n",
        "    # vocab (created from dataset with build_data.py)\n",
        "    filename_words = \"/content/drive/MyDrive/UNIFOR/NER/CDJur/results_lstm/words.txt\"\n",
        "    filename_tags = \"/content/drive/MyDrive/UNIFOR/NER/CDJur/results_lstm/tags.txt\"\n",
        "    filename_chars = \"/content/drive/MyDrive/UNIFOR/NER/CDJur/results_lstm/chars.txt\"\n",
        "\n",
        "    # training\n",
        "    train_embeddings = True\n",
        "    nepochs          = 20#55#1#25#55\n",
        "    dropout          = 0.5\n",
        "    batch_size       = 10\n",
        "    lr_method        = \"sgd\"\n",
        "    lr               = 0.015\n",
        "    lr_decay         = 0.95\n",
        "    clip             = 5 # if negative, no clipping\n",
        "    nepoch_no_imprv  = 20\n",
        "\n",
        "    # model hyperparameters\n",
        "    hidden_size_char = 25 # lstm on chars\n",
        "    hidden_size_lstm = 100 # lstm on word embeddings\n",
        "\n",
        "    # NOTE: if both chars and crf, only 1.6x slower on GPU\n",
        "    use_crf = True # if crf, training is 1.7x slower on CPU\n",
        "    use_chars = True # if char embedding, training is 3.5x slower on CPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-ElIDgxqVsI",
        "outputId": "0bed89ab-1739-40ba-edba-0510a026a4c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train\n",
            "dev\n",
            "test\n"
          ]
        }
      ],
      "source": [
        "config = Config(load=False)\n",
        "processing_word = get_processing_word(lowercase=True)\n",
        "\n",
        "# Generators\n",
        "print('train')\n",
        "train = CoNLLDataset(config.filename_train, processing_word)\n",
        "print('dev')\n",
        "dev   = CoNLLDataset(config.filename_dev, processing_word)\n",
        "print('test')\n",
        "test  = CoNLLDataset(config.filename_test, processing_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVcDvrsZ4UMH",
        "outputId": "2124d086-e4bb-4356-bcea-d6b9ba7f6b73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building vocab...\n",
            "- done. 69735 tokens\n",
            "Building vocab...\n",
            "- done. 1 tokens\n",
            "Writing vocab...\n",
            "- done. 2 tokens\n",
            "Writing vocab...\n",
            "- done. 43 tokens\n"
          ]
        }
      ],
      "source": [
        "# Build Word and Tag vocab\n",
        "# vocab_words, vocab_tags = get_vocabs([train, dev, test, test2])\n",
        "vocab_words, vocab_tags = get_vocabs([train, dev])\n",
        "vocab_glove = get_glove_vocab(config.filename_glove)\n",
        "\n",
        "vocab = vocab_words & vocab_glove\n",
        "vocab.add(UNK)\n",
        "vocab.add(NUM)\n",
        "\n",
        "# Save vocab\n",
        "write_vocab(vocab, config.filename_words)\n",
        "write_vocab(vocab_tags, config.filename_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQXM92Z24Xvn",
        "outputId": "95743b93-e9b2-487d-d305-4a2ec5d0cb89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing vocab...\n",
            "- done. 145 tokens\n"
          ]
        }
      ],
      "source": [
        "# Trim GloVe Vectors\n",
        "vocab = load_vocab(config.filename_words)\n",
        "export_trimmed_glove_vectors(vocab, config.filename_glove,\n",
        "                            config.filename_trimmed, config.dim_word)\n",
        "\n",
        "# Build and save char vocab\n",
        "train = CoNLLDataset(config.filename_train)\n",
        "vocab_chars = get_char_vocab(train)\n",
        "write_vocab(vocab_chars, config.filename_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtXZt2ylkSpk",
        "outputId": "bc754c77-aa21-41d9-dd88-8627c466a41c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-9-03865dfb2506>:142: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-9-03865dfb2506>:147: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f053da5cf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f053da5cf50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f053beccdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f053beccdd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:From <ipython-input-9-03865dfb2506>:158: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f053da5cf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f053da5cf50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f053beccdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f053beccdd0>>: AttributeError: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f053b36c710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f053b36c710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f0547924a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f0547924a10>>: AttributeError: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f053b36c710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f053b36c710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f0547924a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f0547924a10>>: AttributeError: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:Initializing tf session\n"
          ]
        }
      ],
      "source": [
        "config = Config()\n",
        "\n",
        "# build model\n",
        "model = NERModel(config)\n",
        "model.build()\n",
        "score = 0\n",
        "# model.restore_session(config.dir_model) # optional, restore weights\n",
        "# model.reinitialize_weights(\"proj\")\n",
        "# make sure to make score equals models best score\n",
        "\n",
        "# create datasets\n",
        "dev   = CoNLLDataset(config.filename_dev, config.processing_word, config.processing_tag, config.max_iter)\n",
        "train = CoNLLDataset(config.filename_train, config.processing_word, config.processing_tag, config.max_iter)\n",
        "test = CoNLLDataset(config.filename_test, config.processing_word, config.processing_tag, config.max_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxW8OXlMjrfv",
        "outputId": "68b0d4d5-5e6d-4431-ca4d-7a183ee0c040"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:Epoch 1 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1122s - train loss: 9.5235  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        21\n",
            "          END_DELITO       0.00      0.00      0.00        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.00      0.00      0.00       155\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.52      0.56      0.54      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.00      0.00      0.00       318\n",
            "       NOR_PRINCIPAL       0.35      0.13      0.19      1145\n",
            "                PENA       0.00      0.00      0.00        70\n",
            "           PES_ADVOG       0.00      0.00      0.00       155\n",
            "           PES_AUTOR       0.00      0.00      0.00       222\n",
            "PES_AUTORID_POLICIAL       0.00      0.00      0.00       531\n",
            "            PES_JUIZ       0.00      0.00      0.00       125\n",
            "          PES_OUTROS       0.09      0.00      0.00      1312\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        70\n",
            "             PES_REU       0.30      0.23      0.26      1663\n",
            "      PES_TESTEMUNHA       0.47      0.02      0.04       745\n",
            "          PES_VITIMA       0.00      0.00      0.00       488\n",
            "               PROVA       0.00      0.00      0.00       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.40      0.13      0.19      9218\n",
            "           macro avg       0.08      0.04      0.05      9218\n",
            "        weighted avg       0.21      0.13      0.14      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 90.40 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        21\n",
            "          END_DELITO       0.00      0.00      0.00        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.00      0.00      0.00       155\n",
            "      END_TESTEMUNHA       0.00      0.00      0.00        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.57      0.64      0.60      1151\n",
            "  NOR_JURISPRUDÊNCIA       1.00      0.00      0.01       318\n",
            "       NOR_PRINCIPAL       0.63      0.27      0.37      1145\n",
            "                PENA       0.00      0.00      0.00        70\n",
            "           PES_ADVOG       0.00      0.00      0.00       155\n",
            "           PES_AUTOR       0.00      0.00      0.00       222\n",
            "PES_AUTORID_POLICIAL       0.00      0.00      0.00       531\n",
            "            PES_JUIZ       0.00      0.00      0.00       125\n",
            "          PES_OUTROS       0.17      0.00      0.01      1312\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        70\n",
            "             PES_REU       0.33      0.25      0.29      1663\n",
            "      PES_TESTEMUNHA       0.47      0.02      0.04       745\n",
            "          PES_VITIMA       0.00      0.00      0.00       488\n",
            "               PROVA       0.00      0.00      0.00       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.47      0.16      0.24      9218\n",
            "           macro avg       0.15      0.06      0.06      9218\n",
            "        weighted avg       0.31      0.16      0.18      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21]\n",
            "B-END_DELITO\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 81]\n",
            "B-END_OUTROS\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0 123]\n",
            "B-END_REU\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0\n",
            "   0   0   0 153]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 78]\n",
            "B-END_VITIMA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 737   0 163   0   0   0   0   0   0   0   1   0\n",
            "   0   0   0 250]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   6   0   0   1   1   0   0   0   0   0   0   0   0   8   0\n",
            "   0   0   0 302]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 541   0 305   0   0   0   0   0   2   0   7   1\n",
            "   0   0   0 289]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 70]\n",
            "B-PES_ADVOG\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  13   0  35   0\n",
            "   0   0   0 107]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0  17   0\n",
            "   0   0   0 204]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0 132   1\n",
            "   0   0   0 397]\n",
            "B-PES_JUIZ\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10   0\n",
            "   0   0   0 115]\n",
            "B-PES_OUTROS\t[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    6    0  286    3    0    0    0 1017]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0 68]\n",
            "B-PES_REU\t[   0    0    0    0    0    0    1    0    0    0    0    0    0    0\n",
            "    5    0  423    8    0    0    0 1226]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0 248  14\n",
            "   0   0   0 480]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0  96   3\n",
            "   0   0   0 388]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0\n",
            "   0   0   0 730]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9]\n",
            "O\t[     0      0      0      1      0      0     20      0     17      0\n",
            "      0      0      0      0      2      0      2      0      0      0\n",
            "      0 381230]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 2 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1168s - train loss: 4.9798  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        21\n",
            "          END_DELITO       0.00      0.00      0.00        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.00      0.00      0.00       155\n",
            "      END_TESTEMUNHA       0.16      0.08      0.10        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.64      0.39      0.49      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.32      0.37      0.35       318\n",
            "       NOR_PRINCIPAL       0.35      0.39      0.37      1145\n",
            "                PENA       0.67      0.03      0.05        70\n",
            "           PES_ADVOG       0.00      0.00      0.00       155\n",
            "           PES_AUTOR       0.00      0.00      0.00       222\n",
            "PES_AUTORID_POLICIAL       0.48      0.02      0.04       531\n",
            "            PES_JUIZ       0.00      0.00      0.00       125\n",
            "          PES_OUTROS       0.17      0.17      0.17      1312\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        70\n",
            "             PES_REU       0.36      0.34      0.35      1663\n",
            "      PES_TESTEMUNHA       0.18      0.06      0.09       745\n",
            "          PES_VITIMA       0.00      0.00      0.00       488\n",
            "               PROVA       0.13      0.01      0.01       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.34      0.20      0.25      9218\n",
            "           macro avg       0.16      0.09      0.10      9218\n",
            "        weighted avg       0.28      0.20      0.22      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 91.16 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        21\n",
            "          END_DELITO       0.00      0.00      0.00        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.00      0.00      0.00       155\n",
            "      END_TESTEMUNHA       0.21      0.10      0.14        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.72      0.44      0.55      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.44      0.53      0.48       318\n",
            "       NOR_PRINCIPAL       0.59      0.76      0.66      1145\n",
            "                PENA       1.00      0.04      0.08        70\n",
            "           PES_ADVOG       0.00      0.00      0.00       155\n",
            "           PES_AUTOR       0.00      0.00      0.00       222\n",
            "PES_AUTORID_POLICIAL       0.55      0.02      0.04       531\n",
            "            PES_JUIZ       0.00      0.00      0.00       125\n",
            "          PES_OUTROS       0.23      0.23      0.23      1312\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        70\n",
            "             PES_REU       0.41      0.39      0.40      1663\n",
            "      PES_TESTEMUNHA       0.22      0.09      0.12       745\n",
            "          PES_VITIMA       0.00      0.00      0.00       488\n",
            "               PROVA       0.40      0.03      0.05       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.44      0.28      0.34      9218\n",
            "           macro avg       0.23      0.12      0.13      9218\n",
            "        weighted avg       0.37      0.28      0.29      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 0  0  0  0  3  0  0 11  0  0  0  0  0  0  2  0  0  0  0  0  0  5]\n",
            "B-END_DELITO\t[ 0  0  0  0  5  0  0 31  0  0  0  0  0  0  4  0  1  0  0  0  0 40]\n",
            "B-END_OUTROS\t[ 0  0  0  0  9  0  0 28  0  0  0  0  0  0  3  0  0  0  0  0  0 84]\n",
            "B-END_REU\t[ 0  0  0  0 12  0  0 74  0  0  0  0  0  0  9  0  0  1  0  0  0 59]\n",
            "B-END_TESTEMUNHA\t[ 0  1  0  0  8  0  0 41  0  0  0  0  0  0  4  0  0  0  0  0  0 24]\n",
            "B-END_VITIMA\t[ 0  0  0  0  0  0  0  7  0  0  0  0  0  0  1  0  0  0  0  0  0 13]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 507   1 521   0   0   0   0   0  17   0   0   0\n",
            "   0   0   0 105]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   1 168   0   0   0   0   0   0  28   0   4   0\n",
            "   0   0   0 117]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 171   2 866   0   0   0   0   0  18   0   2   0\n",
            "   0   2   0  84]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0  3  0  0  0  0  3  0  4  0  0 13  0 47]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  2  0  0  0  0  0  0 69  0  5  1  0  0  0 78]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   0   2   3   0   0   0   0   0  57   0  41   1\n",
            "   0   0   0 118]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   1   0   0   0   0  11   0 152   0  54  55\n",
            "   0   0   0 258]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 21  0  3  4  0  0  0 97]\n",
            "B-PES_OUTROS\t[  0   0   0   0   0   0   0   1   5   0   0   0   4   0 297   0 318  88\n",
            "   0   7   0 592]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  0  2  0 10  0  2  0  0  0  0 56]\n",
            "B-PES_REU\t[  0   0   0   0   0   0   0   2   0   0   0   0   1   0 254   0 643  72\n",
            "   0   2   0 689]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0 129   0 250  65\n",
            "   0   1   0 300]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  87   0 127   9\n",
            "   0   3   0 262]\n",
            "B-PROVA\t[  0   0   0   0   0   0   0   0   3   0   0   0   0   0  20   0  13   1\n",
            "   0  21   0 676]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 7]\n",
            "O\t[     0      0      0      0      2      0     28      9     69      0\n",
            "      0      0      2      0    105      0    118      4      0      3\n",
            "      0 378661]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 3 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1201s - train loss: 4.1750  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        21\n",
            "          END_DELITO       0.33      0.25      0.28        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.00      0.00      0.00       155\n",
            "      END_TESTEMUNHA       0.20      0.45      0.27        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.49      0.69      0.57      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.49      0.54      0.51       318\n",
            "       NOR_PRINCIPAL       0.48      0.19      0.27      1145\n",
            "                PENA       0.56      0.21      0.31        70\n",
            "           PES_ADVOG       0.00      0.00      0.00       155\n",
            "           PES_AUTOR       0.50      0.00      0.01       222\n",
            "PES_AUTORID_POLICIAL       0.24      0.06      0.10       531\n",
            "            PES_JUIZ       0.00      0.00      0.00       125\n",
            "          PES_OUTROS       0.22      0.35      0.27      1312\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        70\n",
            "             PES_REU       0.45      0.25      0.32      1663\n",
            "      PES_TESTEMUNHA       0.18      0.10      0.13       745\n",
            "          PES_VITIMA       0.00      0.00      0.00       488\n",
            "               PROVA       0.18      0.01      0.02       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.36      0.24      0.29      9218\n",
            "           macro avg       0.21      0.15      0.15      9218\n",
            "        weighted avg       0.31      0.24      0.24      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 91.65 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        21\n",
            "          END_DELITO       0.36      0.27      0.31        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.00      0.00      0.00       155\n",
            "      END_TESTEMUNHA       0.23      0.51      0.31        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.58      0.79      0.67      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.65      0.72      0.68       318\n",
            "       NOR_PRINCIPAL       0.72      0.31      0.43      1145\n",
            "                PENA       0.71      0.34      0.46        70\n",
            "           PES_ADVOG       0.00      0.00      0.00       155\n",
            "           PES_AUTOR       1.00      0.01      0.02       222\n",
            "PES_AUTORID_POLICIAL       0.56      0.14      0.23       531\n",
            "            PES_JUIZ       0.00      0.00      0.00       125\n",
            "          PES_OUTROS       0.27      0.43      0.33      1312\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        70\n",
            "             PES_REU       0.50      0.28      0.36      1663\n",
            "      PES_TESTEMUNHA       0.27      0.18      0.21       745\n",
            "          PES_VITIMA       0.00      0.00      0.00       488\n",
            "               PROVA       0.44      0.03      0.05       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.45      0.31      0.36      9218\n",
            "           macro avg       0.30      0.19      0.19      9218\n",
            "        weighted avg       0.44      0.31      0.32      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[0 6 0 0 8 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 4]\n",
            "B-END_DELITO\t[ 0 22  0  0 21  0  1  2  0  0  0  0  0  0  5  0  0  2  0  1  0 27]\n",
            "B-END_OUTROS\t[ 0  1  0  0 36  0  0  3  0  0  0  0  0  0  4  0  0  0  0  0  0 80]\n",
            "B-END_REU\t[ 0 24  0  0 61  0  0  6  0  0  0  0  0  0  4  0  0  1  0  0  0 59]\n",
            "B-END_TESTEMUNHA\t[ 0  4  0  0 40  0  0  6  0  0  0  0  3  0  2  0  0  3  0  0  0 20]\n",
            "B-END_VITIMA\t[ 0  1  0  0  6  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 13]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 914   8 114   0   0   0   0   0  14   0   0   1\n",
            "   0   0   0 100]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   1   0   3 228   0   0   0   0   0   0   7   0   0   2\n",
            "   0   0   0  77]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 597  75 350   0   0   0   0   0  11   0   4   0\n",
            "   0   1   0 107]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0 24  0  0  0  0  5  0  2  1  0 13  0 25]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0  0  0  1  0 79  0  2  2  0  0  0 71]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   1   3   1   0   0   2   3   0  74   0  23   6\n",
            "   0   0   0 109]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0  76   0 183   0   8  74\n",
            "   0   0   0 190]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  2  0 34  0  0  6  0  0  0 83]\n",
            "B-PES_OUTROS\t[  0   0   0   0   0   0   1   4   0   5   0   0  13   0 570   0 129  80\n",
            "   0   2   0 508]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  0  6  0 15  0  1  0  0  0  0 48]\n",
            "B-PES_REU\t[  0   0   0   0   0   0   0   2   0   0   0   0   7   0 480   0 473 131\n",
            "   0   2   0 568]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   0   0   0   0   1   0 238   0 121 131\n",
            "   0   1   0 253]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   1   0 155   0  92  23\n",
            "   0   1   0 216]\n",
            "B-PROVA\t[  0   0   0   0   2   0   6   3   0   5   0   0   0   0  24   0   5   1\n",
            "   0  19   0 669]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 7]\n",
            "O\t[     1      3      0      0      2      0     65     10     21      0\n",
            "      0      0     23      0    198      0     78     14      0      3\n",
            "      0 378353]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 4 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1232s - train loss: 3.7049  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.50      0.05      0.09        21\n",
            "          END_DELITO       0.45      0.28      0.35        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.56      0.28      0.38       155\n",
            "      END_TESTEMUNHA       0.28      0.54      0.37        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.51      0.71      0.59      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.48      0.63      0.55       318\n",
            "       NOR_PRINCIPAL       0.45      0.23      0.30      1145\n",
            "                PENA       0.59      0.33      0.42        70\n",
            "           PES_ADVOG       0.00      0.00      0.00       155\n",
            "           PES_AUTOR       0.88      0.07      0.13       222\n",
            "PES_AUTORID_POLICIAL       0.40      0.26      0.32       531\n",
            "            PES_JUIZ       0.95      0.15      0.26       125\n",
            "          PES_OUTROS       0.25      0.32      0.28      1312\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        70\n",
            "             PES_REU       0.45      0.41      0.43      1663\n",
            "      PES_TESTEMUNHA       0.31      0.13      0.18       745\n",
            "          PES_VITIMA       0.00      0.00      0.00       488\n",
            "               PROVA       0.17      0.01      0.01       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.41      0.30      0.35      9218\n",
            "           macro avg       0.35      0.21      0.22      9218\n",
            "        weighted avg       0.37      0.30      0.31      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 92.15 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.50      0.05      0.09        21\n",
            "          END_DELITO       0.47      0.30      0.36        81\n",
            "          END_OUTROS       1.00      0.10      0.18       124\n",
            "             END_REU       0.56      0.28      0.38       155\n",
            "      END_TESTEMUNHA       0.32      0.60      0.42        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.59      0.81      0.68      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.62      0.82      0.71       318\n",
            "       NOR_PRINCIPAL       0.70      0.40      0.51      1145\n",
            "                PENA       0.84      0.51      0.64        70\n",
            "           PES_ADVOG       0.00      0.00      0.00       155\n",
            "           PES_AUTOR       0.94      0.07      0.13       222\n",
            "PES_AUTORID_POLICIAL       0.55      0.36      0.44       531\n",
            "            PES_JUIZ       0.95      0.15      0.26       125\n",
            "          PES_OUTROS       0.34      0.45      0.39      1312\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        70\n",
            "             PES_REU       0.49      0.44      0.46      1663\n",
            "      PES_TESTEMUNHA       0.41      0.17      0.25       745\n",
            "          PES_VITIMA       0.00      0.00      0.00       488\n",
            "               PROVA       0.50      0.03      0.05       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.50      0.38      0.43      9218\n",
            "           macro avg       0.47      0.26      0.28      9218\n",
            "        weighted avg       0.50      0.38      0.39      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[1 3 0 8 5 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2]\n",
            "B-END_DELITO\t[ 0 24  0 18 17  0  3  3  0  0  0  0  0  0  1  0  0  0  0  0  0 15]\n",
            "B-END_OUTROS\t[ 0  5 12  2 26  0  7  6  0  0  0  0  0  0  3  0  0  0  0  0  0 63]\n",
            "B-END_REU\t[ 0 12  0 44 41  0  1  5  0  0  0  0  0  0  1  0  1  0  0  0  0 50]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  6 47  0  0  6  0  0  0  0  0  0  5  0  0  0  0  0  0 14]\n",
            "B-END_VITIMA\t[ 0  2  0  0  6  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0 11]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 929  13 138   0   0   0   0   0   5   0   0   0\n",
            "   0   0   0  66]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   1   0   5 262   0   0   0   0   0   0   0   0   0   1\n",
            "   0   0   0  49]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 540  71 454   0   0   0   0   0   6   0   4   0\n",
            "   0   1   0  69]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  1 36  0  0  3  0  0  0  3  0  0  4  0 23]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  4  0  0  0  0 12  0 74  0  3  3  0  0  0 59]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   0   2   4   0   0  16   7   0  51   0  19   6\n",
            "   0   0   0 117]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   1   0   0   0   0   0   2   0   0   1   0 191   0 136   0  14  34\n",
            "   0   0   0 152]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  1  0  0  0  0 15 19 23  0  3  6  0  0  0 58]\n",
            "B-PES_OUTROS\t[  0   0   0   0   0   0   3   9   0   0   0   0  19   0 589   0 209  34\n",
            "   0   6   0 443]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  2  0  0  0  1 19  0 13  0  0  0  0  0  0 35]\n",
            "B-PES_REU\t[  0   0   0   0   1   0  13   3   1   1   0   0  23   0 322   0 737  65\n",
            "   0   2   0 495]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   2   0   0   0   0  16   0 149   0 239 130\n",
            "   0   0   0 209]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   2   0   0   0   2   0  92   0 171  33\n",
            "   0   1   0 187]\n",
            "B-PROVA\t[  0   0   0   0   0   0  13   6   2   6   0   0   0   0  18   0  18   2\n",
            "   0  19   0 650]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 7]\n",
            "O\t[     1      4      0      0      3      0     73     23     45      0\n",
            "      0      0     39      1    227      0     89      2      1      5\n",
            "      0 376837]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 5 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1241s - train loss: 3.3980  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        21\n",
            "          END_DELITO       0.54      0.31      0.39        81\n",
            "          END_OUTROS       0.42      0.04      0.07       124\n",
            "             END_REU       0.59      0.37      0.45       155\n",
            "      END_TESTEMUNHA       0.44      0.53      0.48        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.53      0.74      0.61      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.50      0.65      0.57       318\n",
            "       NOR_PRINCIPAL       0.61      0.27      0.37      1145\n",
            "                PENA       0.60      0.39      0.47        70\n",
            "           PES_ADVOG       0.00      0.00      0.00       155\n",
            "           PES_AUTOR       0.89      0.11      0.20       222\n",
            "PES_AUTORID_POLICIAL       0.62      0.33      0.43       531\n",
            "            PES_JUIZ       0.84      0.17      0.28       125\n",
            "          PES_OUTROS       0.38      0.30      0.33      1312\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        70\n",
            "             PES_REU       0.43      0.52      0.47      1663\n",
            "      PES_TESTEMUNHA       0.33      0.05      0.09       745\n",
            "          PES_VITIMA       0.50      0.01      0.01       488\n",
            "               PROVA       0.44      0.01      0.01       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.48      0.33      0.39      9218\n",
            "           macro avg       0.41      0.23      0.25      9218\n",
            "        weighted avg       0.48      0.33      0.34      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 92.78 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.50      0.10      0.16        21\n",
            "          END_DELITO       0.57      0.32      0.41        81\n",
            "          END_OUTROS       0.85      0.09      0.16       124\n",
            "             END_REU       0.60      0.37      0.46       155\n",
            "      END_TESTEMUNHA       0.48      0.58      0.52        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.61      0.83      0.70      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.63      0.84      0.72       318\n",
            "       NOR_PRINCIPAL       0.77      0.35      0.49      1145\n",
            "                PENA       0.83      0.56      0.67        70\n",
            "           PES_ADVOG       0.00      0.00      0.00       155\n",
            "           PES_AUTOR       0.93      0.12      0.21       222\n",
            "PES_AUTORID_POLICIAL       0.71      0.38      0.50       531\n",
            "            PES_JUIZ       0.96      0.19      0.32       125\n",
            "          PES_OUTROS       0.46      0.37      0.41      1312\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        70\n",
            "             PES_REU       0.47      0.57      0.51      1663\n",
            "      PES_TESTEMUNHA       0.38      0.06      0.10       745\n",
            "          PES_VITIMA       0.50      0.01      0.01       488\n",
            "               PROVA       0.73      0.01      0.02       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.56      0.38      0.46      9218\n",
            "           macro avg       0.52      0.27      0.30      9218\n",
            "        weighted avg       0.57      0.38      0.40      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[2 3 0 9 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 4]\n",
            "B-END_DELITO\t[ 0 26  0 16  5  0  0  1  0  0  0  0  0  0  3  0  0  0  0  0  0 30]\n",
            "B-END_OUTROS\t[ 0  5 11  5 10  0  0  4  0  0  0  0  0  0  3  0  0  0  0  0  0 86]\n",
            "B-END_REU\t[ 0  8  2 58 26  0  0  3  0  0  0  0  0  0  0  0  2  0  0  0  0 56]\n",
            "B-END_TESTEMUNHA\t[ 0  2  0  9 45  0  0  5  0  0  0  0  0  0  0  0  0  1  0  0  0 16]\n",
            "B-END_VITIMA\t[ 0  1  0  0  6  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 13]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 950  15  95   0   0   0   0   0   5   0   0   0\n",
            "   0   0   0  86]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   2 266   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0  50]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 542  75 405   0   0   0   0   0   6   0   3   0\n",
            "   0   0   0 114]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0 39  0  0  1  0  1  0  2  0  0  1  0 26]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0  0  0  2  0 69  0  8  1  0  0  0 75]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   0   1   2   0   0  26   7   0  16   0  44   1\n",
            "   0   0   0 125]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   2   0   0   0   0 203   0  68   0  31  25\n",
            "   0   0   0 202]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  1  0  0  0  0  7 24 20  0  3  2  0  0  0 68]\n",
            "B-PES_OUTROS\t[  0   0   0   0   0   0   1   5   0   0   0   1  10   0 489   0 252   5\n",
            "   1   0   0 548]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  1  0  0  0  1 12  0  8  0  1  0  0  0  0 47]\n",
            "B-PES_REU\t[  0   0   0   0   0   0   0   4   0   0   0   0  21   0 127   0 942  19\n",
            "   0   1   0 549]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   4   0   0   0   0   8   0  89   0 344  44\n",
            "   0   0   0 256]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   3   0   0   0   0   0   0  32   0 238   9\n",
            "   3   1   0 202]\n",
            "B-PROVA\t[  0   0   0   0   0   0   5   6   0   7   0   0   0   0   9   0  13   2\n",
            "   0   8   0 684]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 7]\n",
            "O\t[     2      1      0      0      1      0     68     21     23      1\n",
            "      0      0     14      1    111      0    120      6      2      0\n",
            "      0 379168]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 6 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1239s - train loss: 3.1763  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        21\n",
            "          END_DELITO       0.40      0.02      0.05        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.42      0.05      0.09       155\n",
            "      END_TESTEMUNHA       0.21      0.71      0.33        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.50      0.71      0.59      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.39      0.66      0.49       318\n",
            "       NOR_PRINCIPAL       0.71      0.17      0.28      1145\n",
            "                PENA       0.00      0.00      0.00        70\n",
            "           PES_ADVOG       0.36      0.03      0.06       155\n",
            "           PES_AUTOR       0.62      0.07      0.13       222\n",
            "PES_AUTORID_POLICIAL       0.66      0.31      0.42       531\n",
            "            PES_JUIZ       0.74      0.30      0.42       125\n",
            "          PES_OUTROS       0.34      0.32      0.33      1312\n",
            "     PES_PROMOTOR_MP       0.00      0.00      0.00        70\n",
            "             PES_REU       0.54      0.30      0.39      1663\n",
            "      PES_TESTEMUNHA       0.27      0.19      0.22       745\n",
            "          PES_VITIMA       0.62      0.01      0.02       488\n",
            "               PROVA       0.00      0.01      0.00       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.25      0.28      0.27      9218\n",
            "           macro avg       0.32      0.18      0.18      9218\n",
            "        weighted avg       0.45      0.28      0.30      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 27.13 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.00      0.00      0.00        21\n",
            "          END_DELITO       0.50      0.02      0.05        81\n",
            "          END_OUTROS       0.71      0.14      0.23       124\n",
            "             END_REU       0.47      0.06      0.10       155\n",
            "      END_TESTEMUNHA       0.26      0.71      0.38        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.55      0.81      0.66      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.50      0.81      0.62       318\n",
            "       NOR_PRINCIPAL       0.84      0.21      0.34      1145\n",
            "                PENA       0.00      0.00      0.00        70\n",
            "           PES_ADVOG       0.60      0.08      0.14       155\n",
            "           PES_AUTOR       0.73      0.09      0.15       222\n",
            "PES_AUTORID_POLICIAL       0.83      0.39      0.53       531\n",
            "            PES_JUIZ       0.82      0.34      0.48       125\n",
            "          PES_OUTROS       0.42      0.41      0.42      1312\n",
            "     PES_PROMOTOR_MP       1.00      0.04      0.08        70\n",
            "             PES_REU       0.57      0.33      0.42      1663\n",
            "      PES_TESTEMUNHA       0.30      0.23      0.26       745\n",
            "          PES_VITIMA       0.60      0.01      0.02       488\n",
            "               PROVA       0.11      0.89      0.20       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.31      0.40      0.35      9218\n",
            "           macro avg       0.47      0.27      0.24      9218\n",
            "        weighted avg       0.54      0.40      0.37      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 0  0  0  2  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0]\n",
            "B-END_DELITO\t[ 0  2  0  3 16  0  0  2  0  0  0  0  0  0  3  0  0  0  0 53  0  2]\n",
            "B-END_OUTROS\t[ 0  0 17  0 26  2  1  4  0  0  0  0  0  0  2  0  0  0  0 57  0 15]\n",
            "B-END_REU\t[ 0  0  0  9 84  1  1  0  0  0  0  0  0  0  4  0  0  0  0 53  0  3]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  0 55  0  0  2  0  0  0  0  0  0  2  0  1  1  0 16  0  1]\n",
            "B-END_VITIMA\t[ 0  0  0  0  7  0  0  1  0  0  0  0  0  0  1  0  0  0  0 10  0  2]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 938  17  32   0   0   0   0   0   0   0   0   0\n",
            "   0 158   0   6]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   3 259   0   0   0   0   0   1   0   0   0   0\n",
            "   0  49   0   6]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 674  74 242   0   0   0   0   0   2   0   1   0\n",
            "   0 143   0   9]\n",
            "B-PENA\t[ 0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  2  1  0 63  0  1]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  1  0  1  1  0  0 12  0  0  0 79  0  5 10  0 17  0 29]\n",
            "B-PES_AUTOR\t[  0   0   0   0   0   0   1   5   2   0   1  19   4   0  22   0  20   9\n",
            "   0 107   0  32]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   1   1   0   0   7   0   0   1   0 206   1 118   0   8  47\n",
            "   0  95   0  46]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  7  0  0  0  0  7 42 25  0  0 11  0 21  0 12]\n",
            "B-PES_OUTROS\t[  0   0   1   0   3   0   3  16   0   0   3   0   2   0 544   0  76  58\n",
            "   2 474   0 130]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  9  0  0  1  1 13  4 12  3  0  3  0 14  0 10]\n",
            "B-PES_REU\t[  0   0   0   0   1   0   6  10   1   0   0   0   2   0 159   0 552 171\n",
            "   1 706   0  54]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   1   0   0  11   0   0   0   0   0   0  75   0 157 172\n",
            "   0 299   0  30]\n",
            "B-PES_VITIMA\t[  0   0   0   0   1   0   4   8   0   0   0   0   0   0  34   0  83  53\n",
            "   6 292   0   7]\n",
            "B-PROVA\t[  0   0   0   0   1   0   3   5   0   0   2   0   2   0   8   0  15   5\n",
            "   0 652   0  41]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 8 0 0]\n",
            "O\t[    0     2     6     4    14     1    71    80    11     0     0     6\n",
            "    12     3   193     0    40    24     1  2645     0 93251]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 7 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1225s - train loss: 3.0617  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.30      0.29      0.29        21\n",
            "          END_DELITO       0.38      0.44      0.41        81\n",
            "          END_OUTROS       0.08      0.05      0.06       124\n",
            "             END_REU       0.65      0.20      0.31       155\n",
            "      END_TESTEMUNHA       0.32      0.67      0.43        78\n",
            "          END_VITIMA       0.04      0.05      0.05        21\n",
            "       NOR_ACESSORIA       0.47      0.77      0.59      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.65      0.68      0.66       318\n",
            "       NOR_PRINCIPAL       0.72      0.24      0.36      1145\n",
            "                PENA       1.00      0.06      0.11        70\n",
            "           PES_ADVOG       0.19      0.05      0.07       155\n",
            "           PES_AUTOR       0.74      0.19      0.31       222\n",
            "PES_AUTORID_POLICIAL       0.67      0.40      0.51       531\n",
            "            PES_JUIZ       0.73      0.46      0.57       125\n",
            "          PES_OUTROS       0.44      0.33      0.38      1312\n",
            "     PES_PROMOTOR_MP       0.38      0.11      0.18        70\n",
            "             PES_REU       0.48      0.50      0.49      1663\n",
            "      PES_TESTEMUNHA       0.33      0.25      0.28       745\n",
            "          PES_VITIMA       0.36      0.03      0.06       488\n",
            "               PROVA       0.01      0.03      0.01       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.38      0.36      0.37      9218\n",
            "           macro avg       0.43      0.28      0.29      9218\n",
            "        weighted avg       0.47      0.36      0.37      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 72.64 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.46      0.29      0.35        21\n",
            "          END_DELITO       0.44      0.52      0.47        81\n",
            "          END_OUTROS       0.43      0.27      0.33       124\n",
            "             END_REU       0.70      0.21      0.33       155\n",
            "      END_TESTEMUNHA       0.36      0.74      0.49        78\n",
            "          END_VITIMA       0.04      0.05      0.04        21\n",
            "       NOR_ACESSORIA       0.54      0.90      0.68      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.83      0.86      0.85       318\n",
            "       NOR_PRINCIPAL       0.84      0.29      0.43      1145\n",
            "                PENA       1.00      0.06      0.11        70\n",
            "           PES_ADVOG       0.68      0.17      0.28       155\n",
            "           PES_AUTOR       0.83      0.22      0.34       222\n",
            "PES_AUTORID_POLICIAL       0.78      0.47      0.59       531\n",
            "            PES_JUIZ       0.88      0.55      0.68       125\n",
            "          PES_OUTROS       0.52      0.39      0.45      1312\n",
            "     PES_PROMOTOR_MP       0.67      0.20      0.31        70\n",
            "             PES_REU       0.53      0.55      0.54      1663\n",
            "      PES_TESTEMUNHA       0.38      0.31      0.34       745\n",
            "          PES_VITIMA       0.43      0.04      0.07       488\n",
            "               PROVA       0.20      0.70      0.31       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.46      0.48      0.47      9218\n",
            "           macro avg       0.55      0.37      0.38      9218\n",
            "        weighted avg       0.57      0.48      0.46      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[6 5 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 2]\n",
            "B-END_DELITO\t[ 0 42  2  3  6  1  0  0  0  0  0  0  0  0  0  0  0  0  0 21  0  6]\n",
            "B-END_OUTROS\t[ 3  6 33  3 14  9  0  1  0  0  0  0  0  0  3  0  0  0  0 25  0 27]\n",
            "B-END_REU\t[ 3 24  4 33 55  8  0  0  0  0  0  0  0  0  2  0  0  1  0 10  0 15]\n",
            "B-END_TESTEMUNHA\t[ 0  4  0  1 58  0  0  1  0  0  0  0  0  0  0  0  0  1  0  9  0  4]\n",
            "B-END_VITIMA\t[0 1 0 2 7 1 0 0 0 0 0 0 0 0 3 0 0 0 0 5 0 2]\n",
            "B-NOR_ACESSORIA\t[   0    0    0    0    0    0 1039    9   37    0    0    0    0    0\n",
            "    0    0    0    0    0   49    0   17]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   1   0   0   0   1 275   0   0   0   0   0   0   0   0   0   0\n",
            "   0  21   0  20]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 740   7 330   0   0   0   0   0   0   0   1   1\n",
            "   0  38   0  28]\n",
            "B-PENA\t[ 0  0  0  0  0  0  1  0  0  4  0  0  0  0  0  0  2  1  0 58  0  4]\n",
            "B-PES_ADVOG\t[ 0  0  1  0  0  1  0  0  0  0 27  1  0  0 59  0 10  5  0  3  0 48]\n",
            "B-PES_AUTOR\t[ 0  0  0  0  1  0  1  0  1  0  1 48  9  0  9  0 32  4  0 29  0 87]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   2   0 250   1  65   0  34  52\n",
            "   0  18   0 109]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  6 69 17  0  6  4  0  5  0 18]\n",
            "B-PES_OUTROS\t[  0   0   0   0   0   2   2   5   1   0   5   0  10   1 516   2 190  72\n",
            "   3 200   0 303]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  3  0  0  0  1 17  2  4 14  0  4  0  2  0 23]\n",
            "B-PES_REU\t[  0   0   0   0   1   0   1   1   0   0   0   0   8   0  84   0 914 121\n",
            "   1 377   0 155]\n",
            "B-PES_TESTEMUNHA\t[  0   1   0   0   0   1   0   0   0   0   0   0   1   1  32   0 232 228\n",
            "  16 158   0  75]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   1   0  14   0 169  55\n",
            "  20 194   0  35]\n",
            "B-PROVA\t[  0   0   0   0   0   0   3   1   0   0   0   0   0   0   0   0   6   7\n",
            "   0 512   0 205]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4 0 4]\n",
            "O\t[     1     13     36      3     16      4    130     28     23      0\n",
            "      5      8     19      4    181      5    134     38      6    866\n",
            "      0 286638]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 8 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1234s - train loss: 2.9154  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.25      0.24      0.24        21\n",
            "          END_DELITO       0.69      0.33      0.45        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.49      0.27      0.35       155\n",
            "      END_TESTEMUNHA       0.42      0.64      0.51        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.44      0.73      0.55      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.54      0.69      0.61       318\n",
            "       NOR_PRINCIPAL       0.60      0.16      0.25      1145\n",
            "                PENA       0.44      0.10      0.16        70\n",
            "           PES_ADVOG       0.41      0.09      0.15       155\n",
            "           PES_AUTOR       0.79      0.20      0.32       222\n",
            "PES_AUTORID_POLICIAL       0.65      0.41      0.50       531\n",
            "            PES_JUIZ       0.62      0.49      0.55       125\n",
            "          PES_OUTROS       0.41      0.34      0.37      1312\n",
            "     PES_PROMOTOR_MP       0.46      0.09      0.14        70\n",
            "             PES_REU       0.53      0.46      0.49      1663\n",
            "      PES_TESTEMUNHA       0.38      0.30      0.34       745\n",
            "          PES_VITIMA       0.48      0.06      0.11       488\n",
            "               PROVA       0.01      0.02      0.01       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.35      0.35      0.35      9218\n",
            "           macro avg       0.41      0.27      0.29      9218\n",
            "        weighted avg       0.46      0.35      0.36      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 63.86 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.46      0.29      0.35        21\n",
            "          END_DELITO       0.77      0.37      0.50        81\n",
            "          END_OUTROS       0.50      0.10      0.17       124\n",
            "             END_REU       0.52      0.29      0.37       155\n",
            "      END_TESTEMUNHA       0.48      0.71      0.57        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.53      0.91      0.67      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.68      0.89      0.77       318\n",
            "       NOR_PRINCIPAL       0.85      0.24      0.38      1145\n",
            "                PENA       0.65      0.19      0.29        70\n",
            "           PES_ADVOG       0.76      0.19      0.30       155\n",
            "           PES_AUTOR       0.86      0.22      0.35       222\n",
            "PES_AUTORID_POLICIAL       0.79      0.49      0.60       531\n",
            "            PES_JUIZ       0.76      0.60      0.67       125\n",
            "          PES_OUTROS       0.48      0.40      0.44      1312\n",
            "     PES_PROMOTOR_MP       0.85      0.16      0.27        70\n",
            "             PES_REU       0.57      0.50      0.53      1663\n",
            "      PES_TESTEMUNHA       0.45      0.38      0.41       745\n",
            "          PES_VITIMA       0.53      0.07      0.13       488\n",
            "               PROVA       0.16      0.76      0.27       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.43      0.48      0.45      9218\n",
            "           macro avg       0.55      0.37      0.38      9218\n",
            "        weighted avg       0.57      0.48      0.46      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[6 3 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0]\n",
            "B-END_DELITO\t[ 0 30  0  7  5  0  0  1  0  0  0  0  0  0  1  0  0  0  0 33  0  4]\n",
            "B-END_OUTROS\t[ 3  1 13  6  8 10  0  4  0  0  0  0  0  0  3  0  0  0  0 47  0 29]\n",
            "B-END_REU\t[ 4  3  0 45 40  1  0  0  0  0  0  0  0  0  3  0  0  1  0 53  0  5]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  4 55  0  0  3  0  0  0  0  0  0  0  0  0  1  0 14  0  1]\n",
            "B-END_VITIMA\t[0 0 0 2 6 0 0 2 0 0 0 0 0 0 2 0 0 0 0 8 0 1]\n",
            "B-NOR_ACESSORIA\t[   0    0    0    0    0    0 1042   15   28    0    0    0    0    0\n",
            "    0    0    0    0    0   53    0   13]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   0 284   0   0   0   0   0   0   0   0   0   0\n",
            "   0  21   0  13]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 785  12 280   0   0   0   0   0   0   0   1   1\n",
            "   1  43   0  22]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  2  1  0 50  0  4]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 29  1  0  0 64  0  7  7  1  4  0 42]\n",
            "B-PES_AUTOR\t[ 0  0  0  0  0  0  1  2  1  0  0 49 10  0 13  0 23  4  0 40  0 79]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   2   0   0   1   0 260   2  81   0  23  39\n",
            "   0  37   0  86]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  1  3  0  0  0  0  3 75  9  0  5  5  0  7  0 17]\n",
            "B-PES_OUTROS\t[  0   0   0   0   0   1   5  15   0   0   1   0   9   3 528   0 166  66\n",
            "   1 282   0 235]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  3  0  0  0  1 16  5 13 11  0  1  0  4  0 16]\n",
            "B-PES_REU\t[  0   0   0   0   0   0   1   6   0   0   0   0   3   0 113   0 829 120\n",
            "   1 469   0 121]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   0   0   0   0   2   2  25   0 170 283\n",
            "  15 179   0  69]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   2   1   0   0   0   0   0   0  17   0 131  61\n",
            "  35 222   0  19]\n",
            "B-PROVA\t[  0   0   0   0   0   0   1   2   1   2   0   0   0   0   1   0   4   7\n",
            "   0 558   0 158]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4 0 4]\n",
            "O\t[     0      2     13     18      1      1    133     64     19      5\n",
            "      7      6     28     12    218      2     88     37     12   1297\n",
            "      0 248654]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 9 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1241s - train loss: 2.7705  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.29      0.33      0.31        21\n",
            "          END_DELITO       0.92      0.14      0.24        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.42      0.30      0.35       155\n",
            "      END_TESTEMUNHA       0.27      0.64      0.38        78\n",
            "          END_VITIMA       0.02      0.05      0.03        21\n",
            "       NOR_ACESSORIA       0.53      0.79      0.64      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.68      0.70      0.69       318\n",
            "       NOR_PRINCIPAL       0.67      0.34      0.45      1145\n",
            "                PENA       0.53      0.29      0.37        70\n",
            "           PES_ADVOG       0.63      0.39      0.48       155\n",
            "           PES_AUTOR       0.74      0.27      0.39       222\n",
            "PES_AUTORID_POLICIAL       0.68      0.45      0.54       531\n",
            "            PES_JUIZ       0.73      0.53      0.61       125\n",
            "          PES_OUTROS       0.51      0.34      0.41      1312\n",
            "     PES_PROMOTOR_MP       0.50      0.17      0.26        70\n",
            "             PES_REU       0.55      0.50      0.52      1663\n",
            "      PES_TESTEMUNHA       0.38      0.37      0.38       745\n",
            "          PES_VITIMA       0.49      0.12      0.20       488\n",
            "               PROVA       0.05      0.06      0.05       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.48      0.41      0.44      9218\n",
            "           macro avg       0.46      0.32      0.35      9218\n",
            "        weighted avg       0.51      0.41      0.43      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 86.20 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.41      0.43      0.42        21\n",
            "          END_DELITO       0.92      0.14      0.24        81\n",
            "          END_OUTROS       0.50      0.06      0.11       124\n",
            "             END_REU       0.45      0.32      0.37       155\n",
            "      END_TESTEMUNHA       0.30      0.72      0.42        78\n",
            "          END_VITIMA       0.02      0.10      0.03        21\n",
            "       NOR_ACESSORIA       0.60      0.88      0.72      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.86      0.89      0.88       318\n",
            "       NOR_PRINCIPAL       0.85      0.43      0.57      1145\n",
            "                PENA       0.67      0.40      0.50        70\n",
            "           PES_ADVOG       0.82      0.54      0.65       155\n",
            "           PES_AUTOR       0.80      0.29      0.42       222\n",
            "PES_AUTORID_POLICIAL       0.78      0.52      0.63       531\n",
            "            PES_JUIZ       0.86      0.63      0.73       125\n",
            "          PES_OUTROS       0.59      0.39      0.47      1312\n",
            "     PES_PROMOTOR_MP       0.83      0.29      0.43        70\n",
            "             PES_REU       0.59      0.54      0.56      1663\n",
            "      PES_TESTEMUNHA       0.43      0.44      0.43       745\n",
            "          PES_VITIMA       0.57      0.15      0.23       488\n",
            "               PROVA       0.30      0.62      0.41       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.56      0.52      0.54      9218\n",
            "           macro avg       0.58      0.42      0.44      9218\n",
            "        weighted avg       0.62      0.52      0.53      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[9 0 0 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]\n",
            "B-END_DELITO\t[ 0 11  0 19 20  6  0  0  0  0  0  0  0  0  0  0  1  0  0 17  0  7]\n",
            "B-END_OUTROS\t[ 5  0  8 13 14 31  0  0  0  0  0  0  0  0  1  0  0  0  2  5  0 45]\n",
            "B-END_REU\t[ 5  0  0 49 59 15  0  0  0  0  0  0  1  0  0  0  0  1  0  5  0 20]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  5 56  2  0  1  0  0  0  0  0  0  0  0  0  1  0  6  0  7]\n",
            "B-END_VITIMA\t[0 0 1 3 7 2 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 5]\n",
            "B-NOR_ACESSORIA\t[   0    0    0    0    0    0 1015   11   60    0    0    0    0    0\n",
            "    0    0    0    0    1   21    0   43]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   1 284   0   0   0   0   0   0   0   0   0   0\n",
            "   0   7   0  26]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 569   7 498   0   0   0   0   0   1   0   2   0\n",
            "   0  11   0  57]\n",
            "B-PENA\t[ 0  0  0  0  0  0  1  0  0 28  0  0  0  0  0  0  2  0  0 33  0  6]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 83  1  0  0 18  0  7  2  1  0  0 43]\n",
            "B-PES_AUTOR\t[ 0  0  0  1  1  0  0  0  1  0  1 64 10  0 11  0 16  5  2 12  0 98]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   1   0   0   3   0 278   0  49   0  20  59\n",
            "   0  10   0 111]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  1 79 11  0  4  6  1  1  0 22]\n",
            "B-PES_OUTROS\t[  0   0   1   0   4  21   2   6   1   0   5   0  16   0 516   0 167 100\n",
            "   9 124   0 340]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  1  0  0  0  1 15  3  7 20  0  4  0  1  0 18]\n",
            "B-PES_REU\t[  0   0   0   0   1   2   2   3   0   0   0   1  11   0  78   0 898 158\n",
            "   5 287   0 217]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   2   0   0   0   0   0   0   2   2  26   0 136 328\n",
            "  23 118   0 108]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   3   0   0   0   0   0   0   1   1  16   0 150  54\n",
            "  72 142   0  49]\n",
            "B-PROVA\t[  0   0   0   0   3   0   0   1   0   3   0   0   0   0   2   0   6   9\n",
            "   0 452   0 258]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 3 0 5]\n",
            "O\t[     3      1      6     14     16     17     91     16     28     11\n",
            "      9     13     22      7    142      4    106     44     10    227\n",
            "      0 344087]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 10 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1254s - train loss: 2.6579  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.36      0.19      0.25        21\n",
            "          END_DELITO       0.63      0.27      0.38        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.43      0.45      0.44       155\n",
            "      END_TESTEMUNHA       0.43      0.63      0.51        78\n",
            "          END_VITIMA       0.01      0.05      0.02        21\n",
            "       NOR_ACESSORIA       0.54      0.76      0.63      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.76      0.68      0.72       318\n",
            "       NOR_PRINCIPAL       0.65      0.33      0.43      1145\n",
            "                PENA       0.58      0.21      0.31        70\n",
            "           PES_ADVOG       0.62      0.40      0.49       155\n",
            "           PES_AUTOR       0.70      0.26      0.38       222\n",
            "PES_AUTORID_POLICIAL       0.61      0.42      0.49       531\n",
            "            PES_JUIZ       0.68      0.50      0.58       125\n",
            "          PES_OUTROS       0.47      0.35      0.40      1312\n",
            "     PES_PROMOTOR_MP       0.56      0.29      0.38        70\n",
            "             PES_REU       0.55      0.52      0.54      1663\n",
            "      PES_TESTEMUNHA       0.49      0.34      0.40       745\n",
            "          PES_VITIMA       0.59      0.11      0.18       488\n",
            "               PROVA       0.02      0.05      0.02       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.42      0.40      0.41      9218\n",
            "           macro avg       0.46      0.32      0.36      9218\n",
            "        weighted avg       0.51      0.40      0.43      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 68.99 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.83      0.24      0.37        21\n",
            "          END_DELITO       0.69      0.31      0.43        81\n",
            "          END_OUTROS       0.60      0.02      0.05       124\n",
            "             END_REU       0.46      0.50      0.48       155\n",
            "      END_TESTEMUNHA       0.46      0.68      0.55        78\n",
            "          END_VITIMA       0.03      0.14      0.04        21\n",
            "       NOR_ACESSORIA       0.60      0.86      0.71      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.92      0.83      0.87       318\n",
            "       NOR_PRINCIPAL       0.83      0.43      0.57      1145\n",
            "                PENA       0.68      0.27      0.39        70\n",
            "           PES_ADVOG       0.83      0.56      0.67       155\n",
            "           PES_AUTOR       0.78      0.28      0.42       222\n",
            "PES_AUTORID_POLICIAL       0.76      0.53      0.62       531\n",
            "            PES_JUIZ       0.84      0.62      0.71       125\n",
            "          PES_OUTROS       0.53      0.40      0.46      1312\n",
            "     PES_PROMOTOR_MP       0.78      0.40      0.53        70\n",
            "             PES_REU       0.59      0.57      0.58      1663\n",
            "      PES_TESTEMUNHA       0.54      0.39      0.46       745\n",
            "          PES_VITIMA       0.63      0.12      0.20       488\n",
            "               PROVA       0.18      0.73      0.29       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.49      0.52      0.51      9218\n",
            "           macro avg       0.60      0.42      0.45      9218\n",
            "        weighted avg       0.61      0.52      0.52      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 5  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  2]\n",
            "B-END_DELITO\t[ 0 25  0 24  2  4  0  0  0  0  0  0  0  0  2  0  0  0  0 20  0  4]\n",
            "B-END_OUTROS\t[ 0  2  3 12 12 40  0  0  0  0  0  0  0  0  1  0  0  0  0 14  0 40]\n",
            "B-END_REU\t[ 1  3  0 78 27 13  0  0  0  0  0  0  2  0  6  0  0  0  0 19  0  6]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0 13 53  2  0  0  0  0  0  0  0  0  1  0  0  1  0  6  0  2]\n",
            "B-END_VITIMA\t[0 0 0 5 6 3 0 0 0 0 0 0 0 0 3 0 0 0 0 4 0 0]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 990   6  69   0   0   0   0   0   1   0   0   0\n",
            "   0  47   0  38]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   1   0   2 263   0   0   0   0   0   0   0   0   0   0\n",
            "   0  19   0  33]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 565   3 498   0   0   0   0   0   0   0   2   0\n",
            "   0  35   0  42]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  2  0  0 43  0  6]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 87  1  0  0 16  0  8  0  1  3  0 39]\n",
            "B-PES_AUTOR\t[ 0  0  0  0  1  1  0  0  1  0  1 63 10  0  6  0 23  2  0 37  0 77]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   1   0   1   0   0   0   0   1   0 281   0  78   0  27  40\n",
            "   0  19   0  83]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  2 77 15  1  5  3  0  6  0 16]\n",
            "B-PES_OUTROS\t[  0   2   0   3   2  24   3   3   1   0   4   0  18   1 530   2 185  58\n",
            "   4 220   0 252]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1 14  2 10 28  0  0  0  2  0 13]\n",
            "B-PES_REU\t[  0   0   0   0   1   3   1   1   0   0   1   2   6   0  89   0 945  62\n",
            "   2 418   0 132]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   2   0   0   0   0   0   0   5   2  28   0 161 292\n",
            "  16 171   0  68]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   3   0   0   0   0   0   0   0   0  22   0 127  41\n",
            "  57 218   0  20]\n",
            "B-PROVA\t[  0   0   0   4   0   0   1   0   0   3   0   0   0   0   0   0   5   8\n",
            "   0 537   0 176]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4 0 4]\n",
            "O\t[     0      4      2     20      9     22     78      9     34      6\n",
            "     11     14     33     10    190      5    111     31     10   1097\n",
            "      0 268752]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 11 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1251s - train loss: 2.5899  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.75      0.14      0.24        21\n",
            "          END_DELITO       0.61      0.14      0.22        81\n",
            "          END_OUTROS       0.12      0.01      0.02       124\n",
            "             END_REU       0.33      0.62      0.43       155\n",
            "      END_TESTEMUNHA       0.61      0.49      0.54        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.58      0.78      0.66      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.79      0.69      0.74       318\n",
            "       NOR_PRINCIPAL       0.67      0.39      0.49      1145\n",
            "                PENA       0.59      0.31      0.41        70\n",
            "           PES_ADVOG       0.66      0.43      0.52       155\n",
            "           PES_AUTOR       0.73      0.30      0.42       222\n",
            "PES_AUTORID_POLICIAL       0.67      0.49      0.56       531\n",
            "            PES_JUIZ       0.74      0.50      0.59       125\n",
            "          PES_OUTROS       0.49      0.35      0.41      1312\n",
            "     PES_PROMOTOR_MP       0.55      0.31      0.40        70\n",
            "             PES_REU       0.53      0.55      0.54      1663\n",
            "      PES_TESTEMUNHA       0.49      0.34      0.40       745\n",
            "          PES_VITIMA       0.48      0.16      0.25       488\n",
            "               PROVA       0.06      0.07      0.07       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.50      0.43      0.46      9218\n",
            "           macro avg       0.50      0.34      0.38      9218\n",
            "        weighted avg       0.52      0.43      0.45      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 88.06 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       1.00      0.14      0.25        21\n",
            "          END_DELITO       0.72      0.16      0.26        81\n",
            "          END_OUTROS       0.71      0.04      0.08       124\n",
            "             END_REU       0.39      0.77      0.52       155\n",
            "      END_TESTEMUNHA       0.69      0.54      0.60        78\n",
            "          END_VITIMA       0.00      0.00      0.00        21\n",
            "       NOR_ACESSORIA       0.64      0.86      0.73      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.96      0.84      0.90       318\n",
            "       NOR_PRINCIPAL       0.83      0.51      0.63      1145\n",
            "                PENA       0.76      0.44      0.56        70\n",
            "           PES_ADVOG       0.88      0.60      0.71       155\n",
            "           PES_AUTOR       0.79      0.32      0.46       222\n",
            "PES_AUTORID_POLICIAL       0.77      0.56      0.65       531\n",
            "            PES_JUIZ       0.88      0.59      0.71       125\n",
            "          PES_OUTROS       0.57      0.40      0.47      1312\n",
            "     PES_PROMOTOR_MP       0.78      0.44      0.56        70\n",
            "             PES_REU       0.57      0.61      0.59      1663\n",
            "      PES_TESTEMUNHA       0.53      0.39      0.45       745\n",
            "          PES_VITIMA       0.53      0.18      0.27       488\n",
            "               PROVA       0.32      0.59      0.42       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.59      0.54      0.56      9218\n",
            "           macro avg       0.63      0.43      0.47      9218\n",
            "        weighted avg       0.63      0.54      0.55      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 3  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  2]\n",
            "B-END_DELITO\t[ 0 13  0 51  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  7]\n",
            "B-END_OUTROS\t[ 0  0  5 35  5 14  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0 48]\n",
            "B-END_REU\t[  0   1   0 120   8   2   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "   0   6   0  17]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0 23 42  2  0  0  0  0  0  0  0  0  0  0  0  1  0  4  0  6]\n",
            "B-END_VITIMA\t[0 0 0 9 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 6]\n",
            "B-NOR_ACESSORIA\t[  0   0   0   0   0   0 992   3  82   0   0   0   0   0   3   0   0   0\n",
            "   1  16   0  54]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   2 267   0   0   0   0   0   0   1   0   0   0\n",
            "   0  10   0  38]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 494   3 582   0   0   0   0   0   0   0   2   0\n",
            "   0  10   0  54]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0 31  0  0  0  0  2  0  0  0  0 30  0  7]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 93  1  0  0 12  0  8  0  1  0  0 40]\n",
            "B-PES_AUTOR\t[ 0  0  0  1  0  0  0  0  1  0  1 71  9  0  9  1 19  3  0 18  0 89]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   1   0 298   0  53   0  24  41\n",
            "   0   6   0 108]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  2 74 13  1  4  4  2  2  0 23]\n",
            "B-PES_OUTROS\t[  0   0   0   4   1   1   0   1   2   0   2   2  18   1 531   1 214  77\n",
            "   9 105   0 343]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1  9  1  7 31  0  2  0  1  0 18]\n",
            "B-PES_REU\t[   0    0    0    1    0    0    2    0    0    0    0    3   24    0\n",
            "   77    0 1015   57   15  239    0  230]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   0   0   0   0   6   1  26   0 182 288\n",
            "  35  88   0 119]\n",
            "B-PES_VITIMA\t[  0   0   0   1   0   0   1   0   0   0   0   0   1   0  22   0 158  32\n",
            "  89 113   0  71]\n",
            "B-PROVA\t[  0   0   0   1   0   0   1   0   0   3   0   0   0   0   1   0  10   5\n",
            "   0 430   0 283]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 3 0 5]\n",
            "O\t[     0      4      2     45      1      1     70      4     38      7\n",
            "      9     12     20      7    179      6    132     31     15    213\n",
            "      0 350918]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 12 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1237s - train loss: 2.4821  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.54      0.33      0.41        21\n",
            "          END_DELITO       0.74      0.17      0.28        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.33      0.43      0.37       155\n",
            "      END_TESTEMUNHA       0.36      0.65      0.46        78\n",
            "          END_VITIMA       0.02      0.05      0.02        21\n",
            "       NOR_ACESSORIA       0.57      0.78      0.66      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.74      0.71      0.73       318\n",
            "       NOR_PRINCIPAL       0.68      0.40      0.51      1145\n",
            "                PENA       0.51      0.34      0.41        70\n",
            "           PES_ADVOG       0.69      0.39      0.50       155\n",
            "           PES_AUTOR       0.77      0.29      0.42       222\n",
            "PES_AUTORID_POLICIAL       0.59      0.45      0.51       531\n",
            "            PES_JUIZ       0.72      0.53      0.61       125\n",
            "          PES_OUTROS       0.45      0.36      0.40      1312\n",
            "     PES_PROMOTOR_MP       0.53      0.39      0.45        70\n",
            "             PES_REU       0.55      0.55      0.55      1663\n",
            "      PES_TESTEMUNHA       0.53      0.42      0.47       745\n",
            "          PES_VITIMA       0.63      0.16      0.25       488\n",
            "               PROVA       0.04      0.06      0.05       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.48      0.44      0.46      9218\n",
            "           macro avg       0.48      0.35      0.38      9218\n",
            "        weighted avg       0.52      0.44      0.46      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 83.28 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.73      0.38      0.50        21\n",
            "          END_DELITO       0.84      0.20      0.32        81\n",
            "          END_OUTROS       0.30      0.02      0.04       124\n",
            "             END_REU       0.37      0.53      0.44       155\n",
            "      END_TESTEMUNHA       0.40      0.72      0.51        78\n",
            "          END_VITIMA       0.07      0.33      0.11        21\n",
            "       NOR_ACESSORIA       0.63      0.87      0.73      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.92      0.87      0.89       318\n",
            "       NOR_PRINCIPAL       0.82      0.50      0.62      1145\n",
            "                PENA       0.64      0.46      0.53        70\n",
            "           PES_ADVOG       0.89      0.54      0.67       155\n",
            "           PES_AUTOR       0.83      0.31      0.45       222\n",
            "PES_AUTORID_POLICIAL       0.74      0.57      0.64       531\n",
            "            PES_JUIZ       0.85      0.64      0.73       125\n",
            "          PES_OUTROS       0.53      0.42      0.47      1312\n",
            "     PES_PROMOTOR_MP       0.69      0.53      0.60        70\n",
            "             PES_REU       0.60      0.60      0.60      1663\n",
            "      PES_TESTEMUNHA       0.55      0.46      0.50       745\n",
            "          PES_VITIMA       0.68      0.17      0.27       488\n",
            "               PROVA       0.29      0.64      0.40       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.57      0.55      0.56      9218\n",
            "           macro avg       0.59      0.46      0.48      9218\n",
            "        weighted avg       0.62      0.55      0.56      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[8 0 0 9 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]\n",
            "B-END_DELITO\t[ 0 16  1 32 14  5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  5]\n",
            "B-END_OUTROS\t[ 2  0  3 18 11 38  0  0  0  0  0  0  0  0  1  0  0  0  0  3  0 48]\n",
            "B-END_REU\t[ 1  0  0 82 39 18  0  0  0  0  0  0  1  0  0  0  0  1  0  1  0 12]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0  9 56  4  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  7]\n",
            "B-END_VITIMA\t[0 0 0 7 6 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "B-NOR_ACESSORIA\t[   0    0    0    0    0    0 1002    8   79    0    0    0    0    1\n",
            "    0    0    0    0    0   24    0   37]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   3 277   0   0   0   0   0   0   1   0   0   0\n",
            "   0   7   0  30]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 506   8 574   0   0   0   0   0   1   0   1   0\n",
            "   0  12   0  43]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0 32  0  0  0  0  2  0  0  0  0 28  0  8]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 83  1  0  0 20  5  9  1  1  0  0 35]\n",
            "B-PES_AUTOR\t[ 0  0  0  2  0  0  0  0  1  0  0 69 10  0 17  1 16  3  0  7  0 96]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   1   0   0   0   0   0   0   0   0 302   0  66   0  26  48\n",
            "   0   3   0  85]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  4 80 14  0  4  3  0  1  0 19]\n",
            "B-PES_OUTROS\t[  0   0   0   8   1  15   2   3   2   0   1   1  20   0 553   3 197  78\n",
            "   6 120   0 302]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1 10  2  8 37  0  0  0  1  0 11]\n",
            "B-PES_REU\t[   0    0    0    0    2    3    2    1    0    0    0    1   20    0\n",
            "  103    0 1006   58   11  292    0  164]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   1   0   0   0   0   1   0   4   2  36   0 141 341\n",
            "  12 120   0  87]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   4   1   0   0   0   0   0   1   0  30   0 137  37\n",
            "  84 156   0  38]\n",
            "B-PROVA\t[  0   0   0  14   0   0   1   1   1   3   0   0   0   0   5   0   6   7\n",
            "   0 470   0 226]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 3 0 5]\n",
            "O\t[     0      3      6     37      9     10     81      4     42     15\n",
            "      8     10     37      9    193      8    123     47      9    374\n",
            "      0 329384]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 13 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1266s - train loss: 2.4415  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       1.00      0.14      0.25        21\n",
            "          END_DELITO       0.67      0.17      0.27        81\n",
            "          END_OUTROS       0.05      0.02      0.03       124\n",
            "             END_REU       0.30      0.52      0.38       155\n",
            "      END_TESTEMUNHA       0.57      0.59      0.58        78\n",
            "          END_VITIMA       0.01      0.05      0.02        21\n",
            "       NOR_ACESSORIA       0.54      0.75      0.63      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.71      0.71      0.71       318\n",
            "       NOR_PRINCIPAL       0.70      0.38      0.49      1145\n",
            "                PENA       0.54      0.21      0.31        70\n",
            "           PES_ADVOG       0.66      0.42      0.51       155\n",
            "           PES_AUTOR       0.62      0.27      0.37       222\n",
            "PES_AUTORID_POLICIAL       0.57      0.44      0.49       531\n",
            "            PES_JUIZ       0.61      0.54      0.57       125\n",
            "          PES_OUTROS       0.51      0.33      0.40      1312\n",
            "     PES_PROMOTOR_MP       0.58      0.37      0.45        70\n",
            "             PES_REU       0.56      0.52      0.54      1663\n",
            "      PES_TESTEMUNHA       0.50      0.40      0.44       745\n",
            "          PES_VITIMA       0.54      0.15      0.23       488\n",
            "               PROVA       0.01      0.05      0.02       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.38      0.42      0.40      9218\n",
            "           macro avg       0.49      0.34      0.37      9218\n",
            "        weighted avg       0.52      0.42      0.44      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 58.31 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       1.00      0.14      0.25        21\n",
            "          END_DELITO       0.81      0.21      0.33        81\n",
            "          END_OUTROS       0.33      0.17      0.22       124\n",
            "             END_REU       0.37      0.68      0.48       155\n",
            "      END_TESTEMUNHA       0.63      0.64      0.64        78\n",
            "          END_VITIMA       0.05      0.29      0.09        21\n",
            "       NOR_ACESSORIA       0.62      0.88      0.73      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.87      0.87      0.87       318\n",
            "       NOR_PRINCIPAL       0.85      0.47      0.61      1145\n",
            "                PENA       0.77      0.34      0.48        70\n",
            "           PES_ADVOG       0.85      0.57      0.68       155\n",
            "           PES_AUTOR       0.68      0.29      0.41       222\n",
            "PES_AUTORID_POLICIAL       0.74      0.57      0.64       531\n",
            "            PES_JUIZ       0.77      0.70      0.73       125\n",
            "          PES_OUTROS       0.57      0.38      0.46      1312\n",
            "     PES_PROMOTOR_MP       0.82      0.53      0.64        70\n",
            "             PES_REU       0.61      0.59      0.60      1663\n",
            "      PES_TESTEMUNHA       0.52      0.44      0.48       745\n",
            "          PES_VITIMA       0.56      0.16      0.25       488\n",
            "               PROVA       0.15      0.76      0.25       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.46      0.55      0.50      9218\n",
            "           macro avg       0.60      0.46      0.47      9218\n",
            "        weighted avg       0.61      0.55      0.54      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 3  0  1 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0]\n",
            "B-END_DELITO\t[ 0 17  1 39  0  4  0  0  0  0  0  0  0  0  2  0  0  0  0 16  0  2]\n",
            "B-END_OUTROS\t[ 0  0 21 24  7 31  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0 28]\n",
            "B-END_REU\t[  0   1   1 106  15  17   0   0   0   0   0   0   1   0   3   0   0   0\n",
            "   1   6   0   4]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0 17 50  5  0  0  0  0  0  0  0  0  0  0  0  1  0  4  0  1]\n",
            "B-END_VITIMA\t[0 0 1 4 6 6 0 1 0 0 0 0 0 0 0 0 0 0 0 3 0 0]\n",
            "B-NOR_ACESSORIA\t[   0    0    0    0    0    0 1008    6   59    0    0    0    0    0\n",
            "    0    0    0    0    1   53    0   24]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   2 276   0   0   0   0   0   0   1   0   0   0\n",
            "   0  25   0  14]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 524   4 542   0   0   0   0   0   0   0   2   0\n",
            "   0  52   0  21]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  0 24  0  0  0  0  2  0  0  0  0 39  0  5]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 89  1  0  0 18  0 11  0  1  3  0 32]\n",
            "B-PES_AUTOR\t[ 0  0  0  1  0  0  0  0  1  0  1 65 12  2  8  1 25  3  1 35  0 67]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   2   0   2   0   0   0   0   0   0 303   1  58   0  27  61\n",
            "   1  28   0  48]\n",
            "B-PES_JUIZ\t[ 0  0  0  1  0  0  0  0  0  0  0  0  3 87  6  0  6  5  2  5  0 10]\n",
            "B-PES_OUTROS\t[  0   0   5  16   0  20   6   5   2   0   2   2  24   4 499   1 178  89\n",
            "   8 254   0 197]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  1  0  0  0  0  0  1  7  3 10 37  0  1  0  2  0  8]\n",
            "B-PES_REU\t[  0   0   1   6   0   4   1   0   1   0   0   2  13   0  40   0 973  64\n",
            "  13 448   0  97]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   1   0   2   0   0   0   0   1   1   3   1  23   0 133 330\n",
            "  24 173   0  53]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   3   0   1   0   0   0   0   0   0  15   0 112  35\n",
            "  78 228   0  16]\n",
            "B-PROVA\t[  0   0   2   9   0   4   2   1   1   1   0   0   0   0   0   0   6   7\n",
            "   0 558   0 143]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 5 0 3]\n",
            "O\t[     0      3     31     43      1     13     86     24     35      6\n",
            "     12     23     44     15    185      6    112     41     10   1811\n",
            "      0 220845]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 14 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1251s - train loss: 2.3607  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       1.00      0.19      0.32        21\n",
            "          END_DELITO       0.70      0.20      0.31        81\n",
            "          END_OUTROS       0.00      0.00      0.00       124\n",
            "             END_REU       0.34      0.68      0.45       155\n",
            "      END_TESTEMUNHA       0.60      0.33      0.43        78\n",
            "          END_VITIMA       0.05      0.05      0.05        21\n",
            "       NOR_ACESSORIA       0.40      0.71      0.51      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.71      0.70      0.71       318\n",
            "       NOR_PRINCIPAL       0.69      0.13      0.22      1145\n",
            "                PENA       0.52      0.31      0.39        70\n",
            "           PES_ADVOG       0.68      0.46      0.55       155\n",
            "           PES_AUTOR       0.73      0.27      0.39       222\n",
            "PES_AUTORID_POLICIAL       0.59      0.46      0.52       531\n",
            "            PES_JUIZ       0.71      0.54      0.62       125\n",
            "          PES_OUTROS       0.55      0.34      0.42      1312\n",
            "     PES_PROMOTOR_MP       0.53      0.41      0.46        70\n",
            "             PES_REU       0.55      0.54      0.54      1663\n",
            "      PES_TESTEMUNHA       0.55      0.39      0.45       745\n",
            "          PES_VITIMA       0.55      0.16      0.24       488\n",
            "               PROVA       0.01      0.04      0.02       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.36      0.39      0.37      9218\n",
            "           macro avg       0.50      0.33      0.36      9218\n",
            "        weighted avg       0.51      0.39      0.40      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 55.03 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       1.00      0.19      0.32        21\n",
            "          END_DELITO       0.77      0.21      0.33        81\n",
            "          END_OUTROS       0.48      0.23      0.31       124\n",
            "             END_REU       0.40      0.85      0.54       155\n",
            "      END_TESTEMUNHA       0.71      0.38      0.50        78\n",
            "          END_VITIMA       0.08      0.10      0.09        21\n",
            "       NOR_ACESSORIA       0.50      0.93      0.65      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.88      0.87      0.88       318\n",
            "       NOR_PRINCIPAL       0.88      0.17      0.29      1145\n",
            "                PENA       0.71      0.46      0.56        70\n",
            "           PES_ADVOG       0.85      0.63      0.72       155\n",
            "           PES_AUTOR       0.80      0.30      0.43       222\n",
            "PES_AUTORID_POLICIAL       0.73      0.59      0.65       531\n",
            "            PES_JUIZ       0.81      0.63      0.71       125\n",
            "          PES_OUTROS       0.62      0.39      0.48      1312\n",
            "     PES_PROMOTOR_MP       0.70      0.57      0.63        70\n",
            "             PES_REU       0.59      0.60      0.60      1663\n",
            "      PES_TESTEMUNHA       0.57      0.43      0.49       745\n",
            "          PES_VITIMA       0.58      0.17      0.26       488\n",
            "               PROVA       0.15      0.74      0.25       734\n",
            "            SENTENÇA       0.50      0.11      0.18         9\n",
            "\n",
            "           micro avg       0.44      0.52      0.48      9218\n",
            "           macro avg       0.63      0.45      0.47      9218\n",
            "        weighted avg       0.61      0.52      0.50      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 4  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  2]\n",
            "B-END_DELITO\t[ 0 17  1 43  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0 16  0  3]\n",
            "B-END_OUTROS\t[ 0  0 29 34  6 10  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0 36]\n",
            "B-END_REU\t[  0   1   2 132   2   6   1   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   4   0   7]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0 39 30  2  0  0  0  0  0  0  0  0  0  0  0  1  0  4  0  2]\n",
            "B-END_VITIMA\t[0 0 1 8 4 2 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 2]\n",
            "B-NOR_ACESSORIA\t[   0    0    0    0    0    0 1073    7   11    0    1    0    0    0\n",
            "    0    0    0    0    0   49    0   10]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   1   0   0   6 276   0   0   0   0   0   0   0   0   0   0\n",
            "   0  20   0  15]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 894   3 196   0   0   0   0   0   0   0   0   0\n",
            "   0  38   0  14]\n",
            "B-PENA\t[ 0  0  0  0  0  0  6  0  0 32  0  0  0  0  2  0  0  0  0 26  0  4]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 97  1  2  0  8  4  7  0  1  4  0 31]\n",
            "B-PES_AUTOR\t[ 0  0  0  1  0  0  1  0  1  0  0 66 11  0  8  1 22  2  1 26  1 81]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   1   0   0   1   0   0   0   0   0 311   0  31   1  50  49\n",
            "   1  21   0  65]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  1  0  0  0  1  0  5 79  8  2  5  5  1  5  0 13]\n",
            "B-PES_OUTROS\t[  0   0   9   7   0   3  11   5   1   0   2   0  24   2 507   1 197  80\n",
            "   9 244   0 210]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  2  0  0  0  1  7  2  6 40  0  0  0  1  0 11]\n",
            "B-PES_REU\t[  0   0   0   2   0   0   8   1   0   0   0   0  22   0  49   0 994  37\n",
            "  12 446   0  92]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   0   0   0   0   0   0   0   1   0   4   1  23   0 139 319\n",
            "  20 182   0  56]\n",
            "B-PES_VITIMA\t[  0   0   0   1   0   0   2   0   0   0   0   0   1   0  12   0 122  25\n",
            "  81 228   0  16]\n",
            "B-PROVA\t[  0   0   0   9   0   0   8   1   0   4   0   0   0   0   0   0   6   9\n",
            "   0 545   0 152]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4 1 3]\n",
            "O\t[     0      4     19     38      0      3    154     17     15      9\n",
            "     12     14     38     13    159      8    128     35     14   1790\n",
            "      0 208171]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 15 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1243s - train loss: 2.3038  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.65      0.52      0.58        21\n",
            "          END_DELITO       0.61      0.21      0.31        81\n",
            "          END_OUTROS       0.07      0.02      0.03       124\n",
            "             END_REU       0.31      0.54      0.40       155\n",
            "      END_TESTEMUNHA       0.52      0.62      0.56        78\n",
            "          END_VITIMA       0.01      0.05      0.02        21\n",
            "       NOR_ACESSORIA       0.58      0.76      0.66      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.77      0.73      0.75       318\n",
            "       NOR_PRINCIPAL       0.70      0.47      0.56      1145\n",
            "                PENA       0.49      0.36      0.41        70\n",
            "           PES_ADVOG       0.73      0.50      0.59       155\n",
            "           PES_AUTOR       0.67      0.28      0.39       222\n",
            "PES_AUTORID_POLICIAL       0.66      0.47      0.55       531\n",
            "            PES_JUIZ       0.68      0.56      0.61       125\n",
            "          PES_OUTROS       0.48      0.36      0.41      1312\n",
            "     PES_PROMOTOR_MP       0.51      0.40      0.45        70\n",
            "             PES_REU       0.55      0.55      0.55      1663\n",
            "      PES_TESTEMUNHA       0.62      0.34      0.44       745\n",
            "          PES_VITIMA       0.55      0.16      0.25       488\n",
            "               PROVA       0.02      0.06      0.03       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.43      0.44      0.44      9218\n",
            "           macro avg       0.48      0.38      0.41      9218\n",
            "        weighted avg       0.54      0.44      0.47      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 65.84 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.92      0.57      0.71        21\n",
            "          END_DELITO       0.72      0.26      0.38        81\n",
            "          END_OUTROS       0.44      0.13      0.20       124\n",
            "             END_REU       0.37      0.69      0.48       155\n",
            "      END_TESTEMUNHA       0.58      0.67      0.62        78\n",
            "          END_VITIMA       0.06      0.29      0.10        21\n",
            "       NOR_ACESSORIA       0.66      0.88      0.75      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.91      0.86      0.88       318\n",
            "       NOR_PRINCIPAL       0.84      0.60      0.70      1145\n",
            "                PENA       0.68      0.54      0.60        70\n",
            "           PES_ADVOG       0.87      0.63      0.73       155\n",
            "           PES_AUTOR       0.74      0.32      0.44       222\n",
            "PES_AUTORID_POLICIAL       0.80      0.57      0.67       531\n",
            "            PES_JUIZ       0.80      0.67      0.73       125\n",
            "          PES_OUTROS       0.57      0.43      0.49      1312\n",
            "     PES_PROMOTOR_MP       0.75      0.60      0.67        70\n",
            "             PES_REU       0.60      0.61      0.60      1663\n",
            "      PES_TESTEMUNHA       0.66      0.38      0.48       745\n",
            "          PES_VITIMA       0.56      0.17      0.26       488\n",
            "               PROVA       0.17      0.72      0.28       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.51      0.57      0.54      9218\n",
            "           macro avg       0.61      0.50      0.51      9218\n",
            "        weighted avg       0.63      0.57      0.57      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[12  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2]\n",
            "B-END_DELITO\t[ 0 21  1 38  0  4  0  0  1  0  0  0  0  0  1  0  0  0  0 11  0  4]\n",
            "B-END_OUTROS\t[ 0  1 16 32  8 26  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0 38]\n",
            "B-END_REU\t[  1   2   0 107  18  18   0   0   0   0   0   0   1   0   2   0   0   0\n",
            "   1   2   0   3]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0 16 52  5  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  3]\n",
            "B-END_VITIMA\t[0 0 1 9 4 6 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "B-NOR_ACESSORIA\t[   0    0    0    0    0    0 1010    6   75    0    0    0    0    1\n",
            "    0    0    0    0    0   41    0   18]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   1   0   0   3 272   0   0   0   0   0   0   1   0   0   0\n",
            "   0  13   0  28]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 402   3 684   0   0   0   0   0   0   0   1   0\n",
            "   0  34   0  21]\n",
            "B-PENA\t[ 0  0  0  0  0  0  0  0  1 38  0  0  0  0  2  0  0  0  0 23  0  6]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  1  0  0  0  0 97  1  1  0 10  0  8  0  0  3  0 34]\n",
            "B-PES_AUTOR\t[ 0  0  0  1  1  1  0  0  1  0  0 70 12  0  9  1 20  1  2 21  0 82]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   1   0   1   0   0   0   0   0   0 304   0  70   0  32  22\n",
            "   2  14   0  85]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  1  0  0  0  0  0  1 84 15  1  3  2  1  3  0 14]\n",
            "B-PES_OUTROS\t[  0   2   5  11   0  15   6   3   4   0   1   0  13   2 562   3 184  47\n",
            "   9 186   0 259]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1  5  2 10 42  0  0  0  2  0  8]\n",
            "B-PES_REU\t[   0    0    0    3    1    3    2    0    2    0    0    4    8    0\n",
            "   72    1 1010   25   18  405    0  109]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   1   0   1   0   0   0   0   1   0   3   2  32   1 177 280\n",
            "  20 166   0  61]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   4   0   0   0   0   0   0   0   0  19   0 135  19\n",
            "  83 209   0  19]\n",
            "B-PROVA\t[  0   0   0  10   0   4   2   1   2   3   0   0   0   0   1   0   7   6\n",
            "   0 528   0 170]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4 0 4]\n",
            "O\t[     0      3     13     51      5     16    100     14     40     15\n",
            "     12     18     33     14    186      7    114     23     11   1354\n",
            "      0 252536]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 16 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1256s - train loss: 2.2417  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.69      0.43      0.53        21\n",
            "          END_DELITO       0.61      0.17      0.27        81\n",
            "          END_OUTROS       0.02      0.01      0.01       124\n",
            "             END_REU       0.30      0.66      0.42       155\n",
            "      END_TESTEMUNHA       0.59      0.38      0.47        78\n",
            "          END_VITIMA       0.04      0.05      0.04        21\n",
            "       NOR_ACESSORIA       0.56      0.74      0.64      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.77      0.75      0.76       318\n",
            "       NOR_PRINCIPAL       0.73      0.50      0.59      1145\n",
            "                PENA       0.45      0.36      0.40        70\n",
            "           PES_ADVOG       0.71      0.48      0.57       155\n",
            "           PES_AUTOR       0.66      0.28      0.40       222\n",
            "PES_AUTORID_POLICIAL       0.60      0.44      0.50       531\n",
            "            PES_JUIZ       0.57      0.57      0.57       125\n",
            "          PES_OUTROS       0.49      0.35      0.41      1312\n",
            "     PES_PROMOTOR_MP       0.50      0.43      0.46        70\n",
            "             PES_REU       0.51      0.58      0.54      1663\n",
            "      PES_TESTEMUNHA       0.61      0.31      0.41       745\n",
            "          PES_VITIMA       0.52      0.18      0.27       488\n",
            "               PROVA       0.02      0.06      0.03       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.42      0.44      0.43      9218\n",
            "           macro avg       0.47      0.37      0.39      9218\n",
            "        weighted avg       0.52      0.44      0.46      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 62.90 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.75      0.43      0.55        21\n",
            "          END_DELITO       0.64      0.20      0.30        81\n",
            "          END_OUTROS       0.39      0.21      0.27       124\n",
            "             END_REU       0.36      0.87      0.51       155\n",
            "      END_TESTEMUNHA       0.71      0.45      0.55        78\n",
            "          END_VITIMA       0.07      0.10      0.08        21\n",
            "       NOR_ACESSORIA       0.65      0.88      0.75      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.93      0.89      0.91       318\n",
            "       NOR_PRINCIPAL       0.84      0.59      0.70      1145\n",
            "                PENA       0.69      0.60      0.64        70\n",
            "           PES_ADVOG       0.88      0.63      0.74       155\n",
            "           PES_AUTOR       0.72      0.31      0.43       222\n",
            "PES_AUTORID_POLICIAL       0.78      0.57      0.66       531\n",
            "            PES_JUIZ       0.73      0.74      0.74       125\n",
            "          PES_OUTROS       0.58      0.42      0.49      1312\n",
            "     PES_PROMOTOR_MP       0.74      0.64      0.69        70\n",
            "             PES_REU       0.56      0.64      0.60      1663\n",
            "      PES_TESTEMUNHA       0.65      0.33      0.44       745\n",
            "          PES_VITIMA       0.57      0.20      0.29       488\n",
            "               PROVA       0.17      0.73      0.27       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.50      0.58      0.54      9218\n",
            "           macro avg       0.59      0.50      0.50      9218\n",
            "        weighted avg       0.62      0.58      0.56      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 9  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2]\n",
            "B-END_DELITO\t[ 0 16  1 50  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  4]\n",
            "B-END_OUTROS\t[ 2  0 26 40  3  9  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0 36]\n",
            "B-END_REU\t[  1   2   2 135   5   3   1   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   3   0   3]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0 37 35  2  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  1]\n",
            "B-END_VITIMA\t[0 0 1 9 4 2 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 2]\n",
            "B-NOR_ACESSORIA\t[   0    0    1    0    0    0 1015    3   75    0    0    0    0    1\n",
            "    0    0    0    0    0   39    0   17]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   2 282   0   0   0   0   0   0   0   0   0   0\n",
            "   1  11   0  22]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 417   4 677   0   0   0   0   0   1   0   0   0\n",
            "   0  27   0  19]\n",
            "B-PENA\t[ 0  0  0  0  0  0  1  0  1 42  0  0  0  0  2  0  0  0  0 17  0  7]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 98  1  1  0  9  0 11  0  1  1  0 33]\n",
            "B-PES_AUTOR\t[ 0  0  0  1  0  0  0  0  1  0  0 68 12  2  8  1 22  1  3 22  0 81]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   2   0   0   0   0   0   0   0   0 304   1  55   2  56  17\n",
            "   1  19   0  74]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  1 93 12  1  6  0  0  2  0 10]\n",
            "B-PES_OUTROS\t[  0   4  13  12   0   3   7   3   3   0   1   0  16   4 555   2 223  43\n",
            "   8 187   0 228]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1  2  5  7 45  0  0  0  1  0  9]\n",
            "B-PES_REU\t[   0    0    0    2    0    0    2    0    1    0    0    0   12    0\n",
            "   62    1 1062   26   16  396    0   83]\n",
            "B-PES_TESTEMUNHA\t[  0   1   0   1   0   0   0   0   0   0   1   1   3   2  25   1 218 248\n",
            "  27 162   0  55]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   1   0   0   0   0   0   0   2   0  14   0 128  16\n",
            "  96 214   0  17]\n",
            "B-PROVA\t[  0   0   0  15   0   0   6   0   1   3   0   0   0   0   0   0   6   7\n",
            "   1 536   0 159]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 5 0 3]\n",
            "O\t[     0      2     23     56      2      6    114     11     43     16\n",
            "     11     24     36     19    214      8    162     22     14   1523\n",
            "      0 239276]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 17 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1255s - train loss: 2.1906  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.50      0.57      0.53        21\n",
            "          END_DELITO       0.60      0.37      0.46        81\n",
            "          END_OUTROS       0.05      0.04      0.05       124\n",
            "             END_REU       0.31      0.47      0.37       155\n",
            "      END_TESTEMUNHA       0.46      0.63      0.53        78\n",
            "          END_VITIMA       0.04      0.05      0.04        21\n",
            "       NOR_ACESSORIA       0.54      0.74      0.62      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.73      0.74      0.73       318\n",
            "       NOR_PRINCIPAL       0.70      0.43      0.53      1145\n",
            "                PENA       0.40      0.36      0.38        70\n",
            "           PES_ADVOG       0.66      0.50      0.57       155\n",
            "           PES_AUTOR       0.60      0.29      0.39       222\n",
            "PES_AUTORID_POLICIAL       0.57      0.43      0.49       531\n",
            "            PES_JUIZ       0.64      0.55      0.59       125\n",
            "          PES_OUTROS       0.42      0.37      0.39      1312\n",
            "     PES_PROMOTOR_MP       0.46      0.40      0.43        70\n",
            "             PES_REU       0.53      0.57      0.55      1663\n",
            "      PES_TESTEMUNHA       0.63      0.36      0.46       745\n",
            "          PES_VITIMA       0.56      0.17      0.26       488\n",
            "               PROVA       0.02      0.07      0.03       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.40      0.44      0.42      9218\n",
            "           macro avg       0.45      0.39      0.40      9218\n",
            "        weighted avg       0.51      0.44      0.45      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 62.04 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.57      0.57      0.57        21\n",
            "          END_DELITO       0.73      0.46      0.56        81\n",
            "          END_OUTROS       0.36      0.29      0.32       124\n",
            "             END_REU       0.40      0.69      0.51       155\n",
            "      END_TESTEMUNHA       0.52      0.69      0.60        78\n",
            "          END_VITIMA       0.04      0.05      0.04        21\n",
            "       NOR_ACESSORIA       0.63      0.89      0.74      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.88      0.89      0.89       318\n",
            "       NOR_PRINCIPAL       0.85      0.54      0.66      1145\n",
            "                PENA       0.68      0.66      0.67        70\n",
            "           PES_ADVOG       0.82      0.67      0.74       155\n",
            "           PES_AUTOR       0.66      0.32      0.43       222\n",
            "PES_AUTORID_POLICIAL       0.76      0.58      0.66       531\n",
            "            PES_JUIZ       0.79      0.70      0.74       125\n",
            "          PES_OUTROS       0.51      0.46      0.49      1312\n",
            "     PES_PROMOTOR_MP       0.73      0.64      0.68        70\n",
            "             PES_REU       0.57      0.63      0.60      1663\n",
            "      PES_TESTEMUNHA       0.65      0.40      0.49       745\n",
            "          PES_VITIMA       0.61      0.18      0.28       488\n",
            "               PROVA       0.17      0.73      0.27       734\n",
            "            SENTENÇA       0.33      0.11      0.17         9\n",
            "\n",
            "           micro avg       0.49      0.59      0.54      9218\n",
            "           macro avg       0.58      0.53      0.53      9218\n",
            "        weighted avg       0.61      0.59      0.56      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[12  0  1  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
            "B-END_DELITO\t[ 0 37  2 30  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  2]\n",
            "B-END_OUTROS\t[ 3  1 36 25 10 11  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0 31]\n",
            "B-END_REU\t[  3   3   6 107  26   4   0   0   0   0   0   0   0   0   0   0   1   1\n",
            "   0   2   0   2]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0 16 54  4  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  3]\n",
            "B-END_VITIMA\t[0 0 1 9 6 1 0 0 0 0 0 0 0 0 3 0 0 0 0 1 0 0]\n",
            "B-NOR_ACESSORIA\t[   0    0    1    0    0    0 1027    6   59    0    1    0    0    0\n",
            "    0    0    0    0    0   42    0   15]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   1   1   0   2 283   0   0   0   0   0   0   1   0   0   0\n",
            "   0  12   0  18]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 477   5 615   0   0   0   0   0   0   0   1   0\n",
            "   0  29   0  18]\n",
            "B-PENA\t[ 0  0  0  0  0  0  1  0  1 46  0  0  0  0  2  0  0  0  0 12  0  8]\n",
            "B-PES_ADVOG\t[  0   0   0   0   0   0   0   0   0   0 104   1   2   0  15   0   9   0\n",
            "   0   1   0  23]\n",
            "B-PES_AUTOR\t[ 0  0  0  1  0  0  0  0  1  0  0 71 12  2 20  1 21  1  1 16  1 74]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   2   0   0   0   0   0   0   0   0 309   0  97   3  37  17\n",
            "   2  10   0  54]\n",
            "B-PES_JUIZ\t[ 0  0  0  1  0  0  0  0  0  0  1  0  1 87 15  2  5  0  0  2  0 11]\n",
            "B-PES_OUTROS\t[  1   2  10  12   0   1   6   4   2   0   1   3  21   2 607   2 206  60\n",
            "  12 159   0 201]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  2  0  0  0  1  2  2  8 45  0  0  0  2  0  8]\n",
            "B-PES_REU\t[   0    0    0    1    1    0    2    0    0    0    0    3   11    1\n",
            "   89    1 1048   30   15  383    0   78]\n",
            "B-PES_TESTEMUNHA\t[  0   1   0   1   0   0   0   0   0   0   1   1   3   2  36   1 182 296\n",
            "  19 148   0  54]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   1   0   0   2   0  19   0 143  18\n",
            "  89 197   0  19]\n",
            "B-PROVA\t[  0   0   0  12   0   3   2   1   0   3   0   0   0   0   2   0   8   7\n",
            "   0 534   0 162]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4 1 3]\n",
            "O\t[     2      7     43     43      4      3    117     19     45     18\n",
            "     19     27     45     14    268      7    162     26      9   1620\n",
            "      1 235059]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 18 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1226s - train loss: 2.1488  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       1.00      0.10      0.17        21\n",
            "          END_DELITO       0.58      0.14      0.22        81\n",
            "          END_OUTROS       0.02      0.01      0.01       124\n",
            "             END_REU       0.27      0.62      0.37       155\n",
            "      END_TESTEMUNHA       0.61      0.46      0.53        78\n",
            "          END_VITIMA       0.07      0.05      0.06        21\n",
            "       NOR_ACESSORIA       0.52      0.73      0.61      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.66      0.74      0.70       318\n",
            "       NOR_PRINCIPAL       0.74      0.45      0.56      1145\n",
            "                PENA       0.46      0.37      0.41        70\n",
            "           PES_ADVOG       0.71      0.51      0.59       155\n",
            "           PES_AUTOR       0.60      0.29      0.39       222\n",
            "PES_AUTORID_POLICIAL       0.68      0.47      0.56       531\n",
            "            PES_JUIZ       0.71      0.54      0.61       125\n",
            "          PES_OUTROS       0.47      0.36      0.41      1312\n",
            "     PES_PROMOTOR_MP       0.51      0.40      0.45        70\n",
            "             PES_REU       0.50      0.58      0.53      1663\n",
            "      PES_TESTEMUNHA       0.65      0.38      0.48       745\n",
            "          PES_VITIMA       0.67      0.17      0.27       488\n",
            "               PROVA       0.02      0.06      0.03       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.41      0.44      0.43      9218\n",
            "           macro avg       0.50      0.35      0.38      9218\n",
            "        weighted avg       0.53      0.44      0.46      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 63.30 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       1.00      0.10      0.17        21\n",
            "          END_DELITO       0.65      0.16      0.26        81\n",
            "          END_OUTROS       0.46      0.19      0.26       124\n",
            "             END_REU       0.35      0.88      0.50       155\n",
            "      END_TESTEMUNHA       0.69      0.51      0.59        78\n",
            "          END_VITIMA       0.13      0.10      0.11        21\n",
            "       NOR_ACESSORIA       0.62      0.91      0.73      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.82      0.91      0.86       318\n",
            "       NOR_PRINCIPAL       0.87      0.54      0.66      1145\n",
            "                PENA       0.60      0.50      0.55        70\n",
            "           PES_ADVOG       0.86      0.65      0.74       155\n",
            "           PES_AUTOR       0.68      0.33      0.45       222\n",
            "PES_AUTORID_POLICIAL       0.82      0.58      0.68       531\n",
            "            PES_JUIZ       0.85      0.66      0.74       125\n",
            "          PES_OUTROS       0.55      0.43      0.48      1312\n",
            "     PES_PROMOTOR_MP       0.77      0.61      0.68        70\n",
            "             PES_REU       0.53      0.63      0.58      1663\n",
            "      PES_TESTEMUNHA       0.66      0.41      0.51       745\n",
            "          PES_VITIMA       0.71      0.18      0.29       488\n",
            "               PROVA       0.17      0.76      0.28       734\n",
            "            SENTENÇA       0.50      0.11      0.18         9\n",
            "\n",
            "           micro avg       0.49      0.58      0.53      9218\n",
            "           macro avg       0.63      0.48      0.49      9218\n",
            "        weighted avg       0.62      0.58      0.56      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 2  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  1]\n",
            "B-END_DELITO\t[ 0 13  1 54  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  3]\n",
            "B-END_OUTROS\t[ 0  0 23 43  7  4  0  1  0  0  0  0  0  0  0  0  0  0  0 17  0 29]\n",
            "B-END_REU\t[  0   1   2 137   6   2   1   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   4   0   2]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0 30 40  4  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  1]\n",
            "B-END_VITIMA\t[ 0  0  1 10  4  2  0  0  0  0  0  0  0  0  2  0  0  0  0  2  0  0]\n",
            "B-NOR_ACESSORIA\t[   0    0    0    0    0    0 1042    9   54    0    0    0    0    0\n",
            "    0    0    0    0    0   37    0    9]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   0   0   0   3 290   0   0   0   0   0   0   0   0   0   0\n",
            "   0  13   0  12]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 481   5 614   0   0   0   0   0   0   0   1   0\n",
            "   0  30   0  14]\n",
            "B-PENA\t[ 0  0  0  0  0  0  3  0  1 35  0  0  0  0  2  0  0  0  0 24  0  5]\n",
            "B-PES_ADVOG\t[  0   0   0   0   0   0   0   0   0   0 100   1   0   0  17   0  13   0\n",
            "   0   2   0  22]\n",
            "B-PES_AUTOR\t[ 0  0  0  1  0  0  0  1  1  0  0 74 11  1 10  1 20  1  1 31  1 68]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   1   0   0   0   0   0   0   0   0 307   0  74   0  47  22\n",
            "   1  29   0  50]\n",
            "B-PES_JUIZ\t[ 0  0  0  1  0  0  1  3  0  0  0  0  1 82 11  3  7  0  1  4  0 11]\n",
            "B-PES_OUTROS\t[  0   4   7  16   0   1   8  10   1   0   1   2  11   2 558   2 194  56\n",
            "   7 242   0 190]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  2  0  0  0  1  4  1  8 43  0  0  0  3  0  8]\n",
            "B-PES_REU\t[   0    0    0    8    0    0    2    1    0    0    0    0    6    0\n",
            "   69    1 1046   25    8  434    0   63]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   1   0   0   0   0   0   0   1   0   2   1  28   1 184 304\n",
            "   9 173   0  41]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   0   0   0   0   0   0   0   2   0  17   0 126  19\n",
            "  87 222   0  15]\n",
            "B-PROVA\t[  0   0   0  15   0   0   5   2   0   3   0   0   0   0   0   0   5   6\n",
            "   0 560   0 138]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4 1 3]\n",
            "O\t[     0      2     16     61      1      2    141     29     38     20\n",
            "     14     31     31      9    216      5    314     25      8   1427\n",
            "      0 241061]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 19 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1247s - train loss: 2.1044  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.80      0.57      0.67        21\n",
            "          END_DELITO       0.50      0.17      0.26        81\n",
            "          END_OUTROS       0.08      0.03      0.05       124\n",
            "             END_REU       0.31      0.69      0.42       155\n",
            "      END_TESTEMUNHA       0.66      0.47      0.55        78\n",
            "          END_VITIMA       0.04      0.05      0.04        21\n",
            "       NOR_ACESSORIA       0.53      0.74      0.61      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.80      0.75      0.77       318\n",
            "       NOR_PRINCIPAL       0.74      0.45      0.56      1145\n",
            "                PENA       0.46      0.37      0.41        70\n",
            "           PES_ADVOG       0.73      0.51      0.60       155\n",
            "           PES_AUTOR       0.60      0.30      0.40       222\n",
            "PES_AUTORID_POLICIAL       0.69      0.47      0.56       531\n",
            "            PES_JUIZ       0.73      0.55      0.63       125\n",
            "          PES_OUTROS       0.44      0.38      0.41      1312\n",
            "     PES_PROMOTOR_MP       0.46      0.49      0.47        70\n",
            "             PES_REU       0.58      0.57      0.57      1663\n",
            "      PES_TESTEMUNHA       0.62      0.41      0.50       745\n",
            "          PES_VITIMA       0.61      0.19      0.29       488\n",
            "               PROVA       0.03      0.07      0.04       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.46      0.46      0.46      9218\n",
            "           macro avg       0.50      0.39      0.42      9218\n",
            "        weighted avg       0.54      0.46      0.48      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 71.56 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.86      0.57      0.69        21\n",
            "          END_DELITO       0.62      0.22      0.33        81\n",
            "          END_OUTROS       0.34      0.18      0.23       124\n",
            "             END_REU       0.36      0.88      0.51       155\n",
            "      END_TESTEMUNHA       0.76      0.53      0.62        78\n",
            "          END_VITIMA       0.16      0.19      0.17        21\n",
            "       NOR_ACESSORIA       0.63      0.91      0.74      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.95      0.88      0.91       318\n",
            "       NOR_PRINCIPAL       0.86      0.55      0.67      1145\n",
            "                PENA       0.64      0.53      0.58        70\n",
            "           PES_ADVOG       0.86      0.63      0.73       155\n",
            "           PES_AUTOR       0.67      0.33      0.44       222\n",
            "PES_AUTORID_POLICIAL       0.84      0.57      0.68       531\n",
            "            PES_JUIZ       0.87      0.66      0.75       125\n",
            "          PES_OUTROS       0.53      0.47      0.50      1312\n",
            "     PES_PROMOTOR_MP       0.64      0.67      0.65        70\n",
            "             PES_REU       0.62      0.61      0.61      1663\n",
            "      PES_TESTEMUNHA       0.66      0.45      0.53       745\n",
            "          PES_VITIMA       0.65      0.20      0.31       488\n",
            "               PROVA       0.21      0.70      0.33       734\n",
            "            SENTENÇA       0.50      0.11      0.18         9\n",
            "\n",
            "           micro avg       0.54      0.59      0.56      9218\n",
            "           macro avg       0.63      0.52      0.53      9218\n",
            "        weighted avg       0.63      0.59      0.58      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[12  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2]\n",
            "B-END_DELITO\t[ 0 18  1 51  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  4]\n",
            "B-END_OUTROS\t[ 0  1 22 45  4  9  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0 39]\n",
            "B-END_REU\t[  1   3   2 137   4   4   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   2   0   2]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0 30 41  3  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  3]\n",
            "B-END_VITIMA\t[ 0  0  1 11  4  4  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
            "B-NOR_ACESSORIA\t[   0    0    0    1    0    0 1053    3   51    0    1    0    0    0\n",
            "    0    0    0    0    0   25    0   17]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   4   0   0   3 279   0   0   0   0   0   0   1   0   0   0\n",
            "   0   5   0  26]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 476   3 625   0   0   0   0   0   0   0   1   0\n",
            "   0  19   0  21]\n",
            "B-PENA\t[ 0  0  0  0  0  0  3  0  1 37  0  0  0  0  2  0  0  0  0 20  0  7]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 98  1  0  0 10  0  7  0  0  1  0 38]\n",
            "B-PES_AUTOR\t[ 0  0  0  2  0  1  0  0  1  0  0 73 11  2 14  1 18  1  1 18  1 78]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   2   0   0   0   0   0   0   0   0 303   0  86   4  22  23\n",
            "   3   8   0  80]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  1  0  1 83 14  5  4  2  0  3  0 12]\n",
            "B-PES_OUTROS\t[  0   2  10  10   0   1   7   1   3   0   2   4  10   1 617   3 169  53\n",
            "  11 154   0 254]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1  2  0 10 47  0  0  0  1  0  9]\n",
            "B-PES_REU\t[   0    0    0    2    0    0    2    0    1    0    0    7    6    0\n",
            "  118    1 1016   31   16  352    0  111]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   2   0   0   1   0   0   0   0   1   3   0  46   0 141 332\n",
            "  14 143   0  62]\n",
            "B-PES_VITIMA\t[  0   0   0   0   0   1   0   0   0   1   0   0   0   0  24   0 122  27\n",
            " 100 193   0  20]\n",
            "B-PROVA\t[  0   0   0  17   0   0   6   0   2   1   0   0   0   0   2   0   6   7\n",
            "   0 517   0 176]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 3 1 4]\n",
            "O\t[     1      5     28     64      1      2    126      8     40     19\n",
            "     12     22     26      9    226     13    135     30     10    961\n",
            "      0 276394]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n",
            "INFO:logger:Epoch 20 out of 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2291/2291 [==============================] - 1272s - train loss: 2.0743  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.90      0.43      0.58        21\n",
            "          END_DELITO       0.69      0.25      0.36        81\n",
            "          END_OUTROS       0.07      0.01      0.01       124\n",
            "             END_REU       0.27      0.66      0.38       155\n",
            "      END_TESTEMUNHA       0.68      0.32      0.43        78\n",
            "          END_VITIMA       0.09      0.05      0.06        21\n",
            "       NOR_ACESSORIA       0.60      0.77      0.68      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.74      0.77      0.75       318\n",
            "       NOR_PRINCIPAL       0.79      0.56      0.65      1145\n",
            "                PENA       0.39      0.39      0.39        70\n",
            "           PES_ADVOG       0.74      0.47      0.57       155\n",
            "           PES_AUTOR       0.69      0.30      0.42       222\n",
            "PES_AUTORID_POLICIAL       0.74      0.48      0.58       531\n",
            "            PES_JUIZ       0.66      0.58      0.62       125\n",
            "          PES_OUTROS       0.46      0.38      0.42      1312\n",
            "     PES_PROMOTOR_MP       0.50      0.50      0.50        70\n",
            "             PES_REU       0.55      0.60      0.57      1663\n",
            "      PES_TESTEMUNHA       0.63      0.42      0.50       745\n",
            "          PES_VITIMA       0.53      0.21      0.30       488\n",
            "               PROVA       0.05      0.09      0.07       734\n",
            "            SENTENÇA       0.00      0.00      0.00         9\n",
            "\n",
            "           micro avg       0.51      0.48      0.50      9218\n",
            "           macro avg       0.51      0.39      0.42      9218\n",
            "        weighted avg       0.55      0.48      0.50      9218\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 80.94 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       1.00      0.43      0.60        21\n",
            "          END_DELITO       0.76      0.27      0.40        81\n",
            "          END_OUTROS       0.42      0.04      0.07       124\n",
            "             END_REU       0.34      0.93      0.50       155\n",
            "      END_TESTEMUNHA       0.81      0.37      0.51        78\n",
            "          END_VITIMA       0.09      0.05      0.06        21\n",
            "       NOR_ACESSORIA       0.68      0.89      0.77      1151\n",
            "  NOR_JURISPRUDÊNCIA       0.89      0.91      0.90       318\n",
            "       NOR_PRINCIPAL       0.87      0.62      0.72      1145\n",
            "                PENA       0.55      0.60      0.58        70\n",
            "           PES_ADVOG       0.91      0.62      0.74       155\n",
            "           PES_AUTOR       0.73      0.32      0.45       222\n",
            "PES_AUTORID_POLICIAL       0.87      0.56      0.68       531\n",
            "            PES_JUIZ       0.81      0.72      0.76       125\n",
            "          PES_OUTROS       0.55      0.47      0.51      1312\n",
            "     PES_PROMOTOR_MP       0.70      0.70      0.70        70\n",
            "             PES_REU       0.59      0.65      0.62      1663\n",
            "      PES_TESTEMUNHA       0.66      0.46      0.54       745\n",
            "          PES_VITIMA       0.56      0.23      0.32       488\n",
            "               PROVA       0.28      0.67      0.40       734\n",
            "            SENTENÇA       0.50      0.11      0.18         9\n",
            "\n",
            "           micro avg       0.59      0.60      0.59      9218\n",
            "           macro avg       0.65      0.51      0.52      9218\n",
            "        weighted avg       0.65      0.60      0.59      9218\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 9  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2]\n",
            "B-END_DELITO\t[ 0 22  1 50  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  5]\n",
            "B-END_OUTROS\t[ 0  0  5 56  1  4  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0 52]\n",
            "B-END_REU\t[  0   3   1 144   2   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   1   0   3]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0 42 29  3  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  3]\n",
            "B-END_VITIMA\t[ 0  0  1 11  4  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  3]\n",
            "B-NOR_ACESSORIA\t[   0    0    0    2    0    0 1022    6   67    0    0    0    0    1\n",
            "    0    0    0    0    0   19    0   34]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   1   0   0   1 289   0   0   0   0   0   0   1   0   0   0\n",
            "   0   3   0  23]\n",
            "B-NOR_PRINCIPAL\t[  0   0   0   0   0   0 390   5 708   0   0   0   0   0   0   0   1   0\n",
            "   0  11   0  30]\n",
            "B-PENA\t[ 0  0  0  0  0  0  1  0  1 42  0  0  0  0  2  0  0  0  0 18  0  6]\n",
            "B-PES_ADVOG\t[ 0  0  0  0  0  0  0  0  0  0 96  1  0  0 15  0  8  0  1  0  0 34]\n",
            "B-PES_AUTOR\t[ 0  0  0  2  0  0  0  0  1  0  0 71 12  2 13  1 20  1  1  5  1 92]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0 299   1  82   2  31  24\n",
            "   3   5   0  84]\n",
            "B-PES_JUIZ\t[ 0  0  0  0  0  0  0  0  0  0  0  0  1 90 10  3  5  2  0  2  0 12]\n",
            "B-PES_OUTROS\t[  0   0   0  13   0   1   4   3   2   0   1   3   6   2 614   3 206  56\n",
            "  14 119   0 265]\n",
            "B-PES_PROMOTOR_MP\t[ 0  0  0  0  0  0  0  0  0  0  0  1  1  2  6 49  0  1  0  1  0  9]\n",
            "B-PES_REU\t[   0    0    0    5    0    0    1    0    0    0    0    5    6    0\n",
            "   99    1 1083   31   26  294    0  112]\n",
            "B-PES_TESTEMUNHA\t[  0   1   0   1   0   0   0   0   0   0   0   0   2   1  35   0 152 343\n",
            "  22 116   0  72]\n",
            "B-PES_VITIMA\t[  0   0   0   1   0   0   0   0   0   2   0   0   1   0  20   0 146  25\n",
            " 110 155   0  28]\n",
            "B-PROVA\t[  0   0   0  11   0   0   1   2   0   4   0   0   0   0   2   0   8   7\n",
            "   0 489   0 210]\n",
            "B-SENTENÇA\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 1 5]\n",
            "O\t[     0      3      4     72      0      1     80     18     39     28\n",
            "      8     16     17     12    213     11    167     28     20    486\n",
            "      0 317433]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:- new best score!\n"
          ]
        }
      ],
      "source": [
        "model.train(train, dev, score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTC9kGhbrPNh",
        "outputId": "649c88f1-1a4c-4fc5-ac95-520a2c8b0e84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:Testing model over test set: \n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.47      0.23      0.31        40\n",
            "          END_DELITO       0.57      0.21      0.30       156\n",
            "          END_OUTROS       0.09      0.02      0.03       153\n",
            "             END_REU       0.23      0.61      0.33       283\n",
            "      END_TESTEMUNHA       0.65      0.34      0.45       120\n",
            "          END_VITIMA       0.19      0.07      0.11        69\n",
            "       NOR_ACESSORIA       0.59      0.79      0.68      2365\n",
            "  NOR_JURISPRUDÊNCIA       0.71      0.76      0.74       753\n",
            "       NOR_PRINCIPAL       0.74      0.51      0.60      2747\n",
            "                PENA       0.54      0.45      0.49       139\n",
            "           PES_ADVOG       0.52      0.23      0.32       228\n",
            "           PES_AUTOR       0.74      0.33      0.45       481\n",
            "PES_AUTORID_POLICIAL       0.80      0.73      0.76       822\n",
            "            PES_JUIZ       0.66      0.57      0.61       183\n",
            "          PES_OUTROS       0.55      0.40      0.46      2652\n",
            "     PES_PROMOTOR_MP       0.49      0.44      0.46       158\n",
            "             PES_REU       0.61      0.63      0.62      3522\n",
            "      PES_TESTEMUNHA       0.69      0.55      0.62      1140\n",
            "          PES_VITIMA       0.52      0.27      0.36       781\n",
            "               PROVA       0.04      0.08      0.05      1132\n",
            "            SENTENÇA       0.00      0.00      0.00        29\n",
            "\n",
            "           micro avg       0.54      0.52      0.53     17953\n",
            "           macro avg       0.50      0.39      0.42     17953\n",
            "        weighted avg       0.59      0.52      0.54     17953\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:logger:acc 83.93 - f1 0.00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report Level Entity:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "           END_AUTOR       0.53      0.23      0.32        40\n",
            "          END_DELITO       0.86      0.31      0.45       156\n",
            "          END_OUTROS       0.12      0.03      0.04       153\n",
            "             END_REU       0.32      0.89      0.47       283\n",
            "      END_TESTEMUNHA       0.66      0.34      0.45       120\n",
            "          END_VITIMA       0.29      0.14      0.19        69\n",
            "       NOR_ACESSORIA       0.67      0.90      0.77      2365\n",
            "  NOR_JURISPRUDÊNCIA       0.86      0.92      0.89       753\n",
            "       NOR_PRINCIPAL       0.91      0.63      0.75      2747\n",
            "                PENA       0.68      0.60      0.64       139\n",
            "           PES_ADVOG       0.77      0.35      0.48       228\n",
            "           PES_AUTOR       0.79      0.35      0.49       481\n",
            "PES_AUTORID_POLICIAL       0.90      0.82      0.86       822\n",
            "            PES_JUIZ       0.74      0.64      0.69       183\n",
            "          PES_OUTROS       0.65      0.48      0.55      2652\n",
            "     PES_PROMOTOR_MP       0.80      0.77      0.79       158\n",
            "             PES_REU       0.66      0.68      0.67      3522\n",
            "      PES_TESTEMUNHA       0.74      0.60      0.66      1140\n",
            "          PES_VITIMA       0.59      0.31      0.40       781\n",
            "               PROVA       0.26      0.64      0.37      1132\n",
            "            SENTENÇA       0.00      0.00      0.00        29\n",
            "\n",
            "           micro avg       0.64      0.64      0.64     17953\n",
            "           macro avg       0.61      0.51      0.52     17953\n",
            "        weighted avg       0.69      0.64      0.64     17953\n",
            "\n",
            "\tB-END_AUTOR B-END_DELITO B-END_OUTROS B-END_REU B-END_TESTEMUNHA B-END_VITIMA B-NOR_ACESSORIA B-NOR_JURISPRUDÊNCIA B-NOR_PRINCIPAL B-PENA B-PES_ADVOG B-PES_AUTOR B-PES_AUTORID_POLICIAL B-PES_JUIZ B-PES_OUTROS B-PES_PROMOTOR_MP B-PES_REU B-PES_TESTEMUNHA B-PES_VITIMA B-PROVA B-SENTENÇA O\n",
            "B-END_AUTOR\t[ 9  0  0 24  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5]\n",
            "B-END_DELITO\t[ 0 48  0 85  0  1  0  0  0  0  0  0  0  0  1  0  0  0  0 13  0  8]\n",
            "B-END_OUTROS\t[ 0  3  4 42  4  3  0  1  0  0  0  0  0  0  0  0  0  0  0  2  0 94]\n",
            "B-END_REU\t[  0   0   0 251  12   4   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   8   0   8]\n",
            "B-END_TESTEMUNHA\t[ 0  0  0 72 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5  0  2]\n",
            "B-END_VITIMA\t[ 0  1  0 44  5 10  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  8]\n",
            "B-NOR_ACESSORIA\t[   0    0    0    1    0    0 2139   21  123    0    0    0    0    0\n",
            "    2    0    0    0    0   10    0   69]\n",
            "B-NOR_JURISPRUDÊNCIA\t[  0   0   0   1   0   0   4 692   3   0   0   0   0   0   2   0   0   0\n",
            "   0  10   0  41]\n",
            "B-NOR_PRINCIPAL\t[   0    0    0    2    0    0  851   10 1744    0    0    0    0    0\n",
            "    1    0    0    0    0   40    0   99]\n",
            "B-PENA\t[ 0  0  0  0  0  0  2  0  0 83  0  0  0  0  0  0  2  0  0 29  0 23]\n",
            "B-PES_ADVOG\t[ 0  0  0  5  0  0  0  0  0  0 80  2  0  2 34  3 16  1  3  4  0 78]\n",
            "B-PES_AUTOR\t[  0   0   0   1   0   0   0   0   0   0   0 170   0   1  10   0  66   1\n",
            "   0  16   0 216]\n",
            "B-PES_AUTORID_POLICIAL\t[  0   0   0   0   0   0   0   0   0   0   0   0 676   0  66   2  25  10\n",
            "   1   3   0  39]\n",
            "B-PES_JUIZ\t[  0   0   0   1   0   0   0   0   0   0   0   0   1 118  17   3   5   3\n",
            "   8   2   0  25]\n",
            "B-PES_OUTROS\t[   0    1    1   30    0    5    1    4    0    0    5   15   28    4\n",
            " 1261    9  355   40   48  245    0  600]\n",
            "B-PES_PROMOTOR_MP\t[  0   0   0   0   0   0   0   0   0   0   0   2   0   2   4 122   4   2\n",
            "   0   2   0  20]\n",
            "B-PES_REU\t[   8    0    2   37    0    5    2    1    0    0    0    3    2    0\n",
            "   88    2 2410   72   36  497    0  357]\n",
            "B-PES_TESTEMUNHA\t[  0   0   0   8   0   0   0   0   0   0   0   0   1   1  37   0 212 683\n",
            "  28  91   0  79]\n",
            "B-PES_VITIMA\t[  0   0   0   3   0   0   0   0   0   0   0   0   1   4  43   1 237  60\n",
            " 241 137   0  54]\n",
            "B-PROVA\t[  0   1   0  24   0   0   0   7   0   2   0   1   1   0   8   0   5   8\n",
            "   0 720   0 355]\n",
            "B-SENTENÇA\t[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0 10  0 16]\n",
            "O\t[     0      2     26    163      0      5    184     69     52     37\n",
            "     19     23     45     27    371     10    314     46     46    897\n",
            "      0 639370]\n"
          ]
        }
      ],
      "source": [
        "#test  = CoNLLDataset('/content/drive/MyDrive/Unifor/NER/cdjur/cdjur_v8/test/labeled/test.conll', processing_word)\n",
        "\n",
        "model.evaluate(test)"
      ]
    }
  ]
}